import sys
from pathlib import Path
import torch
import numpy as np
import open3d as o3d
import argparse
import json
import csv
from typing import Dict, Tuple, Optional

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pointcept.models import build_model
from pointcept.utils.config import Config


def extract_sample_id_from_patch_name(patch_name: str) -> Optional[int]:
    """
    ä» patch æ–‡ä»¶åæå–æ ·æœ¬ ID
    
    Examples:
        >>> extract_sample_id_from_patch_name("patch_000044.pth")
        44
        >>> extract_sample_id_from_patch_name("patch_000198.pth")
        198
    """
    patch_name = Path(patch_name).stem
    
    if patch_name.startswith('patch_'):
        try:
            return int(patch_name.split('_')[1])
        except:
            pass
    
    try:
        return int(patch_name.split('_')[-1])
    except:
        return None


class PTv3ContactMatcher:
    """PTv3 æ¥è§¦ç‚¹ä½ç½®é¢„æµ‹å™¨"""
    
    def __init__(self, config_path: str, checkpoint_path: str, device=None):
        self.config_path = Path(config_path)
        self.checkpoint_path = Path(checkpoint_path)
        
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = device
        
        print(f"ğŸ”§ åŠ è½½é…ç½®: {self.config_path}")
        self.cfg = Config.fromfile(str(self.config_path))
        
        print(f"ğŸ”§ æ„å»ºæ¨¡å‹...")
        self.model = build_model(self.cfg.model).to(self.device)
        
        print(f"ğŸ”§ åŠ è½½æƒé‡: {self.checkpoint_path}")
        checkpoint = torch.load(self.checkpoint_path, map_location=self.device, weights_only=False)
        
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        elif 'model' in checkpoint:
            state_dict = checkpoint['model']
        else:
            state_dict = checkpoint
        
        new_state_dict = {}
        for k, v in state_dict.items():
            if k.startswith('module.'):
                new_state_dict[k[7:]] = v
            else:
                new_state_dict[k] = v
        
        self.model.load_state_dict(new_state_dict)
        self.model.eval()
        
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        if 'epoch' in checkpoint:
            print(f"   è®­ç»ƒè½®æ•°: {checkpoint['epoch']}")
        if 'best_metric_value' in checkpoint:
            print(f"   æœ€ä½³æŒ‡æ ‡: {checkpoint['best_metric_value']:.6f}")
        print(f"   æ¨ç†è®¾å¤‡: {self.device}")
    
    def predict(self, input_dict: Dict, verbose: bool = False) -> np.ndarray:
        model_input = {
            'local': {},
            'parent': {},
        }
        
        if 'local' not in input_dict:
            raise KeyError("Missing 'local' key in input_dict")
        
        if hasattr(self.model, 'use_parent_cloud') and self.model.use_parent_cloud:
            if 'parent' not in input_dict:
                raise KeyError("Missing 'parent' key in input_dict (required when use_parent_cloud=True)")
        
        local_data = input_dict['local']
        num_local_points = None
        for key in ['coord', 'feat', 'grid_coord']:
            if key not in local_data:
                raise KeyError(f"Missing '{key}' in input_dict['local']")
            
            value = local_data[key]
            
            if isinstance(value, np.ndarray):
                value = torch.from_numpy(value)
            elif not isinstance(value, torch.Tensor):
                value = torch.tensor(value)
            
            if num_local_points is None:
                num_local_points = value.shape[0]

            if key in ['coord', 'feat']:
                value = value.float()
            elif key == 'grid_coord':
                value = value.long()
            
            model_input['local'][key] = value.to(self.device) 

        # local point cloud batch and offset
        if 'batch' in local_data:
            batch = local_data['batch']
            if isinstance(batch, np.ndarray):
                batch = torch.from_numpy(batch).long()
            elif not isinstance(batch, torch.Tensor):
                batch = torch.tensor(batch).long()
            model_input['local']['batch'] = batch.to(self.device)
        else:
            model_input['local']['batch'] = torch.zeros(num_local_points, dtype=torch.long, device=self.device)
        
        if 'offset' in local_data:
            offset = local_data['offset']
            if isinstance(offset, np.ndarray):
                offset = torch.from_numpy(offset).long()
            elif not isinstance(offset, torch.Tensor):
                offset = torch.tensor(offset).long()
            model_input['local']['offset'] = offset.to(self.device)
        else:
            model_input['local']['offset'] = torch.tensor([num_local_points], dtype=torch.long, device=self.device)
            
        # deal parent point cloud    
        if hasattr(self.model, 'use_parent_cloud') and self.model.use_parent_cloud:
            parent_data = input_dict['parent']
            num_parent_points = None
            
            for key in ['coord', 'feat', 'grid_coord']:
                if key not in parent_data:
                    raise KeyError(f"Missing '{key}' in input_dict['parent']")
                
                value = parent_data[key]
                if isinstance(value, np.ndarray):
                    value = torch.from_numpy(value)
                elif not isinstance(value, torch.Tensor):
                    value = torch.tensor(value)

                if num_parent_points is None:
                    num_parent_points = value.shape[0]

                if key in ['coord', 'feat']:
                    value = value.float()
                elif key == 'grid_coord':
                    value = value.long()
                
                model_input['parent'][key] = value.to(self.device)
            # parent point cloud batch and offset    
            if 'batch' in parent_data:
                batch = parent_data['batch']
                if isinstance(batch, np.ndarray):
                    batch = torch.from_numpy(batch).long()
                elif not isinstance(batch, torch.Tensor):
                    batch = torch.tensor(batch).long()
                model_input['parent']['batch'] = batch.to(self.device)
            else:
                model_input['parent']['batch'] = torch.zeros(num_parent_points, dtype=torch.long, device=self.device)
            
            if 'offset' in parent_data:
                offset = parent_data['offset']
                if isinstance(offset, np.ndarray):
                    offset = torch.from_numpy(offset).long()
                elif not isinstance(offset, torch.Tensor):
                    offset = torch.tensor(offset).long()
                model_input['parent']['offset'] = offset.to(self.device)
            else:
                model_input['parent']['offset'] = torch.tensor([num_parent_points], dtype=torch.long, device=self.device)     

        # deal whole model input
        if 'grid_size' in input_dict:
            grid_size = input_dict['grid_size']
            if isinstance(grid_size, (int, float)):
                grid_size = torch.tensor(grid_size, dtype=torch.float32)
            elif isinstance(grid_size, np.ndarray):
                grid_size = torch.from_numpy(grid_size).float()
            elif not isinstance(grid_size, torch.Tensor):
                grid_size = torch.tensor(grid_size).float()
            model_input['grid_size'] = grid_size.to(self.device)

        if 'category_id' in input_dict:
            category_id = input_dict['category_id']
            
            if isinstance(category_id, np.ndarray):
                category_id = torch.from_numpy(category_id).long()
            elif isinstance(category_id, (int, np.integer)):
                category_id = torch.tensor(category_id, dtype=torch.long)
            elif not isinstance(category_id, torch.Tensor):
                category_id = torch.tensor(category_id).long()

            if category_id.dim() == 0:
                category_id = category_id.unsqueeze(0)
            
            model_input['category_id'] = category_id.to(self.device)        

        # print debug information
        print("\nğŸ“Š æ¨¡å‹è¾“å…¥:")
        print(f"   use_parent_cloud: {getattr(self.model, 'use_parent_cloud', False)}")
        print(f"   fusion_type: {getattr(self.model, 'fusion_type', 'N/A')}")
        
        if 'local' in model_input:
            print(f"\n   å±€éƒ¨ç‚¹äº‘:")
            for key, value in model_input['local'].items():
                if isinstance(value, torch.Tensor):
                    print(f"      {key}: shape={value.shape}, dtype={value.dtype}")
        
        if 'parent' in model_input and len(model_input['parent']) > 0:
            print(f"\n   çˆ¶ç‚¹äº‘:")
            for key, value in model_input['parent'].items():
                if isinstance(value, torch.Tensor):
                    print(f"      {key}: shape={value.shape}, dtype={value.dtype}")
        
        print(f"\n   å…¨å±€å‚æ•°:")
        if 'grid_size' in model_input:
            print(f"      grid_size: {model_input['grid_size'].item()}")
        if 'category_id' in model_input:
            print(f"      category_id: {model_input['category_id'].item()}")
        
        if 'norm_offset' in input_dict and 'norm_scale' in input_dict:
            print(f"\nğŸ“ å½’ä¸€åŒ–å‚æ•°:")
            print(f"   norm_offset: {input_dict['norm_offset']}")
            print(f"   norm_scale: {input_dict['norm_scale']}")  

        # output final prediction      
        with torch.no_grad():
            output_dict = self.model(model_input)
        
        pred_position = output_dict['pred_position'].cpu().numpy()[0]
        
        return pred_position


def load_patch_data(
    patch_path: Path, 
    parent_pcd_root: Path,
    grid_size: float = 0.002,
    verbose: bool = False
) -> Dict[str, torch.Tensor]:
    """
    åŠ è½½åŸå§‹ patch æ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
    
    Args:
        patch_path: patch æ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚: patch_000120.pth)
        parent_pcd_root: çˆ¶ç‚¹äº‘æ ¹ç›®å½• (ä¾‹å¦‚: /home/ypf/touch_processed_data)
        grid_size: ä½“ç´ åŒ–ç½‘æ ¼å¤§å° (é»˜è®¤: 0.002)
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        å¤„ç†åçš„å­—å…¸ï¼ˆä¸ DataLoader è¾“å‡ºæ ¼å¼ä¸€è‡´ï¼‰
    """
    try:
        data = torch.load(patch_path, map_location='cpu', weights_only=False)
    except Exception as e:
        raise RuntimeError(f"Failed to load {patch_path}: {e}")
    
    # âœ… æ£€æŸ¥åŸå§‹æ•°æ®æ ¼å¼ï¼ˆæ‰å¹³ç»“æ„ï¼‰
    required_keys = ['local_coord', 'local_color', 'gt_position', 'norm_offset', 'norm_scale']
    missing_keys = [k for k in required_keys if k not in data]
    if missing_keys:
        raise KeyError(
            f"Missing required keys: {missing_keys}\n"
            f"Available keys: {list(data.keys())}"
        )
    
    # âœ… 1. æå–å±€éƒ¨ç‚¹äº‘æ•°æ®
    local_coord = data['local_coord']  # (N_local, 3)
    local_color = data['local_color']  # (N_local, 3)
    
    if isinstance(local_coord, np.ndarray):
        local_coord = torch.from_numpy(local_coord).float()
    elif not isinstance(local_coord, torch.Tensor):
        local_coord = torch.tensor(local_coord).float()
    
    if isinstance(local_color, np.ndarray):
        local_color = torch.from_numpy(local_color).float()
    elif not isinstance(local_color, torch.Tensor):
        local_color = torch.tensor(local_color).float()
    
    # âœ… 2. æå–å½’ä¸€åŒ–å‚æ•°
    norm_offset = data['norm_offset']
    norm_scale = data['norm_scale']
    
    if isinstance(norm_offset, np.ndarray):
        norm_offset = torch.from_numpy(norm_offset).float()
    elif not isinstance(norm_offset, torch.Tensor):
        norm_offset = torch.tensor(norm_offset).float()
    
    if isinstance(norm_scale, np.ndarray):
        norm_scale = torch.from_numpy(norm_scale).float()
    elif not isinstance(norm_scale, torch.Tensor):
        norm_scale = torch.tensor(norm_scale).float()
    
    # âœ… 3. åŠ è½½çˆ¶ç‚¹äº‘
    bigpcd_id = data.get('bigpcd_id', data.get('parent_id'))
    category = data.get('category', 'Unknown')
    
    if bigpcd_id is None:
        raise KeyError("Missing 'bigpcd_id' or 'parent_id' in patch data")
    
    # æ ¼å¼åŒ– bigpcd_idï¼ˆç¡®ä¿æ˜¯ 3 ä½å­—ç¬¦ä¸²ï¼‰
    if isinstance(bigpcd_id, (int, np.integer)):
        bigpcd_id_str = f"{bigpcd_id:03d}"
    else:
        bigpcd_id_str = str(bigpcd_id).zfill(3)
    
    # æ„é€ çˆ¶ç‚¹äº‘æ–‡ä»¶è·¯å¾„
    bigpcd_name = data.get('bigpcd_name', f'bigpointcloud_{bigpcd_id_str}.ply')
    
    # å°è¯•ä¸åŒçš„è·¯å¾„æ ¼å¼
    possible_paths = [
        parent_pcd_root / category / bigpcd_name,
        parent_pcd_root / category / f'bigpointcloud_{bigpcd_id_str}.ply',
        parent_pcd_root / category / f'data{bigpcd_id_str}.ply',
        parent_pcd_root / bigpcd_name,
    ]
    
    parent_pcd_path = None
    for path in possible_paths:
        if path.exists():
            parent_pcd_path = path
            break
    
    if parent_pcd_path is None:
        raise FileNotFoundError(
            f"Cannot find parent point cloud for bigpcd_id={bigpcd_id}\n"
            f"Category: {category}\n"
            f"Tried paths:\n" + "\n".join([f"  - {p}" for p in possible_paths])
        )
    
    if verbose:
        print(f"   ğŸ“‚ åŠ è½½çˆ¶ç‚¹äº‘: {parent_pcd_path}")
    
    # è¯»å–çˆ¶ç‚¹äº‘
    import open3d as o3d
    parent_pcd = o3d.io.read_point_cloud(str(parent_pcd_path))
    parent_coord = np.asarray(parent_pcd.points).astype(np.float32)
    parent_color = np.asarray(parent_pcd.colors).astype(np.float32)
    
    parent_coord = torch.from_numpy(parent_coord).float()
    parent_color = torch.from_numpy(parent_color).float()
    
    # âœ… 4. å½’ä¸€åŒ–åæ ‡ï¼ˆä½¿ç”¨æ•°æ®é›†ä¸­ä¿å­˜çš„å½’ä¸€åŒ–å‚æ•°ï¼‰
    # æ³¨æ„ï¼šå±€éƒ¨ç‚¹äº‘å·²ç»æ˜¯å½’ä¸€åŒ–åçš„ï¼Œæ‰€ä»¥ä¸éœ€è¦å†æ¬¡å½’ä¸€åŒ–
    # ä½†çˆ¶ç‚¹äº‘éœ€è¦å½’ä¸€åŒ–
    local_coord_normalized = local_coord  # å·²ç»å½’ä¸€åŒ–
    parent_coord_normalized = (parent_coord - norm_offset) / norm_scale
    
    # âœ… 5. ä½“ç´ åŒ–ï¼ˆGridSampleï¼‰
    local_grid_coord = torch.floor(local_coord_normalized / grid_size).long()
    parent_grid_coord = torch.floor(parent_coord_normalized / grid_size).long()
    
    # âœ… 6. æå– GT ä½ç½®ï¼ˆå·²ç»æ˜¯å½’ä¸€åŒ–çš„ï¼‰
    gt_position = data['gt_position']
    if isinstance(gt_position, np.ndarray):
        gt_position = torch.from_numpy(gt_position).float()
    elif not isinstance(gt_position, torch.Tensor):
        gt_position = torch.tensor(gt_position).float()
    
    # âœ… 7. æå– category_id
    category_id = data.get('category_id')
    if category_id is not None:
        if isinstance(category_id, np.ndarray):
            category_id = torch.from_numpy(category_id).long()
        elif isinstance(category_id, (int, np.integer)):
            category_id = torch.tensor(category_id, dtype=torch.long)
        elif not isinstance(category_id, torch.Tensor):
            category_id = torch.tensor(category_id).long()
    
    # âœ… 8. æ„é€ åµŒå¥—ç»“æ„ï¼ˆä¸ DataLoader ä¸€è‡´ï¼‰
    result = {
        'local': {
            'coord': local_coord_normalized,  # (N_local, 3) - å·²å½’ä¸€åŒ–
            'feat': local_color,               # (N_local, 3)
            'grid_coord': local_grid_coord,    # (N_local, 3)
            'offset': torch.tensor([local_coord_normalized.shape[0]], dtype=torch.long),
        },
        'parent': {
            'coord': parent_coord_normalized,  # (N_parent, 3) - å½’ä¸€åŒ–
            'feat': parent_color,              # (N_parent, 3)
            'grid_coord': parent_grid_coord,   # (N_parent, 3)
            'offset': torch.tensor([parent_coord_normalized.shape[0]], dtype=torch.long),
            'name': str(parent_pcd_path.name),
        },
        'gt_position': gt_position,            # (3,) - å·²å½’ä¸€åŒ–
        'norm_offset': norm_offset,            # (3,)
        'norm_scale': norm_scale,              # (3,) or scalar
        'category_id': category_id,            # scalar
        'name': data.get('name', patch_path.stem),
        'grid_size': grid_size,
        
        # ğŸ”¥ é¢å¤–ä¿å­˜åŸå§‹æ•°æ®ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        '_raw_data': data,
        '_parent_pcd_path': parent_pcd_path,
    }
    
    if verbose:
        print(f"\nâœ… æ•°æ®åŠ è½½æˆåŠŸ:")
        print(f"   å±€éƒ¨ç‚¹äº‘: {result['local']['coord'].shape[0]} ç‚¹")
        print(f"   çˆ¶ç‚¹äº‘: {result['parent']['coord'].shape[0]} ç‚¹")
        print(f"   GT ä½ç½®ï¼ˆå½’ä¸€åŒ–ï¼‰: {gt_position.tolist()}")
        print(f"   å½’ä¸€åŒ–å‚æ•°:")
        print(f"      offset: {norm_offset.tolist()}")
        print(f"      scale: {norm_scale.tolist()}")
        if category_id is not None:
            print(f"   ç±»åˆ« ID: {category_id.item()}")
        print(f"   çˆ¶ç‚¹äº‘æ–‡ä»¶: {parent_pcd_path}")
    
    return result


def get_parent_model_from_data(patch_data: Dict) -> Optional[str]:
    if 'parent' in patch_data and 'name' in patch_data['parent']:
        parent_name = patch_data['parent']['name']
        if isinstance(parent_name, str):
            try:
                # ä¾‹å¦‚ï¼šbigpointcloud_001.ply â†’ 001
                return parent_name.split('_')[-1].split('.')[0].zfill(3)
            except:
                pass
    
    return None


def denormalize_position(position_normalized: np.ndarray, norm_offset, norm_scale) -> np.ndarray:
    if isinstance(norm_offset, torch.Tensor):
        norm_offset = norm_offset.cpu().numpy()
    if isinstance(norm_scale, torch.Tensor):
        norm_scale = norm_scale.cpu().numpy()
    
    if isinstance(position_normalized, torch.Tensor):
        position_normalized = position_normalized.cpu().numpy()
    if not isinstance(position_normalized, np.ndarray):
        position_normalized = np.array(position_normalized)
    
    return position_normalized * norm_scale + norm_offset


def visualize_prediction(
    patch_data: Dict,
    pred_position: np.ndarray,
    gt_position: np.ndarray,
    complete_model_path: Path = None,  # ğŸ”¥ æ”¹ä¸ºå¯é€‰
    patch_name: str = "",
    save_dir: Path = None,
    show_window: bool = False
):
    """å¯è§†åŒ–é¢„æµ‹ç»“æœ"""
    geometries = []
    
    # ğŸ”¥ å¦‚æœæ²¡æœ‰ä¼ å…¥å®Œæ•´ç‚¹äº‘è·¯å¾„ï¼Œä» patch_data ä¸­æå–
    if complete_model_path is None:
        if '_parent_pcd_path' in patch_data:
            complete_model_path = patch_data['_parent_pcd_path']
        else:
            raise ValueError("éœ€è¦æä¾› complete_model_path æˆ–åœ¨ patch_data ä¸­åŒ…å« '_parent_pcd_path'")
    
    if not complete_model_path.exists():
        raise FileNotFoundError(f"å®Œæ•´ç‚¹äº‘æ¨¡å‹ä¸å­˜åœ¨: {complete_model_path}")
    
    print(f"ğŸ“‚ åŠ è½½å®Œæ•´çˆ¶ç‚¹äº‘: {complete_model_path.name}")
    complete_pcd = o3d.io.read_point_cloud(str(complete_model_path))
    complete_pcd.paint_uniform_color([0.85, 0.85, 0.85])
    geometries.append(complete_pcd)
    
    complete_points = np.asarray(complete_pcd.points)
    pcd_min_complete = complete_points.min(axis=0)
    pcd_max_complete = complete_points.max(axis=0)
    pcd_size_complete = np.linalg.norm(pcd_max_complete - pcd_min_complete)
    pcd_center = (pcd_min_complete + pcd_max_complete) / 2
    
    # ğŸ”¥ åå½’ä¸€åŒ–å±€éƒ¨ç‚¹äº‘ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
    if '_raw_data' in patch_data:
        # ä½¿ç”¨åŸå§‹æ•°æ®ï¼ˆæœªå½’ä¸€åŒ–ï¼‰
        coord_real = patch_data['_raw_data']['local_coord']
        if isinstance(coord_real, torch.Tensor):
            coord_real = coord_real.cpu().numpy()
    else:
        # ä»å½’ä¸€åŒ–åæ ‡åæ¨
        coord_normalized = patch_data['local']['coord']
        if isinstance(coord_normalized, torch.Tensor):
            coord_normalized = coord_normalized.cpu().numpy()
        
        norm_offset = patch_data['norm_offset']
        norm_scale = patch_data['norm_scale']
        coord_real = denormalize_position(coord_normalized, norm_offset, norm_scale)
    
    patch_pcd = o3d.geometry.PointCloud()
    patch_pcd.points = o3d.utility.Vector3dVector(coord_real)
    patch_pcd.paint_uniform_color([1.0, 0.65, 0.0])
    geometries.append(patch_pcd)
    
    # åˆ›å»ºæ ‡è®°çƒä½“ï¼ˆä¿æŒä¸å˜ï¼‰
    sphere_radius = pcd_size_complete * 0.01
    
    gt_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=sphere_radius)
    gt_sphere.translate(gt_position)
    gt_sphere.paint_uniform_color([0, 0, 1])
    gt_sphere.compute_vertex_normals()
    geometries.append(gt_sphere)
    
    pred_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=sphere_radius)
    pred_sphere.translate(pred_position)
    pred_sphere.paint_uniform_color([1, 0, 0])
    pred_sphere.compute_vertex_normals()
    geometries.append(pred_sphere)
    
    # è¿æ¥çº¿
    line_set = o3d.geometry.LineSet()
    line_set.points = o3d.utility.Vector3dVector(np.array([pred_position, gt_position]))
    line_set.lines = o3d.utility.Vector2iVector([[0, 1]])
    line_set.colors = o3d.utility.Vector3dVector([[1, 1, 0]])
    geometries.append(line_set)
    
    # åæ ‡ç³»
    coord_size = pcd_size_complete * 0.05
    coord_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(
        size=coord_size, 
        origin=pcd_center
    )
    geometries.append(coord_frame)
    
    error = np.linalg.norm(pred_position - gt_position)
    
    print(f"\n{'='*70}")
    print(f"ğŸ¨ å¯è§†åŒ– ({patch_name}):")
    print(f"   è¯¯å·®: {error:.6f} ç±³ = {error*1000:.2f} æ¯«ç±³")
    print(f"{'='*70}\n")
    
    # ä¿å­˜ç»“æœ
    if save_dir is not None:
        save_dir = Path(save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜ PLY æ–‡ä»¶
        combined_pcd = o3d.geometry.PointCloud()
        combined_pcd += complete_pcd
        combined_pcd += patch_pcd
        combined_pcd += gt_sphere.sample_points_uniformly(number_of_points=1000)
        combined_pcd += pred_sphere.sample_points_uniformly(number_of_points=1000)
        
        ply_path = save_dir / f"{patch_name}_visualization.ply"
        o3d.io.write_point_cloud(str(ply_path), combined_pcd)
        print(f"âœ… PLY æ–‡ä»¶å·²ä¿å­˜: {ply_path}")
        
        # ä¿å­˜ JSON
        result = {
            'patch_name': patch_name,
            'pred_position': pred_position.tolist(),
            'gt_position': gt_position.tolist(),
            'error_meters': float(error),
            'error_mm': float(error * 1000),
            'complete_model': str(complete_model_path),
        }
        json_path = save_dir / f"{patch_name}_result.json"
        with open(json_path, 'w') as f:
            json.dump(result, f, indent=2)
        
        # ä¿å­˜ matplotlib å›¾
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            from mpl_toolkits.mplot3d import Axes3D
            
            fig = plt.figure(figsize=(15, 5))
            
            views = [
                (0, 90, "Top View (XY)"),
                (0, 0, "Front View (XZ)"),
                (90, 90, "Side View (YZ)")
            ]
            
            for i, (elev, azim, title) in enumerate(views):
                ax = fig.add_subplot(1, 3, i+1, projection='3d')
                
                sample_idx = np.random.choice(len(complete_points), 
                                             min(5000, len(complete_points)), 
                                             replace=False)
                ax.scatter(complete_points[sample_idx, 0], 
                          complete_points[sample_idx, 1], 
                          complete_points[sample_idx, 2],
                          c='gray', s=0.1, alpha=0.3, label='Complete Model')
                
                ax.scatter(coord_real[:, 0], coord_real[:, 1], coord_real[:, 2],
                          c='orange', s=5, alpha=0.8, label='Local Patch')
                
                ax.scatter(gt_position[0], gt_position[1], gt_position[2],
                          c='blue', s=200, marker='o', label='GT Position', 
                          edgecolors='black', linewidths=2)
                
                ax.scatter(pred_position[0], pred_position[1], pred_position[2],
                          c='red', s=200, marker='o', label='Predicted Position',
                          edgecolors='black', linewidths=2)
                
                ax.plot([gt_position[0], pred_position[0]],
                       [gt_position[1], pred_position[1]],
                       [gt_position[2], pred_position[2]],
                       'y-', linewidth=2, label='Error Line')
                
                ax.set_xlabel('X')
                ax.set_ylabel('Y')
                ax.set_zlabel('Z')
                ax.set_title(f"{title}\nError: {error*1000:.2f} mm")
                ax.view_init(elev=elev, azim=azim)
                
                if i == 0:
                    ax.legend(fontsize=8, loc='upper right')
            
            plt.suptitle(f"Contact Point Prediction - {patch_name}", fontsize=14)
            plt.tight_layout()
            
            plt_path = save_dir / f"{patch_name}_matplotlib.png"
            plt.savefig(plt_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"âœ… Matplotlib å›¾ç‰‡å·²ä¿å­˜: {plt_path}")
        except Exception as e:
            print(f"âš ï¸  Matplotlib æ¸²æŸ“å¤±è´¥: {e}")
    
    if show_window:
        try:
            o3d.visualization.draw_geometries(
                geometries,
                window_name=f"æ¥è§¦ç‚¹é¢„æµ‹ - {patch_name}",
                width=1920,
                height=1080,
                point_show_normal=False
            )
        except Exception as e:
            print(f"âš ï¸  æ— æ³•æ˜¾ç¤ºçª—å£: {e}")


def test_all_patches(
    matcher: PTv3ContactMatcher,
    dataset_dir: Path,
    category: str = "Scissors",
    save_dir: Path = Path("inference_results"),
    visualize_best_worst_median: bool = True,
    grid_size: float = 0.002,  # ğŸ”¥ æ–°å¢å‚æ•°
):
    """æµ‹è¯•æ•°æ®é›†ä¸­çš„æ‰€æœ‰æ ·æœ¬"""
    print(f"\n{'='*80}")
    print(f"ğŸš€ æ‰¹é‡æµ‹è¯•æ‰€æœ‰ç‚¹äº‘")
    print(f"{'='*80}")
    
    category_dir = dataset_dir / category / "patches"
    
    if not category_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {category_dir}")
        return
    
    patch_files = sorted(category_dir.glob("*.pth"))
    
    if not patch_files:
        print(f"âŒ ç›®å½•ä¸­æ²¡æœ‰ .pth æ–‡ä»¶: {category_dir}")
        return
    
    print(f"ğŸ“‚ æ•°æ®é›†ç›®å½•: {category_dir}")
    print(f"ğŸ“Š æ‰¾åˆ° {len(patch_files)} ä¸ªå°ç‚¹äº‘")
    
    # æŸ¥æ‰¾æ‰€æœ‰å®Œæ•´ç‚¹äº‘æ–‡ä»¶
    complete_model_dir = dataset_dir / category
    complete_models = {}
    
    for ply_file in sorted(complete_model_dir.glob("bigpointcloud_*.ply")):
        model_id = ply_file.stem.split('_')[-1]
        complete_models[model_id] = ply_file
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(complete_models)} ä¸ªå¤§ç‚¹äº‘")
    if complete_models:
        print(f"   æ¨¡å‹ ID: {list(complete_models.keys())}")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    batch_dir = save_dir / f"batch_{category}_{len(patch_files)}_samples"
    batch_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ’¾ ç»“æœä¿å­˜ç›®å½•: {batch_dir}")
    
    # é€ä¸ªæµ‹è¯•
    results = []
    failed_samples = []
    
    print(f"\n{'='*80}")
    print(f"ğŸ”® å¼€å§‹æ‰¹é‡æ¨ç†...")
    print(f"{'='*80}\n")
    
    for i, patch_path in enumerate(patch_files):
        print(f"[{i+1}/{len(patch_files)}] å¤„ç†: {patch_path.name}")
        
        patch_name = patch_path.stem
        complete_model_path = None
        
        try:
            # ğŸ”¥ åŠ è½½æ•°æ®ï¼ˆä½¿ç”¨æ–°çš„å‡½æ•°ï¼‰
            patch_data = load_patch_data(
                patch_path, 
                parent_pcd_root=dataset_dir,
                grid_size=grid_size,
                verbose=False
            )
            
            patch_name = patch_data.get('name', patch_path.stem)
            complete_model_path = patch_data['_parent_pcd_path']
            
            # é¢„æµ‹ï¼ˆå¾—åˆ°å½’ä¸€åŒ–åæ ‡ï¼‰
            pred_position_normalized = matcher.predict(patch_data, verbose=False)
            
            # GT ä½ç½®ï¼ˆå½’ä¸€åŒ–åæ ‡ï¼‰
            gt_position_normalized = patch_data['gt_position']
            if isinstance(gt_position_normalized, torch.Tensor):
                gt_position_normalized = gt_position_normalized.cpu().numpy()
            else:
                gt_position_normalized = np.array(gt_position_normalized)
            
            # ğŸ”¥ åå½’ä¸€åŒ–åˆ°çœŸå®ç©ºé—´
            pred_position = denormalize_position(
                pred_position_normalized, 
                patch_data['norm_offset'],
                patch_data['norm_scale']
            )
            gt_position = denormalize_position(
                gt_position_normalized,
                patch_data['norm_offset'],
                patch_data['norm_scale']
            )
            
            # è®¡ç®—è¯¯å·®ï¼ˆçœŸå®ç©ºé—´ï¼‰
            error = np.linalg.norm(pred_position - gt_position)
            
            # ä¿å­˜ç»“æœ
            result = {
                'index': i,
                'patch_name': patch_name,
                'patch_path': str(patch_path),
                'complete_model_path': str(complete_model_path),
                'complete_model_name': complete_model_path.name,
                'parent_id': patch_data['_raw_data'].get('parent_id', 'unknown'),
                'pred_position_normalized': pred_position_normalized.tolist(),
                'gt_position_normalized': gt_position_normalized.tolist(),
                'pred_position': pred_position.tolist(),
                'gt_position': gt_position.tolist(),
                'error_meters': float(error),
                'error_mm': float(error * 1000),
                'patch_data': patch_data,
            }
            results.append(result)
            
            print(f"   âœ… è¯¯å·®: {error*1000:.2f} mm")
            
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {e}")
            failed_samples.append({
                'patch_name': patch_name,
                'patch_path': str(patch_path),
                'reason': str(e)
            })
            continue
    
    # ç»Ÿè®¡åˆ†æ
    print(f"\n{'='*80}")
    print(f"ğŸ“ˆ ç»Ÿè®¡åˆ†æ")
    print(f"{'='*80}")
    
    if not results:
        print("âŒ æ²¡æœ‰æˆåŠŸçš„æ ·æœ¬ï¼")
        return
    
    errors = np.array([r['error_mm'] for r in results])
    
    print(f"æ€»æ ·æœ¬æ•°: {len(patch_files)}")
    print(f"æˆåŠŸæ ·æœ¬æ•°: {len(results)}")
    print(f"å¤±è´¥æ ·æœ¬æ•°: {len(failed_samples)}")
    print(f"\nè¯¯å·®ç»Ÿè®¡ (æ¯«ç±³):")
    print(f"  å¹³å‡å€¼:   {errors.mean():.2f} mm")
    print(f"  ä¸­ä½æ•°:   {np.median(errors):.2f} mm")
    print(f"  æ ‡å‡†å·®:   {errors.std():.2f} mm")
    print(f"  æœ€å°å€¼:   {errors.min():.2f} mm")
    print(f"  æœ€å¤§å€¼:   {errors.max():.2f} mm")
    
    # æ‰¾å‡ºæœ€å¥½ã€æœ€å·®ã€ä¸­ä½æ•°æ ·æœ¬
    best_idx = np.argmin(errors)
    worst_idx = np.argmax(errors)
    median_idx = np.argmin(np.abs(errors - np.median(errors)))
    
    best_sample = results[best_idx]
    worst_sample = results[worst_idx]
    median_sample = results[median_idx]
    
    print(f"\nğŸ† æœ€ä½³æ ·æœ¬: {best_sample['patch_name']} ({best_sample['error_mm']:.2f} mm)")
    print(f"ğŸ“‰ æœ€å·®æ ·æœ¬: {worst_sample['patch_name']} ({worst_sample['error_mm']:.2f} mm)")
    print(f"ğŸ“Š ä¸­ä½æ•°æ ·æœ¬: {median_sample['patch_name']} ({median_sample['error_mm']:.2f} mm)")
    
    # ä¿å­˜ç»Ÿè®¡ç»“æœ
    summary = {
        'category': category,
        'total_samples': len(patch_files),
        'successful_samples': len(results),
        'failed_samples': len(failed_samples),
        'statistics': {
            'mean_error_mm': float(errors.mean()),
            'median_error_mm': float(np.median(errors)),
            'std_error_mm': float(errors.std()),
            'min_error_mm': float(errors.min()),
            'max_error_mm': float(errors.max()),
        },
        'best_sample': {
            'name': best_sample['patch_name'],
            'error_mm': best_sample['error_mm'],
        },
        'worst_sample': {
            'name': worst_sample['patch_name'],
            'error_mm': worst_sample['error_mm'],
        },
        'median_sample': {
            'name': median_sample['patch_name'],
            'error_mm': median_sample['error_mm'],
        },
        'failed_samples': failed_samples,
    }
    
    summary_path = batch_dir / "summary.json"
    with open(summary_path, 'w') as f:
        json.dump(summary, f, indent=2)
    print(f"\nâœ… ç»Ÿè®¡ç»“æœå·²ä¿å­˜: {summary_path}")
    
    # ä¿å­˜ CSV
    csv_path = batch_dir / "all_results.csv"
    with open(csv_path, 'w', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=[
            'index', 'patch_name', 'parent_id', 'complete_model_name',
            'pred_x', 'pred_y', 'pred_z',
            'gt_x', 'gt_y', 'gt_z',
            'error_mm'
        ])
        writer.writeheader()
        for r in results:
            writer.writerow({
                'index': r['index'],
                'patch_name': r['patch_name'],
                'parent_id': r['parent_id'],
                'complete_model_name': r['complete_model_name'],
                'pred_x': r['pred_position'][0],
                'pred_y': r['pred_position'][1],
                'pred_z': r['pred_position'][2],
                'gt_x': r['gt_position'][0],
                'gt_y': r['gt_position'][1],
                'gt_z': r['gt_position'][2],
                'error_mm': r['error_mm'],
            })
    print(f"âœ… CSV å·²ä¿å­˜: {csv_path}")
    
    # ç”Ÿæˆè¯¯å·®åˆ†å¸ƒå›¾
    try:
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        ax = axes[0, 0]
        ax.hist(errors, bins=50, color='skyblue', edgecolor='black', alpha=0.7)
        ax.axvline(errors.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {errors.mean():.2f} mm')
        ax.axvline(np.median(errors), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(errors):.2f} mm')
        ax.set_xlabel('Error (mm)')
        ax.set_ylabel('Frequency')
        ax.set_title('Error Distribution')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        ax = axes[0, 1]
        bp = ax.boxplot(errors, vert=True, patch_artist=True)
        bp['boxes'][0].set_facecolor('lightblue')
        ax.set_ylabel('Error (mm)')
        ax.set_title('Error Boxplot')
        ax.grid(True, alpha=0.3)
        
        ax = axes[1, 0]
        ax.plot(range(len(errors)), errors, 'o-', markersize=2, linewidth=0.5, alpha=0.6)
        ax.axhline(errors.mean(), color='red', linestyle='--', linewidth=2, label='Mean')
        ax.axhline(np.median(errors), color='green', linestyle='--', linewidth=2, label='Median')
        ax.set_xlabel('Sample Index')
        ax.set_ylabel('Error (mm)')
        ax.set_title('Error vs Sample Index')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        ax = axes[1, 1]
        sorted_errors = np.sort(errors)
        cumulative = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)
        ax.plot(sorted_errors, cumulative, linewidth=2)
        ax.axvline(errors.mean(), color='red', linestyle='--', linewidth=2, label='Mean')
        ax.axvline(np.median(errors), color='green', linestyle='--', linewidth=2, label='Median')
        ax.set_xlabel('Error (mm)')
        ax.set_ylabel('Cumulative Probability')
        ax.set_title('Cumulative Distribution Function')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'Error Analysis - {category} ({len(results)} samples)', fontsize=16)
        plt.tight_layout()
        
        plot_path = batch_dir / "error_analysis.png"
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… è¯¯å·®åˆ†æå›¾å·²ä¿å­˜: {plot_path}")
    except Exception as e:
        print(f"âš ï¸  ç”Ÿæˆè¯¯å·®åˆ†æå›¾å¤±è´¥: {e}")
    
    # å¯è§†åŒ–ä»£è¡¨æ€§æ ·æœ¬
    if visualize_best_worst_median:
        print(f"\nğŸ¨ ç”Ÿæˆä»£è¡¨æ€§æ ·æœ¬çš„å¯è§†åŒ–\n")
        
        samples_to_visualize = [
            (best_sample, "best"),
            (median_sample, "median"),
            (worst_sample, "worst"),
        ]
        
        for sample, label in samples_to_visualize:
            try:
                visualize_prediction(
                    sample['patch_data'],
                    np.array(sample['pred_position']),
                    np.array(sample['gt_position']),
                    Path(sample['complete_model_path']),
                    patch_name=f"{label}_{sample['patch_name']}",
                    save_dir=batch_dir,
                    show_window=False
                )
            except Exception as e:
                print(f"   âš ï¸  å¯è§†åŒ–å¤±è´¥: {e}")
    
    print(f"\n{'='*80}")
    print(f"âœ… æ‰¹é‡æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“‚ ç»“æœä¿å­˜åœ¨: {batch_dir}")
    print(f"{'='*80}\n")
    
    return results, summary


def main():
    parser = argparse.ArgumentParser(description='PTv3 Contact Position Regression æ¨ç†')
    parser.add_argument('--config', type=str, 
                        default='configs/s3dis/semseg-pt-v3m1-gelsight.py')
    parser.add_argument('--checkpoint', type=str,
                        default='exp/gelsight_test/model/model_best.pth')
    parser.add_argument('--dataset_dir', type=str,
                        default='../../touch_processed_data')
    parser.add_argument('--category', type=str,
                        default='Scissors',
                        choices=['Scissors', 'Cup', 'Avocado'])
    parser.add_argument('--save_dir', type=str,
                        default='inference_results')
    parser.add_argument('--no_vis', action='store_true',
                        help='ä¸ç”Ÿæˆå¯è§†åŒ–')
    parser.add_argument('--grid_size', type=float, default=0.002,
                        help='ä½“ç´ åŒ–ç½‘æ ¼å¤§å°ï¼ˆé»˜è®¤: 0.002ï¼‰')
    
    args = parser.parse_args()
    
    print(f"\n{'='*80}")
    print(f"ğŸš€ åˆå§‹åŒ– PTv3 Contact Matcher")
    print(f"{'='*80}")
    
    matcher = PTv3ContactMatcher(
        config_path=args.config,
        checkpoint_path=args.checkpoint
    )
    
    test_all_patches(
        matcher,
        dataset_dir=Path(args.dataset_dir),
        category=args.category,
        save_dir=Path(args.save_dir),
        visualize_best_worst_median=not args.no_vis,
        grid_size=args.grid_size,  # ğŸ”¥ ä¼ å…¥ grid_size
    )


if __name__ == "__main__":
    main()