import sys
from pathlib import Path
import torch
import numpy as np
import open3d as o3d
import argparse
from typing import Dict, Tuple, Optional

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pointcept.models import build_model
from pointcept.utils.config import Config

def get_parent_model_from_sample_id(sample_id: int, samples_per_bigpcd: int = 50):
    """
    æ ¹æ®æ ·æœ¬ ID è®¡ç®—å¯¹åº”çš„çˆ¶ç‚¹äº‘ ID
    
    Args:
        sample_id: æ ·æœ¬ç¼–å·ï¼ˆä» patch æ–‡ä»¶åæå–ï¼‰
        samples_per_bigpcd: æ¯ä¸ªå¤§ç‚¹äº‘ç”Ÿæˆçš„æ ·æœ¬æ•°
    
    Returns:
        parent_id: çˆ¶ç‚¹äº‘ IDï¼ˆä¾‹å¦‚ "001", "002"ï¼‰
    
    Examples:
        >>> get_parent_model_from_sample_id(44, 50)
        '001'  # 0-49 â†’ bigpointcloud_001
        >>> get_parent_model_from_sample_id(99, 50)
        '002'  # 50-99 â†’ bigpointcloud_002
        >>> get_parent_model_from_sample_id(150, 50)
        '004'  # 150-199 â†’ bigpointcloud_004
    """
    bigpcd_id = (sample_id // samples_per_bigpcd) + 1
    return f"{bigpcd_id:03d}"


def extract_sample_id_from_patch_name(patch_name: str):
    """
    ä» patch æ–‡ä»¶åæå–æ ·æœ¬ ID
    
    Examples:
        >>> extract_sample_id_from_patch_name("patch_000044.pth")
        44
        >>> extract_sample_id_from_patch_name("patch_000198.pth")
        198
    """
    # ç§»é™¤è·¯å¾„å’Œæ‰©å±•å
    patch_name = Path(patch_name).stem
    
    # æå–æ•°å­—éƒ¨åˆ†
    if patch_name.startswith('patch_'):
        try:
            return int(patch_name.split('_')[1])
        except:
            pass
    
    # å°è¯•ä»æœ«å°¾æå–æ•°å­—
    try:
        return int(patch_name.split('_')[-1])
    except:
        return None
        
class PTv3ContactMatcher:
    """PTv3 æ¥è§¦ç‚¹ä½ç½®é¢„æµ‹å™¨"""
    
    def __init__(self, config_path: str, checkpoint_path: str, device=None):
        """
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            checkpoint_path: æ¨¡å‹æƒé‡è·¯å¾„
            device: æ¨ç†è®¾å¤‡
        """
        self.config_path = Path(config_path)
        self.checkpoint_path = Path(checkpoint_path)
        
        # è®¾å¤‡é€‰æ‹©
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = device
        
        # åŠ è½½é…ç½®
        print(f"ğŸ”§ åŠ è½½é…ç½®: {self.config_path}")
        self.cfg = Config.fromfile(str(self.config_path))
        
        # æ„å»ºæ¨¡å‹
        print(f"ğŸ”§ æ„å»ºæ¨¡å‹...")
        self.model = build_model(self.cfg.model).to(self.device)
        
        # åŠ è½½æƒé‡
        print(f"ğŸ”§ åŠ è½½æƒé‡: {self.checkpoint_path}")
        checkpoint = torch.load(self.checkpoint_path, map_location=self.device, weights_only=False)
        
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        elif 'model' in checkpoint:
            state_dict = checkpoint['model']
        else:
            state_dict = checkpoint
        
        # ç§»é™¤ 'module.' å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
        new_state_dict = {}
        for k, v in state_dict.items():
            if k.startswith('module.'):
                new_state_dict[k[7:]] = v
            else:
                new_state_dict[k] = v
        
        self.model.load_state_dict(new_state_dict)
        self.model.eval()
        
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        if 'epoch' in checkpoint:
            print(f"   è®­ç»ƒè½®æ•°: {checkpoint['epoch']}")
        if 'best_metric_value' in checkpoint:
            print(f"   æœ€ä½³æŒ‡æ ‡: {checkpoint['best_metric_value']:.6f}")
        print(f"   æ¨ç†è®¾å¤‡: {self.device}")
    
    def predict(self, input_dict: Dict) -> np.ndarray:
        """
        é¢„æµ‹æ¥è§¦ç‚¹ä½ç½®
        
        Args:
            input_dict: åŒ…å«ç‚¹äº‘æ•°æ®çš„å­—å…¸ï¼ˆå¯èƒ½æ˜¯ torch.Tensor æˆ– numpy.ndarrayï¼‰
                - 'coord': (N, 3) ç‚¹åæ ‡
                - 'feat': (N, 3) ç‚¹ç‰¹å¾
                - 'category_id': (1,) ç±»åˆ« IDï¼ˆå¯é€‰ï¼‰
        
        Returns:
            pred_position: (3,) é¢„æµ‹çš„æ¥è§¦ç‚¹ä½ç½®
        """
        # å‡†å¤‡è¾“å…¥
        model_input = {}
        
        # ğŸ”¥ é¦–å…ˆè·å–ç‚¹äº‘æ•°é‡
        num_points = None
        
        for key in ['coord', 'feat', 'grid_coord']:
            if key in input_dict:
                value = input_dict[key]
                
                # ç»Ÿä¸€è½¬æ¢ä¸º torch.Tensor
                if isinstance(value, np.ndarray):
                    value = torch.from_numpy(value).float()
                elif not isinstance(value, torch.Tensor):
                    value = torch.tensor(value).float()
                
                # è®°å½•ç‚¹æ•°
                if num_points is None:
                    num_points = value.shape[0]
                
                # ç¡®ä¿æ­£ç¡®çš„æ•°æ®ç±»å‹
                if key in ['coord', 'feat']:
                    value = value.float()
                elif key == 'grid_coord':
                    value = value.long()
                
                model_input[key] = value.to(self.device)
        
        # ğŸ”¥ æ·»åŠ  batch é”®
        if 'batch' not in input_dict:
            model_input['batch'] = torch.zeros(num_points, dtype=torch.long).to(self.device)
        else:
            batch = input_dict['batch']
            if isinstance(batch, np.ndarray):
                batch = torch.from_numpy(batch).long()
            elif not isinstance(batch, torch.Tensor):
                batch = torch.tensor(batch).long()
            model_input['batch'] = batch.to(self.device)
        
        # ğŸ”¥ æ·»åŠ  offset é”®
        if 'offset' not in input_dict:
            model_input['offset'] = torch.tensor([num_points], dtype=torch.long).to(self.device)
        else:
            offset = input_dict['offset']
            if isinstance(offset, np.ndarray):
                offset = torch.from_numpy(offset).long()
            elif not isinstance(offset, torch.Tensor):
                offset = torch.tensor(offset).long()
            model_input['offset'] = offset.to(self.device)
        
        # ğŸ”¥ æ·»åŠ  grid_sizeï¼ˆä»é…ç½®æ–‡ä»¶ä¸­è·å–ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼‰
        if 'grid_size' not in input_dict:
            # ä»é…ç½®æ–‡ä»¶ä¸­è·å– grid_size
            grid_size = None
            
            # æŸ¥æ‰¾é…ç½®ä¸­çš„ grid_size
            if hasattr(self.cfg, 'data'):
                data_cfg = self.cfg.data
                if 'train' in data_cfg and 'transform' in data_cfg['train']:
                    for transform in data_cfg['train']['transform']:
                        if isinstance(transform, dict) and transform.get('type') == 'GridSample':
                            grid_size = transform.get('grid_size', 0.002)
                            break
            
            # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if grid_size is None:
                grid_size = 0.002  # é»˜è®¤ 2mm
            
            model_input['grid_size'] = torch.tensor(grid_size, dtype=torch.float32).to(self.device)
        else:
            grid_size = input_dict['grid_size']
            if isinstance(grid_size, (int, float)):
                grid_size = torch.tensor(grid_size, dtype=torch.float32)
            elif isinstance(grid_size, np.ndarray):
                grid_size = torch.from_numpy(grid_size).float()
            elif not isinstance(grid_size, torch.Tensor):
                grid_size = torch.tensor(grid_size).float()
            model_input['grid_size'] = grid_size.to(self.device)
        
        # ğŸ”¥ æ·»åŠ ç±»åˆ«ä¿¡æ¯ï¼ˆä½ çš„æ¨¡å‹éœ€è¦è¿™ä¸ªï¼ï¼‰
        if 'category_id' in input_dict:
            category_id = input_dict['category_id']
            
            # ç»Ÿä¸€è½¬æ¢ä¸º torch.Tensor
            if isinstance(category_id, np.ndarray):
                category_id = torch.from_numpy(category_id).long()
            elif isinstance(category_id, (int, np.integer)):
                category_id = torch.tensor(category_id).long()
            elif not isinstance(category_id, torch.Tensor):
                category_id = torch.tensor(category_id).long()
            
            # å¤„ç†æ ‡é‡
            if category_id.dim() == 0:
                category_id = category_id.unsqueeze(0)
            
            model_input['category_id'] = category_id.to(self.device)
            
            # æ‰“å°ç±»åˆ«ä¿¡æ¯
            cat_names = ["Scissors", "Cup", "Avocado"]
            cat_id = category_id.item() if category_id.dim() == 1 else category_id[0].item()
            if 0 <= cat_id < len(cat_names):
                print(f"   ğŸ·ï¸  ç‰©ä½“ç±»åˆ«: {cat_names[cat_id]} (ID={cat_id})")
        else:
            print("   âš ï¸  æ²¡æœ‰æä¾› category_idï¼Œæ¨¡å‹å¯èƒ½éœ€è¦è¿™ä¸ªä¿¡æ¯ï¼")
        
        # ğŸ”¥ æ‰“å°è¾“å…¥ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
        print("\nğŸ“Š æ¨¡å‹è¾“å…¥:")
        for key, value in model_input.items():
            if isinstance(value, torch.Tensor):
                if value.dim() == 0:  # æ ‡é‡
                    print(f"   {key}: æ ‡é‡å€¼={value.item()}, dtype={value.dtype}")
                else:
                    print(f"   {key}: shape={value.shape}, dtype={value.dtype}")
                    if key == 'batch' and value.numel() > 0:
                        unique_batches = torch.unique(value)
                        print(f"      å”¯ä¸€æ‰¹æ¬¡: {unique_batches.tolist()}")
                    elif key == 'offset':
                        print(f"      å€¼: {value.tolist()}")
                    elif key == 'category_id':
                        print(f"      å€¼: {value.tolist()}")
            else:
                print(f"   {key}: {value}")
        
        # æ¨ç†
        with torch.no_grad():
            output_dict = self.model(model_input)
        
        # æå–é¢„æµ‹ä½ç½®
        pred_position = output_dict['pred_position'].cpu().numpy()[0]  # (3,)
        
        return pred_position


def load_patch_data(patch_path: Path, verbose: bool = False) -> Dict[str, torch.Tensor]:
    """
    åŠ è½½ .pth æ ¼å¼çš„å°ç‚¹äº‘æ•°æ®
    
    è¦æ±‚ï¼š
        - å¿…é¡»æœ‰ 'coord'ï¼ˆç‚¹åæ ‡ï¼‰
        - å¿…é¡»æœ‰ 'gt_position'ï¼ˆçœŸå®ä½ç½®ï¼‰
        - å¿…é¡»æœ‰ 'feat' æˆ– 'color'ï¼ˆé¢œè‰²ç‰¹å¾ï¼‰
    
    Args:
        patch_path: .pth æ–‡ä»¶è·¯å¾„
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        data: åŒ…å«ç‚¹äº‘æ•°æ®çš„å­—å…¸ï¼ˆç»Ÿä¸€è½¬ä¸º torch.Tensorï¼‰
    """
    # åŠ è½½æ•°æ®ï¼ˆPyTorch 2.6+ éœ€è¦ weights_only=Falseï¼‰
    try:
        data = torch.load(patch_path, map_location='cpu', weights_only=False)
    except Exception as e:
        raise RuntimeError(f"Failed to load {patch_path}: {e}")
    
    if verbose:
        print(f"\n   åŸå§‹æ•°æ®é”®: {list(data.keys())}")
    
    # 1. æ£€æŸ¥å¿…è¦çš„é”®
    missing_keys = []
    if 'coord' not in data:
        missing_keys.append('coord')
    if 'gt_position' not in data:
        missing_keys.append('gt_position')
    
    if missing_keys:
        raise KeyError(
            f"Missing required keys: {missing_keys}\n"
            f"Available keys: {list(data.keys())}"
        )
    
    # 2. ğŸ”¥ å¤„ç† featï¼ˆå¿…é¡»æ˜¯ colorï¼‰
    if 'feat' not in data:
        if 'color' in data:
            if verbose:
                print(f"   âœ… 'feat' ä¸å­˜åœ¨ï¼Œä½¿ç”¨ 'color' ä½œä¸º 'feat'")
            data['feat'] = data['color']
        else:
            raise KeyError(
                f"Missing 'feat' or 'color' in {patch_path}\n"
                f"feat å¿…é¡»æ¥è‡ªé¢œè‰²ä¿¡æ¯ï¼Œä¸èƒ½ç”¨åæ ‡ä»£æ›¿ï¼\n"
                f"Available keys: {list(data.keys())}"
            )
    
    # ğŸ”¥ 3. ç»Ÿä¸€è½¬æ¢ä¸º torch.Tensorï¼ˆå¦‚æœæ˜¯ numpy.ndarrayï¼‰
    for key in ['coord', 'feat', 'grid_coord', 'gt_position']:
        if key in data:
            value = data[key]
            if isinstance(value, np.ndarray):
                data[key] = torch.from_numpy(value)
            elif not isinstance(value, torch.Tensor):
                data[key] = torch.tensor(value)
    
    # å¤„ç† category_id
    if 'category_id' in data:
        value = data['category_id']
        if isinstance(value, np.ndarray):
            data['category_id'] = torch.from_numpy(value)
        elif isinstance(value, (int, np.integer)):
            data['category_id'] = torch.tensor(value)
        elif not isinstance(value, torch.Tensor):
            data['category_id'] = torch.tensor(value)
    
    if verbose:
        print(f"   æœ€ç»ˆæ•°æ®é”®: {list(data.keys())}")
        print(f"   æ•°æ®ç±»å‹:")
        for key, value in data.items():
            if isinstance(value, torch.Tensor):
                print(f"      {key}: shape={value.shape}, dtype={value.dtype}, type=Tensor")
            elif isinstance(value, np.ndarray):
                print(f"      {key}: shape={value.shape}, dtype={value.dtype}, type=ndarray")
            else:
                print(f"      {key}: type={type(value)}")
    
    return data


def visualize_prediction(
    patch_data: Dict,
    pred_position: np.ndarray,
    gt_position: np.ndarray,
    complete_model_path: Path,
    patch_name: str = "",
    window_title: str = "æ¥è§¦ç‚¹é¢„æµ‹ç»“æœ",
    save_dir: Path = None,
    show_window: bool = False
):
    """
    åœ¨å®Œæ•´çš„çˆ¶ç‚¹äº‘ä¸Šå¯è§†åŒ–é¢„æµ‹ç»“æœ
    
    Args:
        patch_data: å°ç‚¹äº‘æ•°æ®
        pred_position: é¢„æµ‹çš„æ¥è§¦ç‚¹ä½ç½® (3,) numpy
        gt_position: çœŸå®çš„æ¥è§¦ç‚¹ä½ç½® (3,) numpy
        complete_model_path: å®Œæ•´ç‚¹äº‘æ¨¡å‹è·¯å¾„ï¼ˆ.ply/.pcdï¼‰
        patch_name: æ ·æœ¬åç§°
        window_title: çª—å£æ ‡é¢˜
        save_dir: ä¿å­˜ç›®å½•
        show_window: æ˜¯å¦æ˜¾ç¤ºçª—å£ï¼ˆè¿œç¨‹æœåŠ¡å™¨è®¾ä¸º Falseï¼‰
    """
    geometries = []
    
    # 1. åŠ è½½å®Œæ•´çš„çˆ¶ç‚¹äº‘
    if not complete_model_path.exists():
        raise FileNotFoundError(f"å®Œæ•´ç‚¹äº‘æ¨¡å‹ä¸å­˜åœ¨: {complete_model_path}")
    
    print(f"ğŸ“‚ åŠ è½½å®Œæ•´çˆ¶ç‚¹äº‘: {complete_model_path}")
    complete_pcd = o3d.io.read_point_cloud(str(complete_model_path))
    complete_pcd.paint_uniform_color([0.85, 0.85, 0.85])  # æµ…ç°è‰²
    geometries.append(complete_pcd)
    
    # è®¡ç®—å®Œæ•´ç‚¹äº‘å°ºå¯¸
    complete_points = np.asarray(complete_pcd.points)
    pcd_min = complete_points.min(axis=0)
    pcd_max = complete_points.max(axis=0)
    pcd_size = np.linalg.norm(pcd_max - pcd_min)
    pcd_center = (pcd_min + pcd_max) / 2
    
    # 2. é«˜äº®æ˜¾ç¤ºå±€éƒ¨ç‚¹äº‘åŒºåŸŸ
    coord = patch_data['coord']
    if isinstance(coord, torch.Tensor):
        coord = coord.cpu().numpy()
    else:
        coord = np.array(coord)
    
    patch_pcd = o3d.geometry.PointCloud()
    patch_pcd.points = o3d.utility.Vector3dVector(coord)
    patch_pcd.paint_uniform_color([1.0, 0.65, 0.0])  # æ©™è‰²é«˜äº®
    geometries.append(patch_pcd)
    
    # 3. åˆ›å»º GT ä½ç½®æ ‡è®°ï¼ˆè“è‰²çƒä½“ï¼‰
    sphere_radius = pcd_size * 0.01
    gt_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=sphere_radius)
    gt_sphere.translate(gt_position)
    gt_sphere.paint_uniform_color([0, 0, 1])  # è“è‰²
    gt_sphere.compute_vertex_normals()
    geometries.append(gt_sphere)
    
    # 4. åˆ›å»ºé¢„æµ‹ä½ç½®æ ‡è®°ï¼ˆçº¢è‰²çƒä½“ï¼‰
    pred_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=sphere_radius)
    pred_sphere.translate(pred_position)
    pred_sphere.paint_uniform_color([1, 0, 0])  # çº¢è‰²
    pred_sphere.compute_vertex_normals()
    geometries.append(pred_sphere)
    
    # 5. åˆ›å»ºè¿æ¥çº¿
    line_set = o3d.geometry.LineSet()
    line_set.points = o3d.utility.Vector3dVector(np.array([pred_position, gt_position]))
    line_set.lines = o3d.utility.Vector2iVector([[0, 1]])
    line_set.colors = o3d.utility.Vector3dVector([[1, 1, 0]])  # é»„è‰²
    geometries.append(line_set)
    
    # 6. åˆ›å»ºåæ ‡ç³»
    coord_size = pcd_size * 0.05
    coord_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(
        size=coord_size, 
        origin=pcd_center
    )
    geometries.append(coord_frame)
    
    # è®¡ç®—è¯¯å·®
    error = np.linalg.norm(pred_position - gt_position)
    
    # æ‰“å°ä¿¡æ¯
    print(f"\n{'='*70}")
    print(f"ğŸ¨ å¯è§†åŒ–è¯´æ˜ ({patch_name}):")
    print(f"{'='*70}")
    print(f"   ğŸŸ¦ è“è‰²çƒä½“     = GT æ¥è§¦ç‚¹ä½ç½®ï¼ˆçœŸå®ä½ç½®ï¼‰")
    print(f"   ğŸŸ¥ çº¢è‰²çƒä½“     = é¢„æµ‹æ¥è§¦ç‚¹ä½ç½®ï¼ˆæ¨¡å‹è¾“å‡ºï¼‰")
    print(f"   â¬œ ç°è‰²ç‚¹äº‘     = å®Œæ•´çš„çˆ¶ç‚¹äº‘æ¨¡å‹")
    print(f"   ğŸŸ  æ©™è‰²ç‚¹äº‘     = è¾“å…¥çš„å±€éƒ¨ç‚¹äº‘ï¼ˆé«˜äº®æ˜¾ç¤ºï¼‰")
    print(f"   ğŸŸ¨ é»„è‰²çº¿æ®µ     = é¢„æµ‹è¯¯å·®è¿çº¿")
    print(f"\nğŸ“Š é¢„æµ‹ç»“æœ:")
    print(f"   é¢„æµ‹ä½ç½®: [{pred_position[0]:.6f}, {pred_position[1]:.6f}, {pred_position[2]:.6f}]")
    print(f"   GT ä½ç½®:   [{gt_position[0]:.6f}, {gt_position[1]:.6f}, {gt_position[2]:.6f}]")
    print(f"   è¯¯å·®: {error:.6f} ç±³ = {error*1000:.2f} æ¯«ç±³")
    print(f"{'='*70}\n")
    
    # ğŸ”¥ ä¿å­˜å¯è§†åŒ–ç»“æœ
    if save_dir is not None:
        save_dir = Path(save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # ğŸ”¥ æ–¹æ³• 1: ä½¿ç”¨è‡ªå®šä¹‰å›è°ƒä¿å­˜å›¾ç‰‡ï¼ˆé€‚åˆæ— å¤´æœåŠ¡å™¨ï¼‰
        print("ğŸ“¸ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾ç‰‡...")
        
        img_path = save_dir / f"{patch_name}_visualization.png"
        
        def capture_image(vis):
            """å›è°ƒå‡½æ•°ï¼šæ¸²æŸ“åä¿å­˜å›¾ç‰‡"""
            # è®¾ç½®ç›¸æœºå‚æ•°
            ctr = vis.get_view_control()
            if ctr is not None:
                # è®¾ç½®è§†è§’
                ctr.set_front([0.5, 0.5, 0.5])
                ctr.set_lookat(pcd_center.tolist())
                ctr.set_up([0, 0, 1])
                ctr.set_zoom(0.8)
            
            # ä¿å­˜å›¾ç‰‡
            vis.capture_screen_image(str(img_path), do_render=True)
            return False  # è¿”å› False å…³é—­çª—å£
        
        try:
            # å°è¯•ä½¿ç”¨å¯è§†åŒ–çª—å£ä¿å­˜
            o3d.visualization.draw_geometries_with_animation_callback(
                geometries,
                capture_image,
                window_name=window_title,
                width=1920,
                height=1080
            )
            print(f"âœ… å›¾ç‰‡å·²ä¿å­˜: {img_path}")
        except Exception as e:
            print(f"âš ï¸  ç¦»å±æ¸²æŸ“å¤±è´¥: {e}")
            print("   ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥ä¿å­˜ç‚¹äº‘...")
        
        # ğŸ”¥ æ–¹æ³• 2: ä¿å­˜ä¸º PLY æ–‡ä»¶ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼Œæ€»æ˜¯å¯ç”¨ï¼‰
        print("ğŸ’¾ ä¿å­˜ä¸º PLY æ–‡ä»¶...")
        
        # åˆå¹¶æ‰€æœ‰å‡ ä½•ä½“åˆ°ä¸€ä¸ªç‚¹äº‘
        combined_pcd = o3d.geometry.PointCloud()
        
        # å®Œæ•´ç‚¹äº‘ï¼ˆç°è‰²ï¼‰
        combined_pcd += complete_pcd
        
        # å±€éƒ¨ç‚¹äº‘ï¼ˆæ©™è‰²ï¼‰
        combined_pcd += patch_pcd
        
        # GT çƒä½“ï¼ˆè“è‰²ï¼‰- é‡‡æ ·ä¸ºç‚¹äº‘
        gt_sphere_pcd = gt_sphere.sample_points_uniformly(number_of_points=1000)
        combined_pcd += gt_sphere_pcd
        
        # é¢„æµ‹çƒä½“ï¼ˆçº¢è‰²ï¼‰- é‡‡æ ·ä¸ºç‚¹äº‘
        pred_sphere_pcd = pred_sphere.sample_points_uniformly(number_of_points=1000)
        combined_pcd += pred_sphere_pcd
        
        ply_path = save_dir / f"{patch_name}_visualization.ply"
        o3d.io.write_point_cloud(str(ply_path), combined_pcd)
        print(f"âœ… PLY æ–‡ä»¶å·²ä¿å­˜: {ply_path}")
        print(f"   å¯ä»¥ç”¨ MeshLab/CloudCompare æ‰“å¼€æŸ¥çœ‹")
        
        # ä¿å­˜é¢„æµ‹ç»“æœåˆ° JSON
        result = {
            'patch_name': patch_name,
            'pred_position': pred_position.tolist(),
            'gt_position': gt_position.tolist(),
            'error_meters': float(error),
            'error_mm': float(error * 1000),
            'complete_model': str(complete_model_path),
        }
        json_path = save_dir / f"{patch_name}_result.json"
        import json
        with open(json_path, 'w') as f:
            json.dump(result, f, indent=2)
        print(f"âœ… ç»“æœå·²ä¿å­˜: {json_path}")
        
        # ğŸ”¥ æ–¹æ³• 3: ä½¿ç”¨ matplotlib ç”Ÿæˆ 2D æŠ•å½±å›¾ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        try:
            import matplotlib.pyplot as plt
            from mpl_toolkits.mplot3d import Axes3D
            
            fig = plt.figure(figsize=(15, 5))
            
            # ä¸‰ä¸ªè§†è§’
            views = [
                (0, 90, "Top View (XY)"),      # ä¿¯è§†å›¾
                (0, 0, "Front View (XZ)"),     # æ­£è§†å›¾
                (90, 90, "Side View (YZ)")     # ä¾§è§†å›¾
            ]
            
            for i, (elev, azim, title) in enumerate(views):
                ax = fig.add_subplot(1, 3, i+1, projection='3d')
                
                # ç»˜åˆ¶å®Œæ•´ç‚¹äº‘ï¼ˆç°è‰²ï¼Œé‡‡æ ·ä»¥å‡å°‘ç‚¹æ•°ï¼‰
                sample_idx = np.random.choice(len(complete_points), 
                                             min(5000, len(complete_points)), 
                                             replace=False)
                ax.scatter(complete_points[sample_idx, 0], 
                          complete_points[sample_idx, 1], 
                          complete_points[sample_idx, 2],
                          c='gray', s=0.1, alpha=0.3, label='Complete Model')
                
                # ç»˜åˆ¶å±€éƒ¨ç‚¹äº‘ï¼ˆæ©™è‰²ï¼‰
                ax.scatter(coord[:, 0], coord[:, 1], coord[:, 2],
                          c='orange', s=5, alpha=0.8, label='Local Patch')
                
                # ç»˜åˆ¶ GT ä½ç½®ï¼ˆè“è‰²å¤§ç‚¹ï¼‰
                ax.scatter(gt_position[0], gt_position[1], gt_position[2],
                          c='blue', s=200, marker='o', label='GT Position', 
                          edgecolors='black', linewidths=2)
                
                # ç»˜åˆ¶é¢„æµ‹ä½ç½®ï¼ˆçº¢è‰²å¤§ç‚¹ï¼‰
                ax.scatter(pred_position[0], pred_position[1], pred_position[2],
                          c='red', s=200, marker='o', label='Predicted Position',
                          edgecolors='black', linewidths=2)
                
                # ç»˜åˆ¶è¿æ¥çº¿
                ax.plot([gt_position[0], pred_position[0]],
                       [gt_position[1], pred_position[1]],
                       [gt_position[2], pred_position[2]],
                       'y-', linewidth=2, label='Error Line')
                
                ax.set_xlabel('X')
                ax.set_ylabel('Y')
                ax.set_zlabel('Z')
                ax.set_title(f"{title}\nError: {error*1000:.2f} mm")
                ax.view_init(elev=elev, azim=azim)
                
                if i == 0:
                    ax.legend(fontsize=8, loc='upper right')
            
            plt.suptitle(f"Contact Point Prediction - {patch_name}", fontsize=14)
            plt.tight_layout()
            
            # ä¿å­˜ matplotlib å›¾ç‰‡
            plt_path = save_dir / f"{patch_name}_matplotlib.png"
            plt.savefig(plt_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"âœ… Matplotlib å›¾ç‰‡å·²ä¿å­˜: {plt_path}")
        except Exception as e:
            print(f"âš ï¸  Matplotlib æ¸²æŸ“å¤±è´¥: {e}")
    
    # æ˜¾ç¤ºçª—å£ï¼ˆå¯é€‰ï¼‰
    if show_window:
        try:
            o3d.visualization.draw_geometries(
                geometries,
                window_name=window_title,
                width=1920,
                height=1080,
                point_show_normal=False
            )
        except Exception as e:
            print(f"âš ï¸  æ— æ³•æ˜¾ç¤ºçª—å£: {e}")

def visualize_with_complete_model(
    patch_data: Dict[str, torch.Tensor],
    pred_position: np.ndarray,
    gt_position: np.ndarray,
    complete_model_path: Path,
    patch_name: str = "",
    window_title: str = "æ¥è§¦ç‚¹åœ¨å®Œæ•´æ¨¡å‹ä¸Šçš„ä½ç½®"
):
    """
    åœ¨å®Œæ•´ç‚¹äº‘æ¨¡å‹ä¸Šå¯è§†åŒ–é¢„æµ‹ç»“æœ
    
    Args:
        patch_data: å°ç‚¹äº‘æ•°æ®
        pred_position: é¢„æµ‹çš„æ¥è§¦ç‚¹ä½ç½® (3,) numpy
        gt_position: çœŸå®çš„æ¥è§¦ç‚¹ä½ç½® (3,) numpy
        complete_model_path: å®Œæ•´ç‚¹äº‘æ¨¡å‹è·¯å¾„ï¼ˆ.ply/.pcdï¼‰
        patch_name: æ ·æœ¬åç§°
        window_title: çª—å£æ ‡é¢˜
    """
    geometries = []
    
    # åŠ è½½å®Œæ•´ç‚¹äº‘æ¨¡å‹
    if complete_model_path.exists():
        print(f"ğŸ“‚ åŠ è½½å®Œæ•´æ¨¡å‹: {complete_model_path}")
        complete_pcd = o3d.io.read_point_cloud(str(complete_model_path))
        complete_pcd.paint_uniform_color([0.8, 0.8, 0.8])  # æµ…ç°è‰²
        geometries.append(complete_pcd)
        
        # è®¡ç®—ç‚¹äº‘å°ºå¯¸
        points = np.asarray(complete_pcd.points)
        pcd_min = points.min(axis=0)
        pcd_max = points.max(axis=0)
        pcd_size = np.linalg.norm(pcd_max - pcd_min)
    else:
        print(f"âš ï¸  å®Œæ•´æ¨¡å‹ä¸å­˜åœ¨: {complete_model_path}")
        # ğŸ”¥ ä¿®å¤ï¼šç»Ÿä¸€è½¬æ¢ä¸º numpy
        coord = patch_data['coord']
        if isinstance(coord, torch.Tensor):
            coord = coord.cpu().numpy()
        else:
            coord = np.array(coord)
        
        patch_pcd = o3d.geometry.PointCloud()
        patch_pcd.points = o3d.utility.Vector3dVector(coord)
        patch_pcd.paint_uniform_color([0.7, 0.7, 0.7])
        geometries.append(patch_pcd)
        
        pcd_min = coord.min(axis=0)
        pcd_max = coord.max(axis=0)
        pcd_size = np.linalg.norm(pcd_max - pcd_min)
    
    # åˆ›å»ºé¢„æµ‹ä½ç½®æ ‡è®°ï¼ˆçº¢è‰²çƒä½“ï¼‰
    sphere_radius = pcd_size * 0.015
    pred_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=sphere_radius)
    pred_sphere.translate(pred_position)
    pred_sphere.paint_uniform_color([1, 0, 0])  # çº¢è‰²
    geometries.append(pred_sphere)
    
    # åˆ›å»º GT ä½ç½®æ ‡è®°ï¼ˆè“è‰²çƒä½“ï¼‰
    gt_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=sphere_radius)
    gt_sphere.translate(gt_position)
    gt_sphere.paint_uniform_color([0, 0, 1])  # è“è‰²
    geometries.append(gt_sphere)
    
    # åˆ›å»ºè¿æ¥çº¿
    line_set = o3d.geometry.LineSet()
    line_set.points = o3d.utility.Vector3dVector(np.array([pred_position, gt_position]))
    line_set.lines = o3d.utility.Vector2iVector([[0, 1]])
    line_set.colors = o3d.utility.Vector3dVector([[1, 0.5, 0]])  # æ©™è‰²
    geometries.append(line_set)
    
    # åˆ›å»ºåæ ‡ç³»
    coord_size = pcd_size * 0.08
    coord_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(
        size=coord_size, 
        origin=[0, 0, 0]
    )
    geometries.append(coord_frame)
    
    # è®¡ç®—è¯¯å·®
    error = np.linalg.norm(pred_position - gt_position)
    
    # æ‰“å°ä¿¡æ¯
    print(f"\nğŸ¨ å®Œæ•´æ¨¡å‹å¯è§†åŒ– ({patch_name}):")
    print(f"   ğŸŸ¦ è“è‰²çƒä½“ = GT æ¥è§¦ç‚¹")
    print(f"   ğŸŸ¥ çº¢è‰²çƒä½“ = é¢„æµ‹æ¥è§¦ç‚¹")
    print(f"   â¬œ ç°è‰²ç‚¹äº‘ = å®Œæ•´æ¨¡å‹")
    print(f"   è¯¯å·®: {error:.6f} ç±³ = {error*1000:.2f} æ¯«ç±³")
    
    # å¯è§†åŒ–
    o3d.visualization.draw_geometries(
        geometries,
        window_name=window_title,
        width=1280,
        height=720,
        point_show_normal=False
    )


def test_single_sample(
    matcher: PTv3ContactMatcher,
    patch_path: Path,
    complete_model_path: Path,
    visualize: bool = True,
    save_result: bool = True,  # ğŸ”¥ é»˜è®¤ä¿å­˜
    save_dir: Path = Path("inference_results"),  # ğŸ”¥ ä¿å­˜ç›®å½•
    show_window: bool = False  # ğŸ”¥ è¿œç¨‹æœåŠ¡å™¨ä¸æ˜¾ç¤ºçª—å£
):
    """
    æµ‹è¯•å•ä¸ªæ ·æœ¬
    
    Args:
        matcher: PTv3ContactMatcher å®ä¾‹
        patch_path: å±€éƒ¨ç‚¹äº‘æ–‡ä»¶è·¯å¾„ (.pth)
        complete_model_path: å®Œæ•´ç‚¹äº‘æ¨¡å‹è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
        visualize: æ˜¯å¦ç”Ÿæˆå¯è§†åŒ–
        save_result: æ˜¯å¦ä¿å­˜ç»“æœ
        save_dir: ä¿å­˜ç›®å½•
        show_window: æ˜¯å¦æ˜¾ç¤ºçª—å£ï¼ˆè¿œç¨‹æœåŠ¡å™¨è®¾ä¸º Falseï¼‰
    """
    print(f"\n{'='*70}")
    print(f"ğŸ§ª æµ‹è¯•æ ·æœ¬: {patch_path}")
    print(f"{'='*70}")
    
    # æ£€æŸ¥å®Œæ•´æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if not complete_model_path.exists():
        raise FileNotFoundError(f"å®Œæ•´ç‚¹äº‘æ¨¡å‹ä¸å­˜åœ¨: {complete_model_path}")
    
    # åŠ è½½æ•°æ®
    patch_data = load_patch_data(patch_path, verbose=True)
    
    # ç»Ÿä¸€è½¬æ¢ä¸º numpy
    coord = patch_data['coord']
    if isinstance(coord, torch.Tensor):
        coord_np = coord.cpu().numpy()
    else:
        coord_np = np.array(coord)
    
    gt_position = patch_data['gt_position']
    if isinstance(gt_position, torch.Tensor):
        gt_position = gt_position.cpu().numpy()
    else:
        gt_position = np.array(gt_position)
    
    patch_name = patch_data.get('name', patch_path.stem)
    category_id = patch_data.get('category_id', None)
    
    print(f"\nğŸ“‚ å±€éƒ¨ç‚¹äº‘:")
    print(f"   åç§°: {patch_name}")
    print(f"   ç‚¹æ•°: {len(coord_np)}")
    print(f"   GT ä½ç½®: {gt_position}")
    if category_id is not None:
        if isinstance(category_id, torch.Tensor):
            cat_id_value = category_id.item() if category_id.dim() == 0 else category_id[0].item()
        else:
            cat_id_value = int(category_id)
        print(f"   ç±»åˆ« ID: {cat_id_value}")
    
    # é¢„æµ‹
    print(f"\nğŸ”® æ­£åœ¨é¢„æµ‹...")
    try:
        pred_position = matcher.predict(patch_data)
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    # è®¡ç®—è¯¯å·®
    error = np.linalg.norm(pred_position - gt_position)
    
    print(f"\nğŸ“Š é¢„æµ‹ç»“æœ:")
    print(f"   é¢„æµ‹ä½ç½®: [{pred_position[0]:.6f}, {pred_position[1]:.6f}, {pred_position[2]:.6f}]")
    print(f"   GT ä½ç½®:   [{gt_position[0]:.6f}, {gt_position[1]:.6f}, {gt_position[2]:.6f}]")
    print(f"   è¯¯å·®: {error:.6f} ç±³ = {error*1000:.2f} æ¯«ç±³")
    
    # å¯è§†åŒ–å¹¶ä¿å­˜
    if visualize:
        print(f"\nğŸ“º ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
        visualize_prediction(
            patch_data,
            pred_position,
            gt_position,
            complete_model_path,
            patch_name=patch_name,
            window_title=f"æ¥è§¦ç‚¹é¢„æµ‹ - {patch_name}",
            save_dir=save_dir if save_result else None,
            show_window=show_window
        )
    
    print(f"{'='*70}\n")
    
    return error


def test_dataset(
    matcher: PTv3ContactMatcher,
    dataset_dir: Path,
    category: str = "Scissors",
    num_samples: int = 5,
    complete_model_path: Optional[Path] = None,
    visualize_samples: bool = False
):
    """
    æµ‹è¯•æ•°æ®é›†ä¸­çš„å¤šä¸ªæ ·æœ¬
    
    Args:
        matcher: PTv3ContactMatcher å®ä¾‹
        dataset_dir: æ•°æ®é›†ç›®å½•
        category: ç±»åˆ«åç§°
        num_samples: æµ‹è¯•æ ·æœ¬æ•°é‡
        complete_model_path: å®Œæ•´ç‚¹äº‘æ¨¡å‹è·¯å¾„
        visualize_samples: æ˜¯å¦å¯è§†åŒ–æ¯ä¸ªæ ·æœ¬
    """
    category_dir = dataset_dir / category / "patches"
    
    if not category_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {category_dir}")
        return
    
    # è·å–æ‰€æœ‰ patch æ–‡ä»¶
    patch_files = sorted(category_dir.glob("*.pth"))
    
    if not patch_files:
        print(f"âŒ ç›®å½•ä¸­æ²¡æœ‰ .pth æ–‡ä»¶: {category_dir}")
        return
    
    print(f"\n{'='*70}")
    print(f"ğŸ“Š æ•°æ®é›†æ‰¹é‡æµ‹è¯•")
    print(f"{'='*70}")
    print(f"   ç›®å½•: {category_dir}")
    print(f"   æ€»æ ·æœ¬æ•°: {len(patch_files)}")
    print(f"   æµ‹è¯•æ ·æœ¬æ•°: {min(num_samples, len(patch_files))}")
    
    # éšæœºé€‰æ‹©æ ·æœ¬
    import random
    test_files = random.sample(patch_files, min(num_samples, len(patch_files)))
    
    errors = []
    
    for i, patch_path in enumerate(test_files):
        print(f"\n{'-'*70}")
        print(f"æ ·æœ¬ {i+1}/{len(test_files)}: {patch_path.name}")
        print(f"{'-'*70}")
        
        # åŠ è½½æ•°æ®
        patch_data = load_patch_data(patch_path)
        patch_name = patch_data.get('name', patch_path.stem)
        
        # é¢„æµ‹
        pred_position = matcher.predict(patch_data)
        
        # ğŸ”¥ ä¿®å¤ï¼šgt_position å¯èƒ½æ˜¯ Tensor æˆ– ndarray
        gt_position = patch_data['gt_position']
        if isinstance(gt_position, torch.Tensor):
            gt_position = gt_position.cpu().numpy()
        else:
            gt_position = np.array(gt_position)
        
        # è®¡ç®—è¯¯å·®
        error = np.linalg.norm(pred_position - gt_position)
        errors.append(error)
        
        print(f"   åç§°: {patch_name}")
        print(f"   é¢„æµ‹: [{pred_position[0]:.6f}, {pred_position[1]:.6f}, {pred_position[2]:.6f}]")
        print(f"   GT:   [{gt_position[0]:.6f}, {gt_position[1]:.6f}, {gt_position[2]:.6f}]")
        print(f"   è¯¯å·®: {error*1000:.2f} mm")
        
        # å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
        if visualize_samples:
            visualize_prediction(
                patch_data,
                pred_position,
                gt_position,
                patch_name=patch_name,
                window_title=f"æ ·æœ¬ {i+1}/{len(test_files)}: {patch_name}"
            )
    
    # ç»Ÿè®¡
    errors = np.array(errors)
    print(f"\n{'='*70}")
    print(f"ğŸ“ˆ ç»Ÿè®¡ç»“æœ")
    print(f"{'='*70}")
    print(f"   å¹³å‡è¯¯å·®: {errors.mean()*1000:.2f} mm")
    print(f"   ä¸­ä½æ•°è¯¯å·®: {np.median(errors)*1000:.2f} mm")
    print(f"   æ ‡å‡†å·®: {errors.std()*1000:.2f} mm")
    print(f"   æœ€å¤§è¯¯å·®: {errors.max()*1000:.2f} mm")
    print(f"   æœ€å°è¯¯å·®: {errors.min()*1000:.2f} mm")
    print(f"{'='*70}\n")


def test_all_patches(
    matcher: PTv3ContactMatcher,
    dataset_dir: Path,
    category: str = "Scissors",
    save_dir: Path = Path("inference_results"),
    visualize_best_worst_median: bool = True,
):
    """
    æµ‹è¯•æ•°æ®é›†ä¸­çš„æ‰€æœ‰æ ·æœ¬ï¼Œå¹¶ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    """
    print(f"\n{'='*80}")
    print(f"ğŸš€ æ‰¹é‡æµ‹è¯•æ‰€æœ‰ç‚¹äº‘")
    print(f"{'='*80}")
    
    # 1. æŸ¥æ‰¾æ‰€æœ‰ patch æ–‡ä»¶
    category_dir = dataset_dir / category / "patches"
    
    if not category_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {category_dir}")
        return
    
    patch_files = sorted(category_dir.glob("*.pth"))
    
    if not patch_files:
        print(f"âŒ ç›®å½•ä¸­æ²¡æœ‰ .pth æ–‡ä»¶: {category_dir}")
        return
    
    print(f"ğŸ“‚ æ•°æ®é›†ç›®å½•: {category_dir}")
    print(f"ğŸ“Š æ‰¾åˆ° {len(patch_files)} ä¸ªå°ç‚¹äº‘")
    
    # 2. æŸ¥æ‰¾æ‰€æœ‰å®Œæ•´ç‚¹äº‘æ–‡ä»¶
    complete_model_dir = dataset_dir / category
    complete_models = {}
    
    for ply_file in sorted(complete_model_dir.glob("bigpointcloud_*.ply")):
        model_id = ply_file.stem.split('_')[-1]
        complete_models[model_id] = ply_file
    
    num_bigpcds = len(complete_models)
    print(f"ğŸ“‚ æ‰¾åˆ° {num_bigpcds} ä¸ªå¤§ç‚¹äº‘")
    if complete_models:
        print(f"   æ¨¡å‹ ID: {list(complete_models.keys())}")
    
    # ğŸ”¥ 3. è‡ªåŠ¨è®¡ç®—æ¯ä¸ªå¤§ç‚¹äº‘å¯¹åº”çš„å°ç‚¹äº‘æ•°é‡
    if num_bigpcds == 0:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°å¤§ç‚¹äº‘æ–‡ä»¶")
        return
    
    samples_per_bigpcd = len(patch_files) // num_bigpcds
    
    print(f"\nğŸ’¡ è‡ªåŠ¨æ¨æ–­:")
    print(f"   æ€»å°ç‚¹äº‘æ•°: {len(patch_files)}")
    print(f"   æ€»å¤§ç‚¹äº‘æ•°: {num_bigpcds}")
    print(f"   æ¯ä¸ªå¤§ç‚¹äº‘å¯¹åº”: {samples_per_bigpcd} ä¸ªå°ç‚¹äº‘")
    
    # éªŒè¯æ˜¯å¦æ•´é™¤
    if len(patch_files) % num_bigpcds != 0:
        print(f"   âš ï¸  è­¦å‘Šï¼š{len(patch_files)} ä¸èƒ½è¢« {num_bigpcds} æ•´é™¤")
        print(f"   å¯èƒ½æœ‰éƒ¨åˆ†å¤§ç‚¹äº‘çš„å°ç‚¹äº‘æ•°é‡ä¸åŒ")
    
    # 4. æ‰“å°æ˜ å°„å…³ç³»
    print(f"\nğŸ“‹ æ¨æ–­çš„æ˜ å°„å…³ç³»:")
    for i, (model_id, model_path) in enumerate(sorted(complete_models.items())):
        start_idx = i * samples_per_bigpcd
        end_idx = start_idx + samples_per_bigpcd - 1
        print(f"   bigpointcloud_{model_id}.ply â†’ patch_{start_idx:06d} ~ patch_{end_idx:06d}")
    
    # 5. åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    batch_dir = save_dir / f"batch_{category}_{len(patch_files)}_samples"
    batch_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ’¾ ç»“æœä¿å­˜ç›®å½•: {batch_dir}")
    
    # 6. é€ä¸ªæµ‹è¯•
    results = []
    failed_samples = []
    
    print(f"\n{'='*80}")
    print(f"ğŸ”® å¼€å§‹æ‰¹é‡æ¨ç†...")
    print(f"{'='*80}\n")
    
    for i, patch_path in enumerate(patch_files):
        print(f"[{i+1}/{len(patch_files)}] å¤„ç†: {patch_path.name}")
        
        try:
            # åŠ è½½æ•°æ®
            patch_data = load_patch_data(patch_path, verbose=False)
            patch_name = patch_data.get('name', patch_path.stem)
            
            # ğŸ”¥ æ–¹æ³• 1: ä»æ•°æ®ä¸­è¯»å–ï¼ˆæœ€å‡†ç¡®ï¼‰
            complete_model_path = None
            parent_id = None
            
            if 'bigpcd_id' in patch_data:
                bigpcd_id = patch_data['bigpcd_id']
                if isinstance(bigpcd_id, torch.Tensor):
                    bigpcd_id = bigpcd_id.item()
                parent_id = f"{int(bigpcd_id):03d}"
                complete_model_path = complete_models.get(parent_id)
                print(f"   ğŸ“‚ ä»æ•°æ®è¯»å–: bigpcd_id={bigpcd_id} â†’ bigpointcloud_{parent_id}.ply")
            
            # ğŸ”¥ æ–¹æ³• 2: ä»æ–‡ä»¶åæ¨æ–­ï¼ˆä½¿ç”¨æ ·æœ¬ IDï¼‰
            else:
                sample_id = extract_sample_id_from_patch_name(patch_path.name)
                if sample_id is not None:
                    # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨å®é™…è®¡ç®—çš„ samples_per_bigpcd
                    parent_id = get_parent_model_from_sample_id(sample_id, samples_per_bigpcd)
                    complete_model_path = complete_models.get(parent_id)
                    print(f"   ğŸ“‚ ä»æ ·æœ¬ ID æ¨æ–­: sample_id={sample_id} â†’ parent_id={parent_id}")
            
            # ğŸ”¥ æ–¹æ³• 3: ä½¿ç”¨ç¬¬ä¸€ä¸ªï¼ˆå¤‡ç”¨ï¼‰
            if complete_model_path is None or not complete_model_path.exists():
                if complete_models:
                    complete_model_path = list(complete_models.values())[0]
                    parent_id = complete_model_path.stem.split('_')[-1]
                    print(f"   âš ï¸  ä½¿ç”¨é»˜è®¤: {complete_model_path.name}")
                else:
                    print(f"   âŒ æ‰¾ä¸åˆ°å®Œæ•´ç‚¹äº‘æ¨¡å‹ï¼Œè·³è¿‡")
                    failed_samples.append({
                        'patch_name': patch_name,
                        'reason': 'No complete model found'
                    })
                    continue
            
            # é¢„æµ‹
            pred_position = matcher.predict(patch_data)
            
            # GT ä½ç½®
            gt_position = patch_data['gt_position']
            if isinstance(gt_position, torch.Tensor):
                gt_position = gt_position.cpu().numpy()
            else:
                gt_position = np.array(gt_position)
            
            # è®¡ç®—è¯¯å·®
            error = np.linalg.norm(pred_position - gt_position)
            
            # ä¿å­˜ç»“æœ
            result = {
                'index': i,
                'patch_name': patch_name,
                'patch_path': str(patch_path),
                'complete_model_path': str(complete_model_path),
                'complete_model_name': complete_model_path.name,
                'parent_id': parent_id,
                'pred_position': pred_position.tolist(),
                'gt_position': gt_position.tolist(),
                'error_meters': float(error),
                'error_mm': float(error * 1000),
                'patch_data': patch_data,
            }
            results.append(result)
            
            print(f"   âœ… è¯¯å·®: {error*1000:.2f} mm | çˆ¶ç‚¹äº‘: bigpointcloud_{parent_id}.ply")
            
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            failed_samples.append({
                'patch_name': patch_path.name,
                'reason': str(e)
            })
    
    # 5. ç»Ÿè®¡åˆ†æ
    print(f"\n{'='*80}")
    print(f"ğŸ“ˆ ç»Ÿè®¡åˆ†æ")
    print(f"{'='*80}")
    
    if not results:
        print("âŒ æ²¡æœ‰æˆåŠŸçš„æ ·æœ¬ï¼")
        return
    
    errors = np.array([r['error_mm'] for r in results])
    
    print(f"æ€»æ ·æœ¬æ•°: {len(patch_files)}")
    print(f"æˆåŠŸæ ·æœ¬æ•°: {len(results)}")
    print(f"å¤±è´¥æ ·æœ¬æ•°: {len(failed_samples)}")
    print(f"\nè¯¯å·®ç»Ÿè®¡ (æ¯«ç±³):")
    print(f"  å¹³å‡å€¼:   {errors.mean():.2f} mm")
    print(f"  ä¸­ä½æ•°:   {np.median(errors):.2f} mm")
    print(f"  æ ‡å‡†å·®:   {errors.std():.2f} mm")
    print(f"  æœ€å°å€¼:   {errors.min():.2f} mm")
    print(f"  æœ€å¤§å€¼:   {errors.max():.2f} mm")
    print(f"  25% åˆ†ä½: {np.percentile(errors, 25):.2f} mm")
    print(f"  75% åˆ†ä½: {np.percentile(errors, 75):.2f} mm")
    
    # 6. æ‰¾å‡ºæœ€å¥½ã€æœ€å·®ã€ä¸­ä½æ•°æ ·æœ¬
    best_idx = np.argmin(errors)
    worst_idx = np.argmax(errors)
    median_idx = np.argmin(np.abs(errors - np.median(errors)))
    
    best_sample = results[best_idx]
    worst_sample = results[worst_idx]
    median_sample = results[median_idx]
    
    print(f"\nğŸ† æœ€ä½³æ ·æœ¬ (æœ€å°è¯¯å·®):")
    print(f"  åç§°: {best_sample['patch_name']}")
    print(f"  è¯¯å·®: {best_sample['error_mm']:.2f} mm")
    
    print(f"\nğŸ“‰ æœ€å·®æ ·æœ¬ (æœ€å¤§è¯¯å·®):")
    print(f"  åç§°: {worst_sample['patch_name']}")
    print(f"  è¯¯å·®: {worst_sample['error_mm']:.2f} mm")
    
    print(f"\nğŸ“Š ä¸­ä½æ•°æ ·æœ¬:")
    print(f"  åç§°: {median_sample['patch_name']}")
    print(f"  è¯¯å·®: {median_sample['error_mm']:.2f} mm")
    
    # 7. ä¿å­˜ç»Ÿè®¡ç»“æœåˆ° JSON
    summary = {
        'category': category,
        'total_samples': len(patch_files),
        'successful_samples': len(results),
        'failed_samples': len(failed_samples),
        'statistics': {
            'mean_error_mm': float(errors.mean()),
            'median_error_mm': float(np.median(errors)),
            'std_error_mm': float(errors.std()),
            'min_error_mm': float(errors.min()),
            'max_error_mm': float(errors.max()),
            'percentile_25_mm': float(np.percentile(errors, 25)),
            'percentile_75_mm': float(np.percentile(errors, 75)),
        },
        'best_sample': {
            'name': best_sample['patch_name'],
            'error_mm': best_sample['error_mm'],
            'pred_position': best_sample['pred_position'],
            'gt_position': best_sample['gt_position'],
        },
        'worst_sample': {
            'name': worst_sample['patch_name'],
            'error_mm': worst_sample['error_mm'],
            'pred_position': worst_sample['pred_position'],
            'gt_position': worst_sample['gt_position'],
        },
        'median_sample': {
            'name': median_sample['patch_name'],
            'error_mm': median_sample['error_mm'],
            'pred_position': median_sample['pred_position'],
            'gt_position': median_sample['gt_position'],
        },
        'failed_samples': failed_samples,
    }
    
    summary_path = batch_dir / "summary.json"
    import json
    with open(summary_path, 'w') as f:
        json.dump(summary, f, indent=2)
    print(f"\nâœ… ç»Ÿè®¡ç»“æœå·²ä¿å­˜: {summary_path}")
    
    # 8. ä¿å­˜æ‰€æœ‰ç»“æœåˆ° CSV
    import csv
    csv_path = batch_dir / "all_results.csv"
    with open(csv_path, 'w', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=[
            'index', 'patch_name', 'parent_id', 'complete_model_name',  # ğŸ”¥ æ·»åŠ  parent_id
            'pred_x', 'pred_y', 'pred_z',
            'gt_x', 'gt_y', 'gt_z',
            'error_mm'
        ])
        writer.writeheader()
        for r in results:
            writer.writerow({
                'index': r['index'],
                'patch_name': r['patch_name'],
                'parent_id': r['parent_id'],  # ğŸ”¥ æ·»åŠ è¿™ä¸€åˆ—
                'complete_model_name': r['complete_model_name'],
                'pred_x': r['pred_position'][0],
                'pred_y': r['pred_position'][1],
                'pred_z': r['pred_position'][2],
                'gt_x': r['gt_position'][0],
                'gt_y': r['gt_position'][1],
                'gt_z': r['gt_position'][2],
                'error_mm': r['error_mm'],
            })
    print(f"âœ… è¯¦ç»†ç»“æœå·²ä¿å­˜: {csv_path}")
    
    # 9. ç”Ÿæˆè¯¯å·®åˆ†å¸ƒå›¾
    try:
        import matplotlib.pyplot as plt
        import matplotlib
        matplotlib.use('Agg')
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 9.1 è¯¯å·®ç›´æ–¹å›¾
        ax = axes[0, 0]
        ax.hist(errors, bins=50, color='skyblue', edgecolor='black', alpha=0.7)
        ax.axvline(errors.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {errors.mean():.2f} mm')
        ax.axvline(np.median(errors), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(errors):.2f} mm')
        ax.set_xlabel('Error (mm)', fontsize=12)
        ax.set_ylabel('Frequency', fontsize=12)
        ax.set_title('Error Distribution', fontsize=14)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 9.2 è¯¯å·®ç®±çº¿å›¾
        ax = axes[0, 1]
        bp = ax.boxplot(errors, vert=True, patch_artist=True)
        bp['boxes'][0].set_facecolor('lightblue')
        ax.set_ylabel('Error (mm)', fontsize=12)
        ax.set_title('Error Boxplot', fontsize=14)
        ax.grid(True, alpha=0.3)
        
        # 9.3 è¯¯å·®éšæ ·æœ¬å˜åŒ–
        ax = axes[1, 0]
        ax.plot(range(len(errors)), errors, 'o-', markersize=2, linewidth=0.5, alpha=0.6)
        ax.axhline(errors.mean(), color='red', linestyle='--', linewidth=2, label='Mean')
        ax.axhline(np.median(errors), color='green', linestyle='--', linewidth=2, label='Median')
        ax.set_xlabel('Sample Index', fontsize=12)
        ax.set_ylabel('Error (mm)', fontsize=12)
        ax.set_title('Error vs Sample Index', fontsize=14)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 9.4 ç´¯ç§¯åˆ†å¸ƒå‡½æ•°
        ax = axes[1, 1]
        sorted_errors = np.sort(errors)
        cumulative = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)
        ax.plot(sorted_errors, cumulative, linewidth=2)
        ax.axvline(errors.mean(), color='red', linestyle='--', linewidth=2, label='Mean')
        ax.axvline(np.median(errors), color='green', linestyle='--', linewidth=2, label='Median')
        ax.set_xlabel('Error (mm)', fontsize=12)
        ax.set_ylabel('Cumulative Probability', fontsize=12)
        ax.set_title('Cumulative Distribution Function', fontsize=14)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'Error Analysis - {category} ({len(results)} samples)', fontsize=16)
        plt.tight_layout()
        
        plot_path = batch_dir / "error_analysis.png"
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… è¯¯å·®åˆ†æå›¾å·²ä¿å­˜: {plot_path}")
    except Exception as e:
        print(f"âš ï¸  ç”Ÿæˆè¯¯å·®åˆ†æå›¾å¤±è´¥: {e}")
    
    # 10. å¯è§†åŒ–æœ€å¥½ã€æœ€å·®ã€ä¸­ä½æ•°æ ·æœ¬
    if visualize_best_worst_median:
        print(f"\n{'='*80}")
        print(f"ğŸ¨ ç”Ÿæˆä»£è¡¨æ€§æ ·æœ¬çš„å¯è§†åŒ–")
        print(f"{'='*80}\n")
        
        samples_to_visualize = [
            (best_sample, "best", "ğŸ† æœ€ä½³æ ·æœ¬"),
            (median_sample, "median", "ğŸ“Š ä¸­ä½æ•°æ ·æœ¬"),
            (worst_sample, "worst", "ğŸ“‰ æœ€å·®æ ·æœ¬"),
        ]
        
        for sample, label, title in samples_to_visualize:
            print(f"\n{title}: {sample['patch_name']} (è¯¯å·®: {sample['error_mm']:.2f} mm)")
            
            try:
                visualize_prediction(
                    sample['patch_data'],
                    np.array(sample['pred_position']),
                    np.array(sample['gt_position']),
                    Path(sample['complete_model_path']),
                    patch_name=f"{label}_{sample['patch_name']}",
                    window_title=f"{title} - {sample['patch_name']}",
                    save_dir=batch_dir,
                    show_window=False
                )
            except Exception as e:
                print(f"   âš ï¸  å¯è§†åŒ–å¤±è´¥: {e}")
    
    print(f"\n{'='*80}")
    print(f"âœ… æ‰¹é‡æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*80}")
    print(f"ğŸ“‚ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {batch_dir}")
    print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - summary.json           : ç»Ÿè®¡æ‘˜è¦")
    print(f"  - all_results.csv        : æ‰€æœ‰æ ·æœ¬çš„è¯¦ç»†ç»“æœ")
    print(f"  - error_analysis.png     : è¯¯å·®åˆ†æå›¾")
    print(f"  - best_*                 : æœ€ä½³æ ·æœ¬çš„å¯è§†åŒ–")
    print(f"  - median_*               : ä¸­ä½æ•°æ ·æœ¬çš„å¯è§†åŒ–")
    print(f"  - worst_*                : æœ€å·®æ ·æœ¬çš„å¯è§†åŒ–")
    print(f"{'='*80}\n")
    
    return results, summary

def main():
    parser = argparse.ArgumentParser(description='PTv3 Contact Position Regression æ¨ç†ä¸å¯è§†åŒ–')
    parser.add_argument('--config', type=str, 
                        default='configs/s3dis/semseg-pt-v3m1-gelsight.py',
                        help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--checkpoint', type=str,
                        default='exp/gelsight_test/model/model_best.pth',
                        help='æ¨¡å‹æƒé‡è·¯å¾„')
    
    # ğŸ”¥ ä¸¤ç§æ¨¡å¼ï¼šå•ä¸ªæ ·æœ¬ æˆ– æ‰¹é‡æµ‹è¯•
    parser.add_argument('--mode', type=str, 
                        choices=['single', 'batch'], 
                        default='single',
                        help='è¿è¡Œæ¨¡å¼ï¼šsingleï¼ˆå•ä¸ªæ ·æœ¬ï¼‰æˆ– batchï¼ˆæ‰¹é‡æµ‹è¯•ï¼‰')
    
    # å•ä¸ªæ ·æœ¬æ¨¡å¼å‚æ•°
    parser.add_argument('--patch', type=str,
                        help='å•ä¸ªå±€éƒ¨ç‚¹äº‘æ–‡ä»¶è·¯å¾„ (.pth)')
    parser.add_argument('--complete_model', type=str,
                        help='å®Œæ•´ç‚¹äº‘æ¨¡å‹è·¯å¾„ (.ply/.pcd)')
    
    # æ‰¹é‡æµ‹è¯•æ¨¡å¼å‚æ•°
    parser.add_argument('--dataset_dir', type=str,
                        default='../../touch_processed_data',
                        help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--category', type=str,
                        default='Scissors',
                        choices=['Scissors', 'Cup', 'Avocado'],
                        help='ç‰©ä½“ç±»åˆ«')
    
    # é€šç”¨å‚æ•°
    parser.add_argument('--save_dir', type=str,
                        default='inference_results',
                        help='ä¿å­˜ç»“æœçš„ç›®å½•')
    parser.add_argument('--no_vis', action='store_true',
                        help='ä¸ç”Ÿæˆå¯è§†åŒ–')
    parser.add_argument('--show_window', action='store_true',
                        help='æ˜¾ç¤ºçª—å£ï¼ˆæœ¬åœ°æœ‰æ˜¾ç¤ºå™¨æ—¶ä½¿ç”¨ï¼‰')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æ¨ç†å™¨
    print(f"\n{'='*80}")
    print(f"ğŸš€ åˆå§‹åŒ– PTv3 Contact Matcher")
    print(f"{'='*80}")
    
    matcher = PTv3ContactMatcher(
        config_path=args.config,
        checkpoint_path=args.checkpoint
    )
    
    if args.mode == 'single':
        # å•ä¸ªæ ·æœ¬æµ‹è¯•
        if not args.patch or not args.complete_model:
            parser.error("å•ä¸ªæ ·æœ¬æ¨¡å¼éœ€è¦ --patch å’Œ --complete_model å‚æ•°")
        
        test_single_sample(
            matcher,
            Path(args.patch),
            complete_model_path=Path(args.complete_model),
            visualize=not args.no_vis,
            save_result=True,
            save_dir=Path(args.save_dir),
            show_window=args.show_window
        )
    
    elif args.mode == 'batch':
        # æ‰¹é‡æµ‹è¯•
        test_all_patches(
            matcher,
            dataset_dir=Path(args.dataset_dir),
            category=args.category,
            save_dir=Path(args.save_dir),
            visualize_best_worst_median=not args.no_vis
        )


if __name__ == "__main__":
    main()