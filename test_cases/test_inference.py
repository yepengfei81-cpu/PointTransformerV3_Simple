import sys
from pathlib import Path
import torch
import numpy as np
import open3d as o3d
import argparse
from typing import Dict, Tuple, Optional

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pointcept.models import build_model
from pointcept.utils.config import Config


class PTv3ContactMatcher:
    """PTv3 æ¥è§¦ç‚¹ä½ç½®é¢„æµ‹å™¨"""
    
    def __init__(self, config_path: str, checkpoint_path: str, device=None):
        """
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            checkpoint_path: æ¨¡å‹æƒé‡è·¯å¾„
            device: æ¨ç†è®¾å¤‡
        """
        self.config_path = Path(config_path)
        self.checkpoint_path = Path(checkpoint_path)
        
        # è®¾å¤‡é€‰æ‹©
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = device
        
        # åŠ è½½é…ç½®
        print(f"ğŸ”§ åŠ è½½é…ç½®: {self.config_path}")
        self.cfg = Config.fromfile(str(self.config_path))
        
        # æ„å»ºæ¨¡å‹
        print(f"ğŸ”§ æ„å»ºæ¨¡å‹...")
        self.model = build_model(self.cfg.model).to(self.device)
        
        # åŠ è½½æƒé‡
        print(f"ğŸ”§ åŠ è½½æƒé‡: {self.checkpoint_path}")
        checkpoint = torch.load(self.checkpoint_path, map_location=self.device, weights_only=False)
        
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        elif 'model' in checkpoint:
            state_dict = checkpoint['model']
        else:
            state_dict = checkpoint
        
        # ç§»é™¤ 'module.' å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
        new_state_dict = {}
        for k, v in state_dict.items():
            if k.startswith('module.'):
                new_state_dict[k[7:]] = v
            else:
                new_state_dict[k] = v
        
        self.model.load_state_dict(new_state_dict)
        self.model.eval()
        
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        if 'epoch' in checkpoint:
            print(f"   è®­ç»ƒè½®æ•°: {checkpoint['epoch']}")
        if 'best_metric_value' in checkpoint:
            print(f"   æœ€ä½³æŒ‡æ ‡: {checkpoint['best_metric_value']:.6f}")
        print(f"   æ¨ç†è®¾å¤‡: {self.device}")
    
    def predict(self, input_dict: Dict) -> np.ndarray:
        """
        é¢„æµ‹æ¥è§¦ç‚¹ä½ç½®
        
        Args:
            input_dict: åŒ…å«ç‚¹äº‘æ•°æ®çš„å­—å…¸ï¼ˆå¯èƒ½æ˜¯ torch.Tensor æˆ– numpy.ndarrayï¼‰
                - 'coord': (N, 3) ç‚¹åæ ‡
                - 'feat': (N, 3) ç‚¹ç‰¹å¾
                - 'category_id': (1,) ç±»åˆ« IDï¼ˆå¯é€‰ï¼‰
        
        Returns:
            pred_position: (3,) é¢„æµ‹çš„æ¥è§¦ç‚¹ä½ç½®
        """
        # å‡†å¤‡è¾“å…¥
        model_input = {}
        
        # ğŸ”¥ é¦–å…ˆè·å–ç‚¹äº‘æ•°é‡
        num_points = None
        
        for key in ['coord', 'feat', 'grid_coord']:
            if key in input_dict:
                value = input_dict[key]
                
                # ç»Ÿä¸€è½¬æ¢ä¸º torch.Tensor
                if isinstance(value, np.ndarray):
                    value = torch.from_numpy(value).float()
                elif not isinstance(value, torch.Tensor):
                    value = torch.tensor(value).float()
                
                # è®°å½•ç‚¹æ•°
                if num_points is None:
                    num_points = value.shape[0]
                
                # ç¡®ä¿æ­£ç¡®çš„æ•°æ®ç±»å‹
                if key in ['coord', 'feat']:
                    value = value.float()
                elif key == 'grid_coord':
                    value = value.long()
                
                model_input[key] = value.to(self.device)
        
        # ğŸ”¥ æ·»åŠ  batch é”®
        if 'batch' not in input_dict:
            model_input['batch'] = torch.zeros(num_points, dtype=torch.long).to(self.device)
        else:
            batch = input_dict['batch']
            if isinstance(batch, np.ndarray):
                batch = torch.from_numpy(batch).long()
            elif not isinstance(batch, torch.Tensor):
                batch = torch.tensor(batch).long()
            model_input['batch'] = batch.to(self.device)
        
        # ğŸ”¥ æ·»åŠ  offset é”®
        if 'offset' not in input_dict:
            model_input['offset'] = torch.tensor([num_points], dtype=torch.long).to(self.device)
        else:
            offset = input_dict['offset']
            if isinstance(offset, np.ndarray):
                offset = torch.from_numpy(offset).long()
            elif not isinstance(offset, torch.Tensor):
                offset = torch.tensor(offset).long()
            model_input['offset'] = offset.to(self.device)
        
        # ğŸ”¥ æ·»åŠ  grid_sizeï¼ˆä»é…ç½®æ–‡ä»¶ä¸­è·å–ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼‰
        if 'grid_size' not in input_dict:
            # ä»é…ç½®æ–‡ä»¶ä¸­è·å– grid_size
            grid_size = None
            
            # æŸ¥æ‰¾é…ç½®ä¸­çš„ grid_size
            if hasattr(self.cfg, 'data'):
                data_cfg = self.cfg.data
                if 'train' in data_cfg and 'transform' in data_cfg['train']:
                    for transform in data_cfg['train']['transform']:
                        if isinstance(transform, dict) and transform.get('type') == 'GridSample':
                            grid_size = transform.get('grid_size', 0.002)
                            break
            
            # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if grid_size is None:
                grid_size = 0.002  # é»˜è®¤ 2mm
            
            model_input['grid_size'] = torch.tensor(grid_size, dtype=torch.float32).to(self.device)
        else:
            grid_size = input_dict['grid_size']
            if isinstance(grid_size, (int, float)):
                grid_size = torch.tensor(grid_size, dtype=torch.float32)
            elif isinstance(grid_size, np.ndarray):
                grid_size = torch.from_numpy(grid_size).float()
            elif not isinstance(grid_size, torch.Tensor):
                grid_size = torch.tensor(grid_size).float()
            model_input['grid_size'] = grid_size.to(self.device)
        
        # ğŸ”¥ æ·»åŠ ç±»åˆ«ä¿¡æ¯ï¼ˆä½ çš„æ¨¡å‹éœ€è¦è¿™ä¸ªï¼ï¼‰
        if 'category_id' in input_dict:
            category_id = input_dict['category_id']
            
            # ç»Ÿä¸€è½¬æ¢ä¸º torch.Tensor
            if isinstance(category_id, np.ndarray):
                category_id = torch.from_numpy(category_id).long()
            elif isinstance(category_id, (int, np.integer)):
                category_id = torch.tensor(category_id).long()
            elif not isinstance(category_id, torch.Tensor):
                category_id = torch.tensor(category_id).long()
            
            # å¤„ç†æ ‡é‡
            if category_id.dim() == 0:
                category_id = category_id.unsqueeze(0)
            
            model_input['category_id'] = category_id.to(self.device)
            
            # æ‰“å°ç±»åˆ«ä¿¡æ¯
            cat_names = ["Scissors", "Cup", "Avocado"]
            cat_id = category_id.item() if category_id.dim() == 1 else category_id[0].item()
            if 0 <= cat_id < len(cat_names):
                print(f"   ğŸ·ï¸  ç‰©ä½“ç±»åˆ«: {cat_names[cat_id]} (ID={cat_id})")
        else:
            print("   âš ï¸  æ²¡æœ‰æä¾› category_idï¼Œæ¨¡å‹å¯èƒ½éœ€è¦è¿™ä¸ªä¿¡æ¯ï¼")
        
        # ğŸ”¥ æ‰“å°è¾“å…¥ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
        print("\nğŸ“Š æ¨¡å‹è¾“å…¥:")
        for key, value in model_input.items():
            if isinstance(value, torch.Tensor):
                if value.dim() == 0:  # æ ‡é‡
                    print(f"   {key}: æ ‡é‡å€¼={value.item()}, dtype={value.dtype}")
                else:
                    print(f"   {key}: shape={value.shape}, dtype={value.dtype}")
                    if key == 'batch' and value.numel() > 0:
                        unique_batches = torch.unique(value)
                        print(f"      å”¯ä¸€æ‰¹æ¬¡: {unique_batches.tolist()}")
                    elif key == 'offset':
                        print(f"      å€¼: {value.tolist()}")
                    elif key == 'category_id':
                        print(f"      å€¼: {value.tolist()}")
            else:
                print(f"   {key}: {value}")
        
        # æ¨ç†
        with torch.no_grad():
            output_dict = self.model(model_input)
        
        # æå–é¢„æµ‹ä½ç½®
        pred_position = output_dict['pred_position'].cpu().numpy()[0]  # (3,)
        
        return pred_position


def load_patch_data(patch_path: Path, verbose: bool = False) -> Dict[str, torch.Tensor]:
    """
    åŠ è½½ .pth æ ¼å¼çš„å°ç‚¹äº‘æ•°æ®
    
    è¦æ±‚ï¼š
        - å¿…é¡»æœ‰ 'coord'ï¼ˆç‚¹åæ ‡ï¼‰
        - å¿…é¡»æœ‰ 'gt_position'ï¼ˆçœŸå®ä½ç½®ï¼‰
        - å¿…é¡»æœ‰ 'feat' æˆ– 'color'ï¼ˆé¢œè‰²ç‰¹å¾ï¼‰
    
    Args:
        patch_path: .pth æ–‡ä»¶è·¯å¾„
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        data: åŒ…å«ç‚¹äº‘æ•°æ®çš„å­—å…¸ï¼ˆç»Ÿä¸€è½¬ä¸º torch.Tensorï¼‰
    """
    # åŠ è½½æ•°æ®ï¼ˆPyTorch 2.6+ éœ€è¦ weights_only=Falseï¼‰
    try:
        data = torch.load(patch_path, map_location='cpu', weights_only=False)
    except Exception as e:
        raise RuntimeError(f"Failed to load {patch_path}: {e}")
    
    if verbose:
        print(f"\n   åŸå§‹æ•°æ®é”®: {list(data.keys())}")
    
    # 1. æ£€æŸ¥å¿…è¦çš„é”®
    missing_keys = []
    if 'coord' not in data:
        missing_keys.append('coord')
    if 'gt_position' not in data:
        missing_keys.append('gt_position')
    
    if missing_keys:
        raise KeyError(
            f"Missing required keys: {missing_keys}\n"
            f"Available keys: {list(data.keys())}"
        )
    
    # 2. ğŸ”¥ å¤„ç† featï¼ˆå¿…é¡»æ˜¯ colorï¼‰
    if 'feat' not in data:
        if 'color' in data:
            if verbose:
                print(f"   âœ… 'feat' ä¸å­˜åœ¨ï¼Œä½¿ç”¨ 'color' ä½œä¸º 'feat'")
            data['feat'] = data['color']
        else:
            raise KeyError(
                f"Missing 'feat' or 'color' in {patch_path}\n"
                f"feat å¿…é¡»æ¥è‡ªé¢œè‰²ä¿¡æ¯ï¼Œä¸èƒ½ç”¨åæ ‡ä»£æ›¿ï¼\n"
                f"Available keys: {list(data.keys())}"
            )
    
    # ğŸ”¥ 3. ç»Ÿä¸€è½¬æ¢ä¸º torch.Tensorï¼ˆå¦‚æœæ˜¯ numpy.ndarrayï¼‰
    for key in ['coord', 'feat', 'grid_coord', 'gt_position']:
        if key in data:
            value = data[key]
            if isinstance(value, np.ndarray):
                data[key] = torch.from_numpy(value)
            elif not isinstance(value, torch.Tensor):
                data[key] = torch.tensor(value)
    
    # å¤„ç† category_id
    if 'category_id' in data:
        value = data['category_id']
        if isinstance(value, np.ndarray):
            data['category_id'] = torch.from_numpy(value)
        elif isinstance(value, (int, np.integer)):
            data['category_id'] = torch.tensor(value)
        elif not isinstance(value, torch.Tensor):
            data['category_id'] = torch.tensor(value)
    
    if verbose:
        print(f"   æœ€ç»ˆæ•°æ®é”®: {list(data.keys())}")
        print(f"   æ•°æ®ç±»å‹:")
        for key, value in data.items():
            if isinstance(value, torch.Tensor):
                print(f"      {key}: shape={value.shape}, dtype={value.dtype}, type=Tensor")
            elif isinstance(value, np.ndarray):
                print(f"      {key}: shape={value.shape}, dtype={value.dtype}, type=ndarray")
            else:
                print(f"      {key}: type={type(value)}")
    
    return data


def visualize_prediction(
    patch_data: Dict[str, torch.Tensor],
    pred_position: np.ndarray,
    gt_position: np.ndarray,
    patch_name: str = "",
    window_title: str = "æ¥è§¦ç‚¹é¢„æµ‹ç»“æœ"
):
    """
    åœ¨ Open3D ä¸­å¯è§†åŒ–é¢„æµ‹ç»“æœï¼ˆåªæ˜¾ç¤ºå±€éƒ¨ç‚¹äº‘ï¼‰
    
    Args:
        patch_data: å°ç‚¹äº‘æ•°æ®ï¼ˆå¯èƒ½æ˜¯ torch.Tensor æˆ– numpy.ndarrayï¼‰
        pred_position: é¢„æµ‹çš„æ¥è§¦ç‚¹ä½ç½® (3,) numpy
        gt_position: çœŸå®çš„æ¥è§¦ç‚¹ä½ç½® (3,) numpy
        patch_name: æ ·æœ¬åç§°
        window_title: çª—å£æ ‡é¢˜
    """
    # ğŸ”¥ ä¿®å¤ï¼šç»Ÿä¸€è½¬æ¢ä¸º numpy
    coord = patch_data['coord']
    if isinstance(coord, torch.Tensor):
        coord = coord.cpu().numpy()
    else:
        coord = np.array(coord)
    
    # åˆ›å»ºå°ç‚¹äº‘
    patch_pcd = o3d.geometry.PointCloud()
    patch_pcd.points = o3d.utility.Vector3dVector(coord)
    patch_pcd.paint_uniform_color([0.7, 0.7, 0.7])  # ç°è‰²
    
    # è®¡ç®—ç‚¹äº‘èŒƒå›´
    pcd_min = coord.min(axis=0)
    pcd_max = coord.max(axis=0)
    pcd_center = (pcd_min + pcd_max) / 2
    pcd_size = np.linalg.norm(pcd_max - pcd_min)
    
    # åˆ›å»ºé¢„æµ‹ä½ç½®æ ‡è®°ï¼ˆçº¢è‰²çƒä½“ï¼‰
    sphere_radius = pcd_size * 0.02
    pred_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=sphere_radius)
    pred_sphere.translate(pred_position)
    pred_sphere.paint_uniform_color([1, 0, 0])  # çº¢è‰²
    
    # åˆ›å»º GT ä½ç½®æ ‡è®°ï¼ˆè“è‰²çƒä½“ï¼‰
    gt_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=sphere_radius)
    gt_sphere.translate(gt_position)
    gt_sphere.paint_uniform_color([0, 0, 1])  # è“è‰²
    
    # åˆ›å»ºè¿æ¥çº¿
    line_set = o3d.geometry.LineSet()
    line_set.points = o3d.utility.Vector3dVector(np.array([pred_position, gt_position]))
    line_set.lines = o3d.utility.Vector2iVector([[0, 1]])
    line_set.colors = o3d.utility.Vector3dVector([[1, 0.5, 0]])  # æ©™è‰²
    
    # åˆ›å»ºåæ ‡ç³»
    coord_size = pcd_size * 0.15
    coord_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(
        size=coord_size, 
        origin=pcd_center
    )
    
    # è®¡ç®—è¯¯å·®
    error = np.linalg.norm(pred_position - gt_position)
    
    # æ‰“å°ä¿¡æ¯
    print(f"\nğŸ¨ å¯è§†åŒ–è¯´æ˜:")
    print(f"   ğŸŸ¦ è“è‰²çƒä½“ = GT æ¥è§¦ç‚¹ä½ç½®")
    print(f"   ğŸŸ¥ çº¢è‰²çƒä½“ = é¢„æµ‹æ¥è§¦ç‚¹ä½ç½®")
    print(f"   â¬œ ç°è‰²ç‚¹äº‘ = è¾“å…¥çš„å±€éƒ¨ç‚¹äº‘")
    print(f"   ğŸŸ§ æ©™è‰²çº¿æ®µ = é¢„æµ‹è¯¯å·®è¿çº¿")
    print(f"\nğŸ“Š é¢„æµ‹ç»“æœ ({patch_name}):")
    print(f"   é¢„æµ‹ä½ç½®: [{pred_position[0]:.6f}, {pred_position[1]:.6f}, {pred_position[2]:.6f}]")
    print(f"   GT ä½ç½®:   [{gt_position[0]:.6f}, {gt_position[1]:.6f}, {gt_position[2]:.6f}]")
    print(f"   è¯¯å·®: {error:.6f} ç±³ = {error*1000:.2f} æ¯«ç±³")
    
    # å¯è§†åŒ–
    o3d.visualization.draw_geometries(
        [patch_pcd, pred_sphere, gt_sphere, line_set, coord_frame],
        window_name=window_title,
        width=1280,
        height=720,
        point_show_normal=False
    )

def visualize_with_complete_model(
    patch_data: Dict[str, torch.Tensor],
    pred_position: np.ndarray,
    gt_position: np.ndarray,
    complete_model_path: Path,
    patch_name: str = "",
    window_title: str = "æ¥è§¦ç‚¹åœ¨å®Œæ•´æ¨¡å‹ä¸Šçš„ä½ç½®"
):
    """
    åœ¨å®Œæ•´ç‚¹äº‘æ¨¡å‹ä¸Šå¯è§†åŒ–é¢„æµ‹ç»“æœ
    
    Args:
        patch_data: å°ç‚¹äº‘æ•°æ®
        pred_position: é¢„æµ‹çš„æ¥è§¦ç‚¹ä½ç½® (3,) numpy
        gt_position: çœŸå®çš„æ¥è§¦ç‚¹ä½ç½® (3,) numpy
        complete_model_path: å®Œæ•´ç‚¹äº‘æ¨¡å‹è·¯å¾„ï¼ˆ.ply/.pcdï¼‰
        patch_name: æ ·æœ¬åç§°
        window_title: çª—å£æ ‡é¢˜
    """
    geometries = []
    
    # åŠ è½½å®Œæ•´ç‚¹äº‘æ¨¡å‹
    if complete_model_path.exists():
        print(f"ğŸ“‚ åŠ è½½å®Œæ•´æ¨¡å‹: {complete_model_path}")
        complete_pcd = o3d.io.read_point_cloud(str(complete_model_path))
        complete_pcd.paint_uniform_color([0.8, 0.8, 0.8])  # æµ…ç°è‰²
        geometries.append(complete_pcd)
        
        # è®¡ç®—ç‚¹äº‘å°ºå¯¸
        points = np.asarray(complete_pcd.points)
        pcd_min = points.min(axis=0)
        pcd_max = points.max(axis=0)
        pcd_size = np.linalg.norm(pcd_max - pcd_min)
    else:
        print(f"âš ï¸  å®Œæ•´æ¨¡å‹ä¸å­˜åœ¨: {complete_model_path}")
        # ğŸ”¥ ä¿®å¤ï¼šç»Ÿä¸€è½¬æ¢ä¸º numpy
        coord = patch_data['coord']
        if isinstance(coord, torch.Tensor):
            coord = coord.cpu().numpy()
        else:
            coord = np.array(coord)
        
        patch_pcd = o3d.geometry.PointCloud()
        patch_pcd.points = o3d.utility.Vector3dVector(coord)
        patch_pcd.paint_uniform_color([0.7, 0.7, 0.7])
        geometries.append(patch_pcd)
        
        pcd_min = coord.min(axis=0)
        pcd_max = coord.max(axis=0)
        pcd_size = np.linalg.norm(pcd_max - pcd_min)
    
    # åˆ›å»ºé¢„æµ‹ä½ç½®æ ‡è®°ï¼ˆçº¢è‰²çƒä½“ï¼‰
    sphere_radius = pcd_size * 0.015
    pred_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=sphere_radius)
    pred_sphere.translate(pred_position)
    pred_sphere.paint_uniform_color([1, 0, 0])  # çº¢è‰²
    geometries.append(pred_sphere)
    
    # åˆ›å»º GT ä½ç½®æ ‡è®°ï¼ˆè“è‰²çƒä½“ï¼‰
    gt_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=sphere_radius)
    gt_sphere.translate(gt_position)
    gt_sphere.paint_uniform_color([0, 0, 1])  # è“è‰²
    geometries.append(gt_sphere)
    
    # åˆ›å»ºè¿æ¥çº¿
    line_set = o3d.geometry.LineSet()
    line_set.points = o3d.utility.Vector3dVector(np.array([pred_position, gt_position]))
    line_set.lines = o3d.utility.Vector2iVector([[0, 1]])
    line_set.colors = o3d.utility.Vector3dVector([[1, 0.5, 0]])  # æ©™è‰²
    geometries.append(line_set)
    
    # åˆ›å»ºåæ ‡ç³»
    coord_size = pcd_size * 0.08
    coord_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(
        size=coord_size, 
        origin=[0, 0, 0]
    )
    geometries.append(coord_frame)
    
    # è®¡ç®—è¯¯å·®
    error = np.linalg.norm(pred_position - gt_position)
    
    # æ‰“å°ä¿¡æ¯
    print(f"\nğŸ¨ å®Œæ•´æ¨¡å‹å¯è§†åŒ– ({patch_name}):")
    print(f"   ğŸŸ¦ è“è‰²çƒä½“ = GT æ¥è§¦ç‚¹")
    print(f"   ğŸŸ¥ çº¢è‰²çƒä½“ = é¢„æµ‹æ¥è§¦ç‚¹")
    print(f"   â¬œ ç°è‰²ç‚¹äº‘ = å®Œæ•´æ¨¡å‹")
    print(f"   è¯¯å·®: {error:.6f} ç±³ = {error*1000:.2f} æ¯«ç±³")
    
    # å¯è§†åŒ–
    o3d.visualization.draw_geometries(
        geometries,
        window_name=window_title,
        width=1280,
        height=720,
        point_show_normal=False
    )


def test_single_sample(
    matcher: PTv3ContactMatcher,
    patch_path: Path,
    complete_model_path: Optional[Path] = None,
    visualize: bool = True,
    save_result: bool = False
):
    """
    æµ‹è¯•å•ä¸ªæ ·æœ¬
    
    Args:
        matcher: PTv3ContactMatcher å®ä¾‹
        patch_path: å±€éƒ¨ç‚¹äº‘æ–‡ä»¶è·¯å¾„ (.pth)
        complete_model_path: å®Œæ•´ç‚¹äº‘æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        visualize: æ˜¯å¦å¯è§†åŒ–
        save_result: æ˜¯å¦ä¿å­˜ç»“æœ
    """
    print(f"\n{'='*70}")
    print(f"ğŸ§ª æµ‹è¯•æ ·æœ¬: {patch_path}")
    print(f"{'='*70}")
    
    # åŠ è½½æ•°æ®ï¼ˆå¼€å¯è¯¦ç»†è¾“å‡ºï¼‰
    patch_data = load_patch_data(patch_path, verbose=True)
    
    # ğŸ”¥ ä¿®å¤ï¼šç»Ÿä¸€è½¬æ¢ä¸º numpy
    coord = patch_data['coord']
    if isinstance(coord, torch.Tensor):
        coord_np = coord.cpu().numpy()
    else:
        coord_np = np.array(coord)
    
    # ğŸ”¥ ä¿®å¤ï¼šgt_position å¯èƒ½æ˜¯ Tensor æˆ– ndarray
    gt_position = patch_data['gt_position']
    if isinstance(gt_position, torch.Tensor):
        gt_position = gt_position.cpu().numpy()
    else:
        gt_position = np.array(gt_position)
    
    patch_name = patch_data.get('name', patch_path.stem)
    category_id = patch_data.get('category_id', None)
    
    print(f"\nğŸ“‚ å±€éƒ¨ç‚¹äº‘:")
    print(f"   åç§°: {patch_name}")
    print(f"   ç‚¹æ•°: {coord.shape[0] if isinstance(coord, torch.Tensor) else len(coord)}")
    print(f"   GT ä½ç½®: {gt_position}")
    if category_id is not None:
        if isinstance(category_id, torch.Tensor):
            cat_id_value = category_id.item() if category_id.dim() == 0 else category_id[0].item()
        else:
            cat_id_value = int(category_id)
        print(f"   ç±»åˆ« ID: {cat_id_value}")
    
    # é¢„æµ‹
    print(f"\nğŸ”® æ­£åœ¨é¢„æµ‹...")
    try:
        pred_position = matcher.predict(patch_data)
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    # è®¡ç®—è¯¯å·®
    error = np.linalg.norm(pred_position - gt_position)
    
    print(f"\nğŸ“Š é¢„æµ‹ç»“æœ:")
    print(f"   é¢„æµ‹ä½ç½®: [{pred_position[0]:.6f}, {pred_position[1]:.6f}, {pred_position[2]:.6f}]")
    print(f"   GT ä½ç½®:   [{gt_position[0]:.6f}, {gt_position[1]:.6f}, {gt_position[2]:.6f}]")
    print(f"   è¯¯å·®: {error:.6f} ç±³ = {error*1000:.2f} æ¯«ç±³")
    
    # å¯è§†åŒ–
    if visualize:
        # å¯è§†åŒ–1: åªæ˜¾ç¤ºå±€éƒ¨ç‚¹äº‘
        print(f"\nğŸ“º çª—å£1: å±€éƒ¨ç‚¹äº‘ + é¢„æµ‹ç»“æœ")
        visualize_prediction(
            patch_data,
            pred_position,
            gt_position,
            patch_name=patch_name,
            window_title=f"å±€éƒ¨ç‚¹äº‘ - {patch_name}"
        )
        
        # å¯è§†åŒ–2: åœ¨å®Œæ•´æ¨¡å‹ä¸Šæ˜¾ç¤ºï¼ˆå¦‚æœæä¾›ï¼‰
        if complete_model_path:
            print(f"\nğŸ“º çª—å£2: å®Œæ•´æ¨¡å‹ + é¢„æµ‹ç»“æœ")
            visualize_with_complete_model(
                patch_data,
                pred_position,
                gt_position,
                complete_model_path,
                patch_name=patch_name,
                window_title=f"å®Œæ•´æ¨¡å‹ - {patch_name}"
            )
    
    # ä¿å­˜ç»“æœ
    if save_result:
        result = {
            'patch_file': str(patch_path),
            'patch_name': patch_name,
            'pred_position': pred_position.tolist(),
            'gt_position': gt_position.tolist(),
            'error_meters': float(error),
            'error_mm': float(error * 1000)
        }
        
        result_path = Path("inference_results") / f"{patch_path.stem}_result.json"
        result_path.parent.mkdir(exist_ok=True)
        
        import json
        with open(result_path, 'w') as f:
            json.dump(result, f, indent=2)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {result_path}")
    
    print(f"{'='*70}\n")
    
    return error


def test_dataset(
    matcher: PTv3ContactMatcher,
    dataset_dir: Path,
    category: str = "Scissors",
    num_samples: int = 5,
    complete_model_path: Optional[Path] = None,
    visualize_samples: bool = False
):
    """
    æµ‹è¯•æ•°æ®é›†ä¸­çš„å¤šä¸ªæ ·æœ¬
    
    Args:
        matcher: PTv3ContactMatcher å®ä¾‹
        dataset_dir: æ•°æ®é›†ç›®å½•
        category: ç±»åˆ«åç§°
        num_samples: æµ‹è¯•æ ·æœ¬æ•°é‡
        complete_model_path: å®Œæ•´ç‚¹äº‘æ¨¡å‹è·¯å¾„
        visualize_samples: æ˜¯å¦å¯è§†åŒ–æ¯ä¸ªæ ·æœ¬
    """
    category_dir = dataset_dir / category / "patches"
    
    if not category_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {category_dir}")
        return
    
    # è·å–æ‰€æœ‰ patch æ–‡ä»¶
    patch_files = sorted(category_dir.glob("*.pth"))
    
    if not patch_files:
        print(f"âŒ ç›®å½•ä¸­æ²¡æœ‰ .pth æ–‡ä»¶: {category_dir}")
        return
    
    print(f"\n{'='*70}")
    print(f"ğŸ“Š æ•°æ®é›†æ‰¹é‡æµ‹è¯•")
    print(f"{'='*70}")
    print(f"   ç›®å½•: {category_dir}")
    print(f"   æ€»æ ·æœ¬æ•°: {len(patch_files)}")
    print(f"   æµ‹è¯•æ ·æœ¬æ•°: {min(num_samples, len(patch_files))}")
    
    # éšæœºé€‰æ‹©æ ·æœ¬
    import random
    test_files = random.sample(patch_files, min(num_samples, len(patch_files)))
    
    errors = []
    
    for i, patch_path in enumerate(test_files):
        print(f"\n{'-'*70}")
        print(f"æ ·æœ¬ {i+1}/{len(test_files)}: {patch_path.name}")
        print(f"{'-'*70}")
        
        # åŠ è½½æ•°æ®
        patch_data = load_patch_data(patch_path)
        patch_name = patch_data.get('name', patch_path.stem)
        
        # é¢„æµ‹
        pred_position = matcher.predict(patch_data)
        
        # ğŸ”¥ ä¿®å¤ï¼šgt_position å¯èƒ½æ˜¯ Tensor æˆ– ndarray
        gt_position = patch_data['gt_position']
        if isinstance(gt_position, torch.Tensor):
            gt_position = gt_position.cpu().numpy()
        else:
            gt_position = np.array(gt_position)
        
        # è®¡ç®—è¯¯å·®
        error = np.linalg.norm(pred_position - gt_position)
        errors.append(error)
        
        print(f"   åç§°: {patch_name}")
        print(f"   é¢„æµ‹: [{pred_position[0]:.6f}, {pred_position[1]:.6f}, {pred_position[2]:.6f}]")
        print(f"   GT:   [{gt_position[0]:.6f}, {gt_position[1]:.6f}, {gt_position[2]:.6f}]")
        print(f"   è¯¯å·®: {error*1000:.2f} mm")
        
        # å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
        if visualize_samples:
            visualize_prediction(
                patch_data,
                pred_position,
                gt_position,
                patch_name=patch_name,
                window_title=f"æ ·æœ¬ {i+1}/{len(test_files)}: {patch_name}"
            )
    
    # ç»Ÿè®¡
    errors = np.array(errors)
    print(f"\n{'='*70}")
    print(f"ğŸ“ˆ ç»Ÿè®¡ç»“æœ")
    print(f"{'='*70}")
    print(f"   å¹³å‡è¯¯å·®: {errors.mean()*1000:.2f} mm")
    print(f"   ä¸­ä½æ•°è¯¯å·®: {np.median(errors)*1000:.2f} mm")
    print(f"   æ ‡å‡†å·®: {errors.std()*1000:.2f} mm")
    print(f"   æœ€å¤§è¯¯å·®: {errors.max()*1000:.2f} mm")
    print(f"   æœ€å°è¯¯å·®: {errors.min()*1000:.2f} mm")
    print(f"{'='*70}\n")


def main():
    parser = argparse.ArgumentParser(description='PTv3 Contact Position Regression æ¨ç†ä¸å¯è§†åŒ–')
    parser.add_argument('--config', type=str, 
                        default='configs/s3dis/semseg-pt-v3m1-gelsight.py',
                        help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--checkpoint', type=str,
                        default='exp/gelsight_test/model/model_best.pth',
                        help='æ¨¡å‹æƒé‡è·¯å¾„')
    parser.add_argument('--patch', type=str,
                        help='å•ä¸ªå±€éƒ¨ç‚¹äº‘æ–‡ä»¶è·¯å¾„ (.pth)')
    parser.add_argument('--dataset', type=str,
                        default='data/gelsight_dataset',
                        help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--category', type=str, default='Scissors',
                        help='ç±»åˆ«åç§°ï¼ˆScissors/Cup/Avocadoï¼‰')
    parser.add_argument('--num_samples', type=int, default=5,
                        help='æ‰¹é‡æµ‹è¯•æ—¶çš„æ ·æœ¬æ•°é‡')
    parser.add_argument('--complete_model', type=str,
                        help='å®Œæ•´ç‚¹äº‘æ¨¡å‹è·¯å¾„ (.ply/.pcd)')
    parser.add_argument('--no_vis', action='store_true',
                        help='ä¸æ˜¾ç¤ºå¯è§†åŒ–')
    parser.add_argument('--vis_all', action='store_true',
                        help='æ‰¹é‡æµ‹è¯•æ—¶å¯è§†åŒ–æ¯ä¸ªæ ·æœ¬ï¼ˆä¼šå¾ˆæ…¢ï¼‰')
    parser.add_argument('--save', action='store_true',
                        help='ä¿å­˜ç»“æœåˆ° JSON')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æ¨ç†å™¨
    print(f"\n{'='*70}")
    print(f"ğŸš€ åˆå§‹åŒ– PTv3 Contact Matcher")
    print(f"{'='*70}")
    
    matcher = PTv3ContactMatcher(
        config_path=args.config,
        checkpoint_path=args.checkpoint
    )
    
    # å®Œæ•´æ¨¡å‹è·¯å¾„
    complete_model_path = Path(args.complete_model) if args.complete_model else None
    
    if args.patch:
        # æµ‹è¯•å•ä¸ªæ ·æœ¬
        test_single_sample(
            matcher,
            Path(args.patch),
            complete_model_path=complete_model_path,
            visualize=not args.no_vis,
            save_result=args.save
        )
    else:
        # æ‰¹é‡æµ‹è¯•æ•°æ®é›†
        test_dataset(
            matcher,
            Path(args.dataset),
            category=args.category,
            num_samples=args.num_samples,
            complete_model_path=complete_model_path,
            visualize_samples=args.vis_all
        )


if __name__ == "__main__":
    main()