import sys
import torch
from pathlib import Path
from torch.utils.data import DataLoader
from functools import partial
import numpy as np


sys.path.insert(0, str(Path(__file__).parent.parent))

from pointcept.datasets.builder import build_dataset
from pointcept.datasets.utils import point_collate_fn
from pointcept.utils.config import Config


def print_separator(title="", width=80):
    """æ‰“å°åˆ†éš”çº¿"""
    if title:
        print("\n" + "=" * width)
        print(title.center(width))
        print("=" * width)
    else:
        print("=" * width)


def analyze_batch(batch, batch_idx, is_test=False):
    """è¯¦ç»†åˆ†æä¸€ä¸ª batch çš„å†…å®¹ï¼ˆåµŒå¥—ç»“æ„ï¼‰"""
    print(f"\n{'â”€' * 80}")
    print(f"ğŸ“¦ Batch {batch_idx} Analysis {'(Test Mode)' if is_test else '(Train/Val Mode)'}")
    print(f"{'â”€' * 80}")
    
    print(f"\n1ï¸âƒ£  åŸºæœ¬ä¿¡æ¯:")
    print(f"   - Type: {type(batch)}")
    print(f"   - Top-level Keys: {list(batch.keys())}")
    
    # åˆ†æå±€éƒ¨ç‚¹äº‘ï¼ˆlocalï¼‰
    if "local" in batch:
        print(f"\n2ï¸âƒ£  å±€éƒ¨ç‚¹äº‘ (local):")
        local = batch["local"]
        print(f"   - Keys: {list(local.keys())}")
        
        # ğŸ”¥ æ›´æ–°ï¼šæ·»åŠ æ–°å­—æ®µ
        for key in ["coord", "grid_coord", "feat", "offset", 
                    "gt_position", "coord_centroid",  # ğŸ”¥ æ–°å¢
                    "name", "category_id", "parent_id"]:  # ğŸ”¥ æ–°å¢
            if key in local:
                value = local[key]
                if isinstance(value, torch.Tensor):
                    print(f"   âœ… {key:25s}: shape={str(value.shape):20s} dtype={value.dtype}")
                elif isinstance(value, list):
                    print(f"   âœ… {key:25s}: list of {len(value)} items")
                else:
                    print(f"   âœ… {key:25s}: {type(value).__name__}")
        
        if "offset" in local:
            offset = local["offset"]
            print(f"\n   Offset åˆ†æ:")
            print(f"   - Offset: {offset.tolist()}")
            print(f"   - Batch size: {len(offset)}")
            
            print(f"\n   å„æ ·æœ¬çš„å±€éƒ¨ç‚¹äº‘ç‚¹æ•°:")
            start = 0
            for i in range(len(offset)):
                n_points = offset[i] - start
                print(f"      Sample {i}: {n_points:6d} points (range: [{start:6d}, {offset[i]:6d}))")
                start = offset[i]
            
            total_points = offset[-1].item()
            print(f"\n   âœ… æ€»å±€éƒ¨ç‚¹æ•°: {total_points}")
            
            if "coord" in local:
                actual_points = local["coord"].shape[0]
                if actual_points == total_points:
                    print(f"   âœ… Offset éªŒè¯é€šè¿‡: coord.shape[0] == offset[-1]")
                else:
                    print(f"   âŒ Offset éªŒè¯å¤±è´¥: {actual_points} != {total_points}")
    
    # åˆ†æçˆ¶ç‚¹äº‘ï¼ˆparentï¼‰
    if "parent" in batch:
        print(f"\n3ï¸âƒ£  çˆ¶ç‚¹äº‘ (parent):")
        parent = batch["parent"]
        print(f"   - Keys: {list(parent.keys())}")
        
        for key in ["coord", "grid_coord", "feat", "offset", "name"]:
            if key in parent:
                value = parent[key]
                if isinstance(value, torch.Tensor):
                    print(f"   âœ… {key:15s}: shape={str(value.shape):20s} dtype={value.dtype}")
                elif isinstance(value, list):
                    print(f"   âœ… {key:15s}: list of {len(value)} items")
                else:
                    print(f"   âœ… {key:15s}: {type(value).__name__}")
        
        if "offset" in parent:
            offset = parent["offset"]
            print(f"\n   Offset åˆ†æ:")
            print(f"   - Offset: {offset.tolist()}")
            print(f"   - Batch size: {len(offset)}")
            
            print(f"\n   å„æ ·æœ¬çš„çˆ¶ç‚¹äº‘ç‚¹æ•°:")
            start = 0
            for i in range(len(offset)):
                n_points = offset[i] - start
                print(f"      Sample {i}: {n_points:6d} points (range: [{start:6d}, {offset[i]:6d}))")
                start = offset[i]
            
            total_points = offset[-1].item()
            print(f"\n   âœ… æ€»çˆ¶ç‚¹äº‘ç‚¹æ•°: {total_points}")
            
            if "coord" in parent:
                actual_points = parent["coord"].shape[0]
                if actual_points == total_points:
                    print(f"   âœ… Offset éªŒè¯é€šè¿‡: coord.shape[0] == offset[-1]")
                else:
                    print(f"   âŒ Offset éªŒè¯å¤±è´¥: {actual_points} != {total_points}")
    
    # å¯¹æ¯”å±€éƒ¨ç‚¹äº‘å’Œçˆ¶ç‚¹äº‘
    if "local" in batch and "parent" in batch:
        if "offset" in batch["local"] and "offset" in batch["parent"]:
            print(f"\n4ï¸âƒ£  å±€éƒ¨ç‚¹äº‘ vs çˆ¶ç‚¹äº‘:")
            local_offset = batch["local"]["offset"]
            parent_offset = batch["parent"]["offset"]
            
            print(f"   {'Sample':<10} {'Local Points':<15} {'Parent Points':<15} {'Ratio':<10}")
            print(f"   {'-'*10} {'-'*15} {'-'*15} {'-'*10}")
            
            local_start = 0
            parent_start = 0
            for i in range(len(local_offset)):
                local_n = local_offset[i] - local_start
                parent_n = parent_offset[i] - parent_start
                ratio = parent_n / local_n if local_n > 0 else 0
                print(f"   {i:<10} {local_n:<15} {parent_n:<15} {ratio:<10.2f}x")
                local_start = local_offset[i]
                parent_start = parent_offset[i]
    
    # åˆ†æå½’ä¸€åŒ–å‚æ•°
    if "norm_offset" in batch or "norm_scale" in batch:
        print(f"\n5ï¸âƒ£  å½’ä¸€åŒ–å‚æ•°:")
        if "norm_offset" in batch:
            norm_offset = batch["norm_offset"]
            if isinstance(norm_offset, torch.Tensor):
                print(f"   - norm_offset shape: {norm_offset.shape}")
                if norm_offset.dim() == 2:
                    for i in range(min(norm_offset.shape[0], 3)):
                        print(f"      Sample {i}: [{norm_offset[i, 0]:.3f}, {norm_offset[i, 1]:.3f}, {norm_offset[i, 2]:.3f}]")
            else:
                print(f"   - norm_offset: list of {len(norm_offset)} items")
        
        if "norm_scale" in batch:
            norm_scale = batch["norm_scale"]
            if isinstance(norm_scale, torch.Tensor):
                print(f"   - norm_scale shape: {norm_scale.shape}")
                if norm_scale.dim() == 1:
                    for i in range(min(norm_scale.shape[0], 3)):
                        print(f"      Sample {i}: {norm_scale[i].item():.6f}")
                elif norm_scale.dim() == 2:
                    for i in range(min(norm_scale.shape[0], 3)):
                        print(f"      Sample {i}: [{norm_scale[i, 0]:.6f}, {norm_scale[i, 1]:.6f}, {norm_scale[i, 2]:.6f}]")
            else:
                print(f"   - norm_scale: list of {len(norm_scale)} items")
    
    # ğŸ”¥ åˆ†æ GTï¼ˆè®­ç»ƒ/éªŒè¯é›†ï¼‰
    if not is_test and "local" in batch:
        print(f"\n6ï¸âƒ£  Ground Truth:")
        
        # GT Positionï¼ˆç»å¯¹ä½ç½®ï¼‰
        if "gt_position" in batch["local"]:
            gt_pos = batch["local"]["gt_position"]
            print(f"   - gt_position shape: {gt_pos.shape}")
            print(f"   - gt_position dtype: {gt_pos.dtype}")
            for j in range(min(gt_pos.shape[0], 3)):
                print(f"      Sample {j}: [{gt_pos[j, 0]:.6f}, {gt_pos[j, 1]:.6f}, {gt_pos[j, 2]:.6f}]")
        
        # Coord Centroidï¼ˆç”¨äºè°ƒè¯•ï¼‰
        if "coord_centroid" in batch["local"]:
            centroid = batch["local"]["coord_centroid"]
            print(f"   - coord_centroid shape: {centroid.shape}")
            for j in range(min(centroid.shape[0], 3)):
                print(f"      Sample {j}: [{centroid[j, 0]:.6f}, {centroid[j, 1]:.6f}, {centroid[j, 2]:.6f}]")
    
    # ğŸ”¥ æµ‹è¯•é›†ï¼šåªæœ‰ coord_centroid
    if is_test and "local" in batch:
        print(f"\n6ï¸âƒ£  æ¨ç†ä¿¡æ¯ (æ—  GT):")
        
        if "coord_centroid" in batch["local"]:
            centroid = batch["local"]["coord_centroid"]
            print(f"   - coord_centroid shape: {centroid.shape}")
            for j in range(min(centroid.shape[0], 3)):
                print(f"      Sample {j}: [{centroid[j, 0]:.6f}, {centroid[j, 1]:.6f}, {centroid[j, 2]:.6f}]")
        else:
            print(f"   âš ï¸  æµ‹è¯•é›†ç¼ºå°‘ coord_centroidï¼ˆæ— æ³•æ¢å¤ç»å¯¹ä½ç½®ï¼‰")
    
    # åˆ†ææ ·æœ¬åç§°
    if "local" in batch and "name" in batch["local"]:
        print(f"\n7ï¸âƒ£  æ ·æœ¬åç§°:")
        print(f"   å±€éƒ¨ç‚¹äº‘:")
        for j, name in enumerate(batch["local"]["name"][:3]):
            print(f"      Sample {j}: {name}")
    
    if "parent" in batch and "name" in batch["parent"]:
        print(f"   çˆ¶ç‚¹äº‘:")
        for j, name in enumerate(batch["parent"]["name"][:3]):
            print(f"      Sample {j}: {name}")
    
    print(f"\n{'â”€' * 80}\n")


def test_single_sample():
    """æµ‹è¯•å•ä¸ªæ ·æœ¬çš„æ•°æ®ç»“æ„"""
    print_separator("ğŸ”¬ æµ‹è¯•å•ä¸ªæ ·æœ¬")
    
    # ğŸ”¥ ä¿®æ”¹é…ç½®æ–‡ä»¶è·¯å¾„
    cfg = Config.fromfile("/home/ypf/PointTransformerV3_Simple/configs/s3dis/semseg-pt-v3m1-gelsight.py")
    
    print(f"\nğŸ“‚ åŠ è½½è®­ç»ƒé›†...")
    train_dataset = build_dataset(cfg.data.train)
    
    print(f"\nğŸ“¦ è·å– Sample 0...")
    sample = train_dataset[0]
    
    print(f"\n   âœ… æ ·æœ¬è·å–æˆåŠŸ!")
    print(f"   - Type: {type(sample)}")
    print(f"   - Top-level Keys: {list(sample.keys())}")
    
    # åˆ†æå±€éƒ¨ç‚¹äº‘
    if "local" in sample:
        print(f"\n   å±€éƒ¨ç‚¹äº‘ (local):")
        local = sample["local"]
        print(f"   - Keys: {list(local.keys())}")
        for key, value in local.items():
            if isinstance(value, torch.Tensor):
                print(f"      âœ… {key:25s}: shape={str(value.shape):20s} dtype={value.dtype}")
            else:
                print(f"      âœ… {key:25s}: {type(value).__name__}")
    
    # åˆ†æçˆ¶ç‚¹äº‘
    if "parent" in sample:
        print(f"\n   çˆ¶ç‚¹äº‘ (parent):")
        parent = sample["parent"]
        print(f"   - Keys: {list(parent.keys())}")
        for key, value in parent.items():
            if isinstance(value, torch.Tensor):
                print(f"      âœ… {key:15s}: shape={str(value.shape):20s} dtype={value.dtype}")
            else:
                print(f"      âœ… {key:15s}: {type(value).__name__}")
    
    # ğŸ”¥ éªŒè¯ GT å­—æ®µ
    if "gt_position" in sample:
        print(f"\n   éªŒè¯ GT å­—æ®µ:")
        gt_pos = sample["gt_position"]
        print(f"   - gt_position: {gt_pos.numpy()}")
        
        if "coord_centroid" in sample:
            centroid = sample["coord_centroid"]
            print(f"   - coord_centroid: {centroid.numpy()}")
            
            # éªŒè¯ gt_position æ˜¯å¦è¿œç¦»åŸç‚¹ï¼ˆç»å¯¹ä½ç½®ï¼‰
            gt_norm = torch.norm(gt_pos).item()
            print(f"   - gt_position norm: {gt_norm:.6f} {'âœ… (ç»å¯¹ä½ç½®)' if gt_norm > 0.1 else 'âš ï¸ (æ¥è¿‘åŸç‚¹)'}")

    if "local" in sample and "coord" in sample["local"]:
        print(f"\n   éªŒè¯åæ ‡å»ä¸­å¿ƒåŒ–:")
        coord = sample["local"]["coord"]
        coord_mean = coord.mean(dim=0).numpy()
        coord_norm = np.linalg.norm(coord_mean)
        
        print(f"   - coord.mean(): [{coord_mean[0]:.6f}, {coord_mean[1]:.6f}, {coord_mean[2]:.6f}]")
        print(f"   - coord.mean() norm: {coord_norm:.2e}")
        
        if coord_norm < 1e-4:
            print(f"   âœ… coord å·²å»ä¸­å¿ƒåŒ–ï¼ˆå‡å€¼æ¥è¿‘åŸç‚¹ï¼‰")
        else:
            print(f"   âŒ coord æœªå»ä¸­å¿ƒåŒ–ï¼ˆå‡å€¼è¿œç¦»åŸç‚¹ï¼‰")
        
        # éªŒè¯æ¢å¤
        if "coord_centroid" in sample:
            centroid = sample["coord_centroid"]
            coord_recovered = coord + centroid
            coord_recovered_mean = coord_recovered.mean(dim=0).numpy()
            
            print(f"\n   æ¢å¤åŸå§‹åæ ‡:")
            print(f"   - (coord + centroid).mean(): [{coord_recovered_mean[0]:.6f}, {coord_recovered_mean[1]:.6f}, {coord_recovered_mean[2]:.6f}]")
            print(f"   - åº”è¯¥ç­‰äº coord_centroid: [{centroid[0]:.6f}, {centroid[1]:.6f}, {centroid[2]:.6f}]")
            
            error = np.linalg.norm(coord_recovered_mean - centroid.numpy())
            if error < 1e-5:
                print(f"   âœ… æ¢å¤éªŒè¯é€šè¿‡ï¼ˆè¯¯å·® {error:.2e}ï¼‰")
            else:
                print(f"   âŒ æ¢å¤éªŒè¯å¤±è´¥ï¼ˆè¯¯å·® {error:.2e}ï¼‰")

    # åˆ†æå½’ä¸€åŒ–å‚æ•°
    if "norm_offset" in sample:
        print(f"\n   å½’ä¸€åŒ–å‚æ•°:")
        print(f"   - norm_offset: {sample['norm_offset']}")
        print(f"   - norm_scale: {sample['norm_scale']}")
    
    print_separator("âœ… å•ä¸ªæ ·æœ¬æµ‹è¯•å®Œæˆ")


def test_collate_fn():
    """æµ‹è¯• collate_fn"""
    print_separator("ğŸ”§ æµ‹è¯• point_collate_fn")
    
    cfg = Config.fromfile("/home/ypf/PointTransformerV3_Simple/configs/s3dis/semseg-pt-v3m1-gelsight.py")
    
    print(f"\nğŸ“‚ åŠ è½½è®­ç»ƒé›†...")
    train_dataset = build_dataset(cfg.data.train)
    
    print(f"\nğŸ“¦ æ‰‹åŠ¨è·å– 3 ä¸ªæ ·æœ¬...")
    samples = [train_dataset[i] for i in range(3)]
    
    print(f"\n   å„æ ·æœ¬çš„ç»“æ„:")
    for i, sample in enumerate(samples):
        print(f"   Sample {i}:")
        print(f"      - Top-level keys: {list(sample.keys())}")
        
        if "local" in sample and "coord" in sample["local"]:
            local_n = sample["local"]["coord"].shape[0]
            print(f"      - å±€éƒ¨ç‚¹æ•°: {local_n}")
        
        if "parent" in sample and "coord" in sample["parent"]:
            parent_n = sample["parent"]["coord"].shape[0]
            print(f"      - çˆ¶ç‚¹äº‘ç‚¹æ•°: {parent_n}")
    
    print(f"\nğŸ”§ è°ƒç”¨ point_collate_fn...")
    batch = point_collate_fn(samples, mix_prob=0.0)
    
    print(f"\n   âœ… Collate æˆåŠŸ!")
    print(f"   Batch top-level keys: {list(batch.keys())}")
    
    if "local" in batch:
        print(f"   Batch local keys: {list(batch['local'].keys())}")
    if "parent" in batch:
        print(f"   Batch parent keys: {list(batch['parent'].keys())}")
    
    analyze_batch(batch, 0, is_test=False)
    
    print_separator("âœ… point_collate_fn æµ‹è¯•å®Œæˆ")


def test_train_dataloader():
    """æµ‹è¯•è®­ç»ƒé›† DataLoader"""
    print_separator("ğŸš‚ æµ‹è¯•è®­ç»ƒé›† DataLoader")
    
    cfg = Config.fromfile("/home/ypf/PointTransformerV3_Simple/configs/s3dis/semseg-pt-v3m1-gelsight.py")
    
    print(f"\nğŸ“‚ åŠ è½½è®­ç»ƒé›†...")
    train_dataset = build_dataset(cfg.data.train)
    
    print(f"   âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ!")
    print(f"      - æ•°æ®é›†ç±»å‹: {type(train_dataset).__name__}")
    print(f"      - æ ·æœ¬æ•°é‡: {len(train_dataset)}")
    print(f"      - Split: {train_dataset.split}")
    
    batch_size = 4
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,
        collate_fn=partial(point_collate_fn, mix_prob=0.0),
        pin_memory=False,
    )
    
    print(f"\nğŸ“¦ åˆ›å»º DataLoader:")
    print(f"   âœ… DataLoader åˆ›å»ºæˆåŠŸ!")
    print(f"      - Batch size: {batch_size}")
    print(f"      - Total batches: {len(train_loader)}")
    
    print_separator("ğŸ” æµ‹è¯•å‰ 2 ä¸ª Batch")
    
    for i, batch in enumerate(train_loader):
        if i >= 2:
            break
        analyze_batch(batch, i, is_test=False)
    
    print_separator("âœ… è®­ç»ƒé›† DataLoader æµ‹è¯•å®Œæˆ")


def test_val_dataloader():
    """æµ‹è¯•éªŒè¯é›† DataLoader"""
    print_separator("ğŸ” æµ‹è¯•éªŒè¯é›† DataLoader")
    
    cfg = Config.fromfile("/home/ypf/PointTransformerV3_Simple/configs/s3dis/semseg-pt-v3m1-gelsight.py")
    
    print(f"\nğŸ“‚ åŠ è½½éªŒè¯é›†...")
    val_dataset = build_dataset(cfg.data.val)
    
    print(f"   âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ!")
    print(f"      - æ•°æ®é›†ç±»å‹: {type(val_dataset).__name__}")
    print(f"      - æ ·æœ¬æ•°é‡: {len(val_dataset)}")
    print(f"      - Split: {val_dataset.split}")
    
    batch_size = 2
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        collate_fn=partial(point_collate_fn, mix_prob=0.0),
        pin_memory=False,
    )
    
    print(f"\nğŸ“¦ åˆ›å»º DataLoader:")
    print(f"   âœ… DataLoader åˆ›å»ºæˆåŠŸ!")
    print(f"      - Batch size: {batch_size}")
    print(f"      - Total batches: {len(val_loader)}")
    
    print_separator("ğŸ” æµ‹è¯•å‰ 1 ä¸ª Batch")
    
    for i, batch in enumerate(val_loader):
        if i >= 1:
            break
        analyze_batch(batch, i, is_test=False)
    
    print_separator("âœ… éªŒè¯é›† DataLoader æµ‹è¯•å®Œæˆ")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "ğŸš€" * 40)
    print("å¼€å§‹æµ‹è¯•å¸¦ CentroidShift çš„ DataLoader".center(80))
    print("ğŸš€" * 40)
    
    try:
        test_single_sample()
        test_collate_fn()
        test_train_dataloader()
        test_val_dataloader()
        
        print("\n" + "ğŸ‰" * 40)
        print("æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼".center(80))
        print("ğŸ‰" * 40 + "\n")
        
    except Exception as e:
        print("\n" + "âŒ" * 40)
        print(f"æµ‹è¯•å¤±è´¥: {e}".center(80))
        print("âŒ" * 40 + "\n")
        
        import traceback
        print("\nå®Œæ•´é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        
        raise


if __name__ == "__main__":
    main()