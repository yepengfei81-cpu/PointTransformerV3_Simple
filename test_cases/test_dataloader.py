import sys
import torch
from pathlib import Path
from torch.utils.data import DataLoader
from functools import partial

sys.path.insert(0, str(Path(__file__).parent.parent))

from pointcept.datasets.builder import build_dataset
from pointcept.datasets.utils import point_collate_fn
from pointcept.utils.config import Config


def print_separator(title="", width=80):
    """æ‰“å°åˆ†éš”çº¿"""
    if title:
        print("\n" + "=" * width)
        print(title.center(width))
        print("=" * width)
    else:
        print("=" * width)


def analyze_batch(batch, batch_idx):
    """è¯¦ç»†åˆ†æä¸€ä¸ª batch çš„å†…å®¹"""
    print(f"\n{'â”€' * 80}")
    print(f"ğŸ“¦ Batch {batch_idx} Analysis")
    print(f"{'â”€' * 80}")
    
    print(f"\n1ï¸âƒ£  åŸºæœ¬ä¿¡æ¯:")
    print(f"   - Type: {type(batch)}")
    print(f"   - Keys: {list(batch.keys())}")
    
    # ğŸ”¥ åˆ†ææ‰€æœ‰å¼ é‡
    print(f"\n2ï¸âƒ£  å¼ é‡å½¢çŠ¶:")
    tensor_keys = [
        'coord', 'grid_coord', 'feat', 'color', 'offset', 'grid_size',
        'gt_position', 'category_id', 'norm_offset', 'norm_scale',
        'parent_coord', 'parent_color', 'parent_grid_coord', 
        'parent_grid_size', 'parent_batch', 'parent_offset',  # ğŸ”¥ æ–°å¢çˆ¶ç‚¹äº‘å­—æ®µ
        'batch', 'name'
    ]
    
    for key in tensor_keys:
        if key in batch:
            value = batch[key]
            if isinstance(value, torch.Tensor):
                print(f"   âœ… {key:20s}: shape={str(value.shape):20s} dtype={value.dtype}")
            elif isinstance(value, list):
                print(f"   âœ… {key:20s}: list of {len(value)} items")
            elif isinstance(value, (int, float)):
                print(f"   âœ… {key:20s}: {type(value).__name__}={value}")
            else:
                print(f"   âš ï¸  {key:20s}: {type(value)}")
    
    # ğŸ”¥ åˆ†æå±€éƒ¨ç‚¹äº‘çš„ offset
    if "offset" in batch:
        offset = batch["offset"]
        print(f"\n3ï¸âƒ£  å±€éƒ¨ç‚¹äº‘ Offset åˆ†æ:")
        print(f"   - Offset tensor: {offset.tolist()}")
        print(f"   - Batch size: {len(offset) - 1}")
        
        print(f"\n   å„æ ·æœ¬çš„å±€éƒ¨ç‚¹äº‘ç‚¹æ•°:")
        for i in range(len(offset) - 1):
            n_points = offset[i + 1] - offset[i]
            print(f"      Sample {i}: {n_points:6d} points (range: [{offset[i]:6d}, {offset[i+1]:6d}))")
        
        total_local_points = offset[-1].item()
        print(f"\n   âœ… æ€»å±€éƒ¨ç‚¹æ•°: {total_local_points}")
        
        # ğŸ”¥ éªŒè¯ offset çš„æ­£ç¡®æ€§
        if "coord" in batch:
            actual_points = batch["coord"].shape[0]
            if actual_points == total_local_points:
                print(f"   âœ… Offset éªŒè¯é€šè¿‡: coord.shape[0] ({actual_points}) == offset[-1] ({total_local_points})")
            else:
                print(f"   âŒ Offset éªŒè¯å¤±è´¥: coord.shape[0] ({actual_points}) != offset[-1] ({total_local_points})")
    
    # ğŸ”¥ åˆ†æçˆ¶ç‚¹äº‘çš„ parent_offset
    if "parent_offset" in batch:
        parent_offset = batch["parent_offset"]
        print(f"\n4ï¸âƒ£  çˆ¶ç‚¹äº‘ Parent Offset åˆ†æ:")
        print(f"   - Parent Offset tensor: {parent_offset.tolist()}")
        print(f"   - Batch size: {len(parent_offset) - 1}")
        
        print(f"\n   å„æ ·æœ¬çš„çˆ¶ç‚¹äº‘ç‚¹æ•°:")
        for i in range(len(parent_offset) - 1):
            n_points = parent_offset[i + 1] - parent_offset[i]
            print(f"      Sample {i}: {n_points:6d} points (range: [{parent_offset[i]:6d}, {parent_offset[i+1]:6d}))")
        
        total_parent_points = parent_offset[-1].item()
        print(f"\n   âœ… æ€»çˆ¶ç‚¹äº‘ç‚¹æ•°: {total_parent_points}")
        
        # ğŸ”¥ éªŒè¯ parent_offset çš„æ­£ç¡®æ€§
        if "parent_coord" in batch:
            actual_points = batch["parent_coord"].shape[0]
            if actual_points == total_parent_points:
                print(f"   âœ… Parent Offset éªŒè¯é€šè¿‡: parent_coord.shape[0] ({actual_points}) == parent_offset[-1] ({total_parent_points})")
            else:
                print(f"   âŒ Parent Offset éªŒè¯å¤±è´¥: parent_coord.shape[0] ({actual_points}) != parent_offset[-1] ({total_parent_points})")
        
        # ğŸ”¥ ä¸ parent_batch å¯¹æ¯”éªŒè¯
        if "parent_batch" in batch:
            parent_batch = batch["parent_batch"]
            print(f"\n   ğŸ” ä¸ parent_batch å¯¹æ¯”éªŒè¯:")
            
            # ä» parent_batch è®¡ç®—é¢„æœŸçš„ parent_offset
            counts = torch.bincount(parent_batch.long())
            expected_offset = torch.cat([
                torch.tensor([0]),
                torch.cumsum(counts, dim=0)
            ])
            
            print(f"      - ä» parent_batch è®¡ç®—çš„ offset: {expected_offset.tolist()}")
            print(f"      - å®é™… parent_offset:           {parent_offset.tolist()}")
            
            if torch.equal(expected_offset, parent_offset):
                print(f"      âœ… Parent Offset ä¸ parent_batch ä¸€è‡´ï¼")
            else:
                print(f"      âŒ Parent Offset ä¸ parent_batch ä¸ä¸€è‡´ï¼")
    else:
        print(f"\n4ï¸âƒ£  çˆ¶ç‚¹äº‘ Parent Offset åˆ†æ:")
        print(f"   âŒ ç¼ºå°‘ 'parent_offset' å­—æ®µï¼")
        print(f"   âš ï¸  è¯·æ£€æŸ¥ point_collate_fn æ˜¯å¦æ­£ç¡®ç”Ÿæˆäº† parent_offset")
    
    # ğŸ”¥ åˆ†æçˆ¶ç‚¹äº‘ï¼ˆä½¿ç”¨ parent_batchï¼‰
    if "parent_coord" in batch:
        parent_coord = batch["parent_coord"]
        print(f"\n5ï¸âƒ£  çˆ¶ç‚¹äº‘è¯¦ç»†åˆ†æ:")
        print(f"   - parent_coord shape: {parent_coord.shape}")
        if "parent_color" in batch:
            print(f"   - parent_color shape: {batch['parent_color'].shape}")
        if "parent_grid_coord" in batch:
            print(f"   - parent_grid_coord shape: {batch['parent_grid_coord'].shape}")
        
        if "parent_batch" in batch:
            parent_batch = batch["parent_batch"]
            print(f"   - parent_batch shape: {parent_batch.shape}")
            
            # ç»Ÿè®¡æ¯ä¸ªæ ·æœ¬çš„çˆ¶ç‚¹äº‘ç‚¹æ•°
            unique_batches = torch.unique(parent_batch)
            print(f"\n   å„æ ·æœ¬çš„çˆ¶ç‚¹äº‘ç‚¹æ•°ï¼ˆä» parent_batch ç»Ÿè®¡ï¼‰:")
            for b_idx in unique_batches:
                mask = parent_batch == b_idx
                n_parent_points = mask.sum().item()
                print(f"      Sample {b_idx}: {n_parent_points:6d} points")
            
            print(f"\n   æ€»çˆ¶ç‚¹äº‘ç‚¹æ•°: {len(parent_batch)}")
    
    # ğŸ”¥ å¯¹æ¯”å±€éƒ¨ç‚¹äº‘å’Œçˆ¶ç‚¹äº‘çš„ç‚¹æ•°
    if "offset" in batch and "parent_offset" in batch:
        print(f"\n6ï¸âƒ£  å±€éƒ¨ç‚¹äº‘ vs çˆ¶ç‚¹äº‘ ç‚¹æ•°å¯¹æ¯”:")
        offset = batch["offset"]
        parent_offset = batch["parent_offset"]
        
        print(f"   {'Sample':<10} {'Local Points':<15} {'Parent Points':<15} {'Ratio':<10}")
        print(f"   {'-'*10} {'-'*15} {'-'*15} {'-'*10}")
        
        for i in range(len(offset) - 1):
            local_n = (offset[i + 1] - offset[i]).item()
            parent_n = (parent_offset[i + 1] - parent_offset[i]).item()
            ratio = parent_n / local_n if local_n > 0 else 0
            print(f"   {i:<10} {local_n:<15} {parent_n:<15} {ratio:<10.2f}x")
    
    # ğŸ”¥ åˆ†æå½’ä¸€åŒ–å‚æ•°
    if "norm_offset" in batch or "norm_scale" in batch:
        print(f"\n7ï¸âƒ£  å½’ä¸€åŒ–å‚æ•°:")
        if "norm_offset" in batch:
            norm_offset = batch["norm_offset"]
            print(f"   - norm_offset shape: {norm_offset.shape}")
            if norm_offset.dim() == 2:
                for i in range(min(norm_offset.shape[0], 5)):  # æœ€å¤šæ˜¾ç¤º 5 ä¸ª
                    print(f"      Sample {i}: [{norm_offset[i, 0]:.3f}, {norm_offset[i, 1]:.3f}, {norm_offset[i, 2]:.3f}]")
        
        if "norm_scale" in batch:
            norm_scale = batch["norm_scale"]
            print(f"   - norm_scale shape: {norm_scale.shape}")
            if norm_scale.dim() == 1:
                for i in range(min(norm_scale.shape[0], 5)):  # æœ€å¤šæ˜¾ç¤º 5 ä¸ª
                    print(f"      Sample {i}: {norm_scale[i].item():.6f}")
    
    # ğŸ”¥ åˆ†æ GT
    if "gt_position" in batch:
        gt_position = batch["gt_position"]
        print(f"\n8ï¸âƒ£  Ground Truth:")
        print(f"   - gt_position shape: {gt_position.shape}")
        for j in range(min(gt_position.shape[0], 5)):  # æœ€å¤šæ˜¾ç¤º 5 ä¸ª
            print(f"      Sample {j}: [{gt_position[j, 0]:.6f}, {gt_position[j, 1]:.6f}, {gt_position[j, 2]:.6f}]")
    
    # ğŸ”¥ åˆ†æç±»åˆ«
    if "category_id" in batch:
        category_id = batch["category_id"]
        print(f"\n9ï¸âƒ£  ç±»åˆ« ID:")
        print(f"   - category_id shape: {category_id.shape}")
        
        category_names = {0: "Scissors", 1: "Cup", 2: "Avocado"}
        for j in range(min(category_id.shape[0], 5)):  # æœ€å¤šæ˜¾ç¤º 5 ä¸ª
            cat_id = category_id[j].item()
            cat_name = category_names.get(cat_id, "Unknown")
            print(f"      Sample {j}: {cat_id} ({cat_name})")
    
    # ğŸ”¥ åˆ†ææ ·æœ¬åç§°
    if "name" in batch:
        print(f"\nğŸ”Ÿ æ ·æœ¬åç§°:")
        for j, name in enumerate(batch['name'][:5]):  # æœ€å¤šæ˜¾ç¤º 5 ä¸ª
            print(f"      Sample {j}: {name}")
    
    print(f"\n{'â”€' * 80}\n")


def test_train_dataloader():
    """æµ‹è¯•è®­ç»ƒé›† DataLoader"""
    print_separator("ğŸš‚ æµ‹è¯•è®­ç»ƒé›† DataLoader")
    
    cfg = Config.fromfile("/home/ypf/PointTransformerV3_Simple/configs/s3dis/semseg-pt-v3m1-gelsight.py")
    
    print(f"\nğŸ“‚ åŠ è½½è®­ç»ƒé›†...")
    train_dataset = build_dataset(cfg.data.train)
    
    print(f"   âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ!")
    print(f"      - æ•°æ®é›†ç±»å‹: {type(train_dataset).__name__}")
    print(f"      - æ ·æœ¬æ•°é‡: {len(train_dataset)}")
    print(f"      - Split: {train_dataset.split}")
    print(f"      - Parent cache size: {train_dataset.max_cache_size}")
    
    batch_size = 4
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,
        collate_fn=partial(point_collate_fn, mix_prob=0.0),
        pin_memory=False,
    )
    
    print(f"\nğŸ“¦ åˆ›å»º DataLoader:")
    print(f"   âœ… DataLoader åˆ›å»ºæˆåŠŸ!")
    print(f"      - Batch size: {batch_size}")
    print(f"      - Total batches: {len(train_loader)}")
    print(f"      - Collate function: point_collate_fn (mix_prob=0.0)")
    
    print_separator("ğŸ” æµ‹è¯•å‰ 2 ä¸ª Batch")
    
    for i, batch in enumerate(train_loader):
        if i >= 2:
            break
        
        analyze_batch(batch, i)
    
    print_separator("âœ… è®­ç»ƒé›† DataLoader æµ‹è¯•å®Œæˆ")


def test_val_dataloader():
    """æµ‹è¯•éªŒè¯é›† DataLoader"""
    print_separator("ğŸ” æµ‹è¯•éªŒè¯é›† DataLoader")
    
    cfg = Config.fromfile("/home/ypf/PointTransformerV3_Simple/configs/s3dis/semseg-pt-v3m1-gelsight.py")
    
    print(f"\nğŸ“‚ åŠ è½½éªŒè¯é›†...")
    val_dataset = build_dataset(cfg.data.val)
    
    print(f"   âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ!")
    print(f"      - æ•°æ®é›†ç±»å‹: {type(val_dataset).__name__}")
    print(f"      - æ ·æœ¬æ•°é‡: {len(val_dataset)}")
    print(f"      - Split: {val_dataset.split}")
    
    batch_size = 2
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        collate_fn=partial(point_collate_fn, mix_prob=0.0),
        pin_memory=False,
    )
    
    print(f"\nğŸ“¦ åˆ›å»º DataLoader:")
    print(f"   âœ… DataLoader åˆ›å»ºæˆåŠŸ!")
    print(f"      - Batch size: {batch_size}")
    print(f"      - Total batches: {len(val_loader)}")
    
    print_separator("ğŸ” æµ‹è¯•å‰ 1 ä¸ª Batch")
    
    for i, batch in enumerate(val_loader):
        if i >= 1:
            break
        
        analyze_batch(batch, i)
    
    print_separator("âœ… éªŒè¯é›† DataLoader æµ‹è¯•å®Œæˆ")


def test_collate_fn():
    """æµ‹è¯• collate_fn æ˜¯å¦æ­£ç¡®å¤„ç†çˆ¶ç‚¹äº‘"""
    print_separator("ğŸ”§ æµ‹è¯• point_collate_fn")
    
    cfg = Config.fromfile("/home/ypf/PointTransformerV3_Simple/configs/s3dis/semseg-pt-v3m1-gelsight.py")
    
    print(f"\nğŸ“‚ åŠ è½½è®­ç»ƒé›†...")
    train_dataset = build_dataset(cfg.data.train)
    
    # æ‰‹åŠ¨è·å–å‡ ä¸ªæ ·æœ¬
    print(f"\nğŸ“¦ æ‰‹åŠ¨è·å– 3 ä¸ªæ ·æœ¬...")
    samples = [train_dataset[i] for i in range(3)]
    
    print(f"\n   å„æ ·æœ¬çš„ keys:")
    for i, sample in enumerate(samples):
        print(f"   Sample {i}: {list(sample.keys())}")
        
        # ğŸ”¥ æ˜¾ç¤ºæ¯ä¸ªæ ·æœ¬çš„ç‚¹æ•°
        if "coord" in sample:
            local_n = sample["coord"].shape[0]
            print(f"      - å±€éƒ¨ç‚¹æ•°: {local_n}")
        
        if "parent_coord" in sample:
            parent_n = sample["parent_coord"].shape[0]
            print(f"      - çˆ¶ç‚¹äº‘ç‚¹æ•°: {parent_n}")
    
    # ä½¿ç”¨ collate_fn
    print(f"\nğŸ”§ è°ƒç”¨ point_collate_fn...")
    batch = point_collate_fn(samples, mix_prob=0.0)
    
    print(f"\n   âœ… Collate æˆåŠŸ!")
    print(f"   Batch keys: {list(batch.keys())}")
    
    # ğŸ”¥ é‡ç‚¹æ£€æŸ¥ parent_offset
    if "parent_offset" in batch:
        print(f"\n   âœ… æˆåŠŸç”Ÿæˆ parent_offset!")
        print(f"      - parent_offset: {batch['parent_offset'].tolist()}")
    else:
        print(f"\n   âŒ æœªç”Ÿæˆ parent_offset!")
        print(f"   âš ï¸  å¯èƒ½çš„é—®é¢˜:")
        print(f"      1. point_collate_fn æ²¡æœ‰ç”Ÿæˆ parent_offset")
        print(f"      2. parent_data ä¸­æ²¡æœ‰ parent_batch")
    
    # åˆ†æç»“æœ
    analyze_batch(batch, 0)
    
    print_separator("âœ… point_collate_fn æµ‹è¯•å®Œæˆ")


def test_single_sample():
    """æµ‹è¯•å•ä¸ªæ ·æœ¬çš„æ•°æ®ç»“æ„"""
    print_separator("ğŸ”¬ æµ‹è¯•å•ä¸ªæ ·æœ¬")
    
    cfg = Config.fromfile("/home/ypf/PointTransformerV3_Simple/configs/s3dis/semseg-pt-v3m1-gelsight.py")
    
    print(f"\nğŸ“‚ åŠ è½½è®­ç»ƒé›†...")
    train_dataset = build_dataset(cfg.data.train)
    
    print(f"\nğŸ“¦ è·å– Sample 0...")
    sample = train_dataset[0]
    
    print(f"\n   âœ… æ ·æœ¬è·å–æˆåŠŸ!")
    print(f"   - Type: {type(sample)}")
    print(f"   - Keys: {list(sample.keys())}")
    
    print(f"\n   è¯¦ç»†å­—æ®µåˆ†æ:")
    for key, value in sample.items():
        if isinstance(value, torch.Tensor):
            print(f"   âœ… {key:20s}: shape={str(value.shape):20s} dtype={value.dtype}")
        elif isinstance(value, (int, float)):
            print(f"   âœ… {key:20s}: {type(value).__name__}={value}")
        elif isinstance(value, str):
            print(f"   âœ… {key:20s}: '{value}'")
        else:
            print(f"   âš ï¸  {key:20s}: {type(value)}")
    
    # ğŸ”¥ æ£€æŸ¥çˆ¶ç‚¹äº‘å­—æ®µ
    print(f"\n   çˆ¶ç‚¹äº‘å­—æ®µæ£€æŸ¥:")
    parent_fields = ["parent_coord", "parent_color", "parent_grid_coord"]
    for field in parent_fields:
        if field in sample:
            value = sample[field]
            if isinstance(value, torch.Tensor):
                print(f"      âœ… {field}: shape={value.shape}")
            else:
                print(f"      âœ… {field}: {type(value).__name__}={value}")
        else:
            print(f"      âŒ {field}: ç¼ºå¤±")
    
    print_separator("âœ… å•ä¸ªæ ·æœ¬æµ‹è¯•å®Œæˆ")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "ğŸš€" * 40)
    print("å¼€å§‹æµ‹è¯•å¸¦çˆ¶ç‚¹äº‘çš„ DataLoader".center(80))
    print("ğŸš€" * 40)
    
    try:
        # 1. æµ‹è¯•å•ä¸ªæ ·æœ¬
        test_single_sample()
        
        # 2. æµ‹è¯• collate_fn
        test_collate_fn()
        
        # 3. æµ‹è¯•è®­ç»ƒé›†
        test_train_dataloader()
        
        # 4. æµ‹è¯•éªŒè¯é›†
        test_val_dataloader()
        
        print("\n" + "ğŸ‰" * 40)
        print("æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼".center(80))
        print("ğŸ‰" * 40 + "\n")
        
    except Exception as e:
        print("\n" + "âŒ" * 40)
        print(f"æµ‹è¯•å¤±è´¥: {e}".center(80))
        print("âŒ" * 40 + "\n")
        
        import traceback
        print("\nå®Œæ•´é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        
        raise


if __name__ == "__main__":
    main()