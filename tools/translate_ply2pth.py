"""
ğŸ¯ å°† GelSight é‡‡é›†çš„å±€éƒ¨ç‚¹äº‘ (.ply) è½¬æ¢ä¸ºæ¨ç†ç”¨çš„ .pth æ–‡ä»¶
- ä½¿ç”¨è®­ç»ƒé›†çš„å…¨å±€å½’ä¸€åŒ–å‚æ•°
- æ•°æ®ç»“æ„ä¸è®­ç»ƒé›†å®Œå…¨ä¸€è‡´
"""

import numpy as np
import open3d as o3d
import torch
from pathlib import Path
import json
import argparse


class LocalPCDConverter:
    def __init__(self, normalization_source):
        self.normalization_source = Path(normalization_source)
        self.global_min = None
        self.global_max = None
        self.global_range = None
        
        self._load_normalization_params()
        
        print(f"âœ… å…¨å±€å½’ä¸€åŒ–å‚æ•°åŠ è½½å®Œæˆ:")
        print(f"   global_min:   {self.global_min}")
        print(f"   global_max:   {self.global_max}")
        print(f"   global_range: {self.global_range}")
    
    def _load_normalization_params(self):
        """ä»è®­ç»ƒé›†åŠ è½½å…¨å±€å½’ä¸€åŒ–å‚æ•°"""
        source = self.normalization_source
        
        if source.suffix == '.pth':
            print(f"ğŸ“‚ ä»æ ·æœ¬æ–‡ä»¶åŠ è½½å½’ä¸€åŒ–å‚æ•°: {source}")
            data_dict = torch.load(source, weights_only=False)
            
            if 'norm_offset' not in data_dict or 'norm_scale' not in data_dict:
                raise ValueError(f"âŒ {source} ä¸­ç¼ºå°‘ norm_offset æˆ– norm_scale å­—æ®µ")
            
            self.global_min = data_dict['norm_offset']
            self.global_range = data_dict['norm_scale']
            self.global_max = self.global_min + self.global_range
            
            # ç¡®ä¿æ˜¯ numpy æ•°ç»„
            if isinstance(self.global_min, torch.Tensor):
                self.global_min = self.global_min.cpu().numpy()
            if isinstance(self.global_range, torch.Tensor):
                self.global_range = self.global_range.cpu().numpy()
            if isinstance(self.global_max, torch.Tensor):
                self.global_max = self.global_max.cpu().numpy()
        else:
            raise ValueError(
                f"âŒ ä¸æ”¯æŒçš„å½’ä¸€åŒ–å‚æ•°æ¥æº: {source}\n"
                f"   è¯·æä¾›è®­ç»ƒé›†çš„ .pth æ ·æœ¬æ–‡ä»¶"
            )
        
        # ç±»å‹æ£€æŸ¥
        self.global_min = self.global_min.astype(np.float32)
        self.global_max = self.global_max.astype(np.float32)
        self.global_range = self.global_range.astype(np.float32)
    
    def load_local_pointcloud(self, ply_path):
        ply_path = Path(ply_path)
        
        if not ply_path.exists():
            raise FileNotFoundError(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {ply_path}")
        
        print(f"\nğŸ“‚ åŠ è½½å±€éƒ¨ç‚¹äº‘: {ply_path.name}")
        
        pcd = o3d.io.read_point_cloud(str(ply_path))
        
        if len(pcd.points) == 0:
            raise ValueError(f"âŒ ç‚¹äº‘ä¸ºç©º: {ply_path}")
        
        local_coord = np.asarray(pcd.points, dtype=np.float32)
        
        if pcd.has_colors():
            local_color = np.asarray(pcd.colors, dtype=np.float32)
            print(f"   âœ… åŠ è½½ {len(local_coord)} ä¸ªç‚¹ï¼ˆå¸¦é¢œè‰²ï¼‰")
        else:
            local_color = np.ones((len(local_coord), 3), dtype=np.float32) * 0.5
            print(f"   âš ï¸  åŠ è½½ {len(local_coord)} ä¸ªç‚¹ï¼ˆæ— é¢œè‰²ï¼Œä½¿ç”¨é»˜è®¤ç°è‰²ï¼‰")
        
        # æ‰“å°åæ ‡èŒƒå›´
        coord_min = local_coord.min(axis=0)
        coord_max = local_coord.max(axis=0)
        coord_range = coord_max - coord_min
        
        print(f"   åæ ‡èŒƒå›´:")
        print(f"      X: [{coord_min[0]:.6f}, {coord_max[0]:.6f}] (range: {coord_range[0]:.6f})")
        print(f"      Y: [{coord_min[1]:.6f}, {coord_max[1]:.6f}] (range: {coord_range[1]:.6f})")
        print(f"      Z: [{coord_min[2]:.6f}, {coord_max[2]:.6f}] (range: {coord_range[2]:.6f})")
        
        return local_coord, local_color
    
    def convert_to_pth(
        self,
        ply_path,
        output_path=None,
        category="Unknown",
        category_id=0,
        sample_name=None,
        gt_position=None,
        bigpcd_id=None,
        bigpcd_name=None,
    ):
        ply_path = Path(ply_path)
        
        # ğŸ”¥ è‡ªåŠ¨ç”Ÿæˆ sample_name
        if sample_name is None:
            sample_name = ply_path.stem
        
        # 1. åŠ è½½ç‚¹äº‘
        local_coord_original, local_color = self.load_local_pointcloud(ply_path)
        
        # 2. å½’ä¸€åŒ–å±€éƒ¨ç‚¹äº‘
        local_coord_normalized = (local_coord_original - self.global_min) / self.global_range
        local_coord_normalized = local_coord_normalized.astype(np.float32)
        
        print(f"\nğŸŒ å½’ä¸€åŒ–ç»“æœ:")
        print(f"   å½’ä¸€åŒ–åæ ‡èŒƒå›´: [{local_coord_normalized.min():.6f}, {local_coord_normalized.max():.6f}]")
        
        # âš ï¸ æ£€æŸ¥æ˜¯å¦åœ¨ [0, 1] èŒƒå›´å†…
        if local_coord_normalized.min() < -0.1 or local_coord_normalized.max() > 1.1:
            print(f"   âš ï¸  è­¦å‘Šï¼šå½’ä¸€åŒ–åæ ‡è¶…å‡º [0, 1] èŒƒå›´è¾ƒå¤šï¼")
            print(f"       è¿™å¯èƒ½æ„å‘³ç€å½“å‰ç‚¹äº‘ä¸è®­ç»ƒé›†çš„ç©ºé—´èŒƒå›´å·®å¼‚è¾ƒå¤§")
        elif local_coord_normalized.min() < 0 or local_coord_normalized.max() > 1:
            print(f"   âš ï¸  æ³¨æ„ï¼šå½’ä¸€åŒ–åæ ‡ç•¥å¾®è¶…å‡º [0, 1] èŒƒå›´ï¼ˆå¯æ¥å—ï¼‰")
        else:
            print(f"   âœ… å½’ä¸€åŒ–åæ ‡åœ¨ [0, 1] èŒƒå›´å†…")
        
        # ğŸ”¥ 3. å¤„ç† GT ä½ç½®
        if gt_position is not None:
            gt_position_original = np.array(gt_position, dtype=np.float32)
            gt_position_normalized = (gt_position_original - self.global_min) / self.global_range
            gt_position_normalized = gt_position_normalized.astype(np.float32)
            
            gt_available = True
            
            print(f"\nâœ… GT ä½ç½®:")
            print(f"   åŸå§‹ç©ºé—´:   [{gt_position_original[0]:.6f}, {gt_position_original[1]:.6f}, {gt_position_original[2]:.6f}] ç±³")
            print(f"   å½’ä¸€åŒ–ç©ºé—´: [{gt_position_normalized[0]:.6f}, {gt_position_normalized[1]:.6f}, {gt_position_normalized[2]:.6f}]")
        else:
            centroid_original = local_coord_original.mean(axis=0).astype(np.float32)
            gt_position_original = centroid_original
            gt_position_normalized = (centroid_original - self.global_min) / self.global_range
            gt_position_normalized = gt_position_normalized.astype(np.float32)
            
            gt_available = False
            
            print(f"\nâš ï¸  æ—  GT ä½ç½®ï¼ˆçœŸå®æ¨ç†åœºæ™¯ï¼‰")
            print(f"   ä½¿ç”¨å±€éƒ¨ç‚¹äº‘è´¨å¿ƒä½œä¸ºå ä½ç¬¦ï¼ˆä¸å‚ä¸è¯¯å·®è®¡ç®—ï¼‰:")
            print(f"      åŸå§‹ç©ºé—´:   [{gt_position_original[0]:.6f}, {gt_position_original[1]:.6f}, {gt_position_original[2]:.6f}] ç±³")
            print(f"      å½’ä¸€åŒ–ç©ºé—´: [{gt_position_normalized[0]:.6f}, {gt_position_normalized[1]:.6f}, {gt_position_normalized[2]:.6f}]")
        
        # ğŸ”¥ 4. å¤„ç†çˆ¶ç‚¹äº‘ä¿¡æ¯
        if bigpcd_id is not None and bigpcd_id >= 0:
            if bigpcd_name is None:
                if isinstance(bigpcd_id, int):
                    bigpcd_name = f"bigpointcloud_{bigpcd_id:03d}.ply"
                else:
                    bigpcd_name = f"bigpointcloud_{str(bigpcd_id).zfill(3)}.ply"
            
            print(f"\nâœ… çˆ¶ç‚¹äº‘ä¿¡æ¯:")
            print(f"   ID:   {bigpcd_id}")
            print(f"   æ–‡ä»¶: {bigpcd_name}")
        else:
            bigpcd_id = -1
            bigpcd_name = "unknown"
            
            print(f"\nâš ï¸  æœªæŒ‡å®šçˆ¶ç‚¹äº‘ï¼ˆæ¨ç†æ—¶ä¸ä¼šå°è¯•åŠ è½½çˆ¶ç‚¹äº‘ï¼‰")
        
        # 5. æ„é€ æ•°æ®å­—å…¸
        data_dict = {
            "local_coord": local_coord_normalized,
            "local_color": local_color,
            "gt_position": gt_position_normalized,
            "gt_available": gt_available,
            "norm_offset": self.global_min,
            "norm_scale": self.global_range,
            "local_coord_original": local_coord_original,
            "gt_position_original": gt_position_original,
            "extraction_method": "real_gelsight",
            "extraction_radius": 0.0,
            "category": category,
            "category_id": category_id,
            "bigpcd_name": bigpcd_name,
            "bigpcd_id": bigpcd_id,
            "parent_id": bigpcd_id,
            "sample_id": -1,
            "name": sample_name,
        }
        
        # 6. ä¿å­˜
        if output_path is None:
            output_path = ply_path.with_suffix('.pth')
        else:
            output_path = Path(output_path)
        
        output_path.parent.mkdir(parents=True, exist_ok=True)
        torch.save(data_dict, output_path)
        
        print(f"\nâœ… è½¬æ¢å®Œæˆï¼")
        print(f"   è¾“å…¥: {ply_path}")
        print(f"   è¾“å‡º: {output_path}")
        print(f"   æ ·æœ¬åç§°: {sample_name}")
        print(f"   ç‚¹æ•°: {len(local_coord_normalized)}")
        print(f"   GT å¯ç”¨: {'æ˜¯' if gt_available else 'å¦'}")
        print(f"   çˆ¶ç‚¹äº‘ ID: {bigpcd_id}")
        
        return output_path
    
    def verify_pth(self, pth_path):
        """éªŒè¯ç”Ÿæˆçš„ .pth æ–‡ä»¶"""
        pth_path = Path(pth_path)
        
        print(f"\n{'='*70}")
        print(f"ğŸ” éªŒè¯ç”Ÿæˆçš„ .pth æ–‡ä»¶")
        print(f"{'='*70}")
        print(f"æ–‡ä»¶: {pth_path}\n")
        
        data_dict = torch.load(pth_path, weights_only=False)
        
        print("ğŸ“‹ å­—æ®µæ£€æŸ¥:")
        required_keys = [
            "local_coord", "local_color", "gt_position", "gt_available",
            "norm_offset", "norm_scale",
            "local_coord_original", "gt_position_original",
            "extraction_method", "extraction_radius",
            "category", "category_id", "bigpcd_name", "bigpcd_id", 
            "parent_id", "sample_id", "name"
        ]
        
        for key in required_keys:
            if key in data_dict:
                value = data_dict[key]
                if isinstance(value, np.ndarray):
                    print(f"   âœ… {key:25s} shape={str(value.shape):15s} dtype={value.dtype}")
                elif value is None:
                    print(f"   âœ… {key:25s} value=None")
                elif isinstance(value, (bool, np.bool_)):
                    print(f"   âœ… {key:25s} value={value}")
                else:
                    print(f"   âœ… {key:25s} value={value}")
            else:
                print(f"   âŒ {key:25s} ç¼ºå¤±")
        
        # ğŸ”¥ åå½’ä¸€åŒ–éªŒè¯
        gt_available = data_dict.get('gt_available', False)
        
        print(f"\nğŸ”„ åå½’ä¸€åŒ–éªŒè¯:")
        print(f"   GT å¯ç”¨: {'æ˜¯' if gt_available else 'å¦'}")
        
        local_coord_norm = data_dict['local_coord']
        norm_offset = data_dict['norm_offset']
        norm_scale = data_dict['norm_scale']
        local_coord_original = data_dict['local_coord_original']
        
        # åå½’ä¸€åŒ–å±€éƒ¨ç‚¹äº‘
        local_coord_denorm = local_coord_norm * norm_scale + norm_offset
        coord_diff = np.abs(local_coord_denorm - local_coord_original).max()
        
        print(f"\n   å±€éƒ¨ç‚¹äº‘åå½’ä¸€åŒ–:")
        print(f"      åæ ‡æœ€å¤§å·®å¼‚: {coord_diff:.6e} ç±³ = {coord_diff*1000:.6f} æ¯«ç±³")
        
        if coord_diff < 1e-6:
            print(f"      âœ… åå½’ä¸€åŒ–ç»“æœä¸åŸå§‹æ•°æ®å®Œå…¨ä¸€è‡´")
        elif coord_diff < 1e-3:
            print(f"      âœ… åå½’ä¸€åŒ–ç»“æœä¸åŸå§‹æ•°æ®åŸºæœ¬ä¸€è‡´ï¼ˆç²¾åº¦æŸå¤±å¯æ¥å—ï¼‰")
        else:
            print(f"      âš ï¸  åå½’ä¸€åŒ–ç»“æœä¸åŸå§‹æ•°æ®å·®å¼‚è¾ƒå¤§")
        
        # ğŸ”¥ å¦‚æœæœ‰ GTï¼ŒéªŒè¯ GT ä½ç½®
        if gt_available:
            gt_position_norm = data_dict['gt_position']
            gt_position_original = data_dict['gt_position_original']
            
            gt_position_denorm = gt_position_norm * norm_scale + norm_offset
            gt_diff = np.linalg.norm(gt_position_denorm - gt_position_original)
            
            print(f"\n   GT ä½ç½®åå½’ä¸€åŒ–:")
            print(f"      ä½ç½®å·®å¼‚: {gt_diff:.6e} ç±³ = {gt_diff*1000:.6f} æ¯«ç±³")
            
            if gt_diff < 1e-6:
                print(f"      âœ… åå½’ä¸€åŒ–ç»“æœä¸åŸå§‹æ•°æ®å®Œå…¨ä¸€è‡´")
            elif gt_diff < 1e-3:
                print(f"      âœ… åå½’ä¸€åŒ–ç»“æœä¸åŸå§‹æ•°æ®åŸºæœ¬ä¸€è‡´ï¼ˆç²¾åº¦æŸå¤±å¯æ¥å—ï¼‰")
            else:
                print(f"      âš ï¸  åå½’ä¸€åŒ–ç»“æœä¸åŸå§‹æ•°æ®å·®å¼‚è¾ƒå¤§")
        
        print(f"\n{'='*70}\n")


def batch_convert(
    input_dir,
    output_dir,
    normalization_source,
    category="Unknown",
    category_id=0,
    config_file=None,  # ğŸ”¥ æ”¹åï¼šæ›´é€šç”¨çš„é…ç½®æ–‡ä»¶
):
    """
    æ‰¹é‡è½¬æ¢ç›®å½•ä¸‹çš„æ‰€æœ‰ .ply æ–‡ä»¶
    
    Args:
        config_file: (å¯é€‰) é…ç½®æ–‡ä»¶ï¼ˆJSON æ ¼å¼ï¼‰ï¼Œæ”¯æŒ:
                     {
                       "sample1.ply": {
                         "gt_position": [x, y, z],
                         "bigpcd_id": 1,
                         "bigpcd_name": "bigpointcloud_001.ply"  // å¯é€‰
                       },
                       "sample2.ply": {
                         "bigpcd_id": 2
                       },
                       ...
                     }
                     
                     æˆ–ç®€åŒ–æ ¼å¼ï¼ˆä»… GTï¼‰:
                     {
                       "sample1.ply": [x, y, z],
                       "sample2.ply": [x, y, z],
                       ...
                     }
    """
    input_dir = Path(input_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    ply_files = sorted(input_dir.glob("*.ply"))
    
    if len(ply_files) == 0:
        print(f"âŒ åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ° .ply æ–‡ä»¶")
        return
    
    # ğŸ”¥ åŠ è½½é…ç½®æ–‡ä»¶
    config_dict = {}
    if config_file is not None:
        config_file = Path(config_file)
        if config_file.exists():
            with open(config_file, 'r') as f:
                config_dict = json.load(f)
            print(f"âœ… åŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
            print(f"   åŒ…å« {len(config_dict)} ä¸ªæ ·æœ¬çš„é…ç½®")
        else:
            print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
    
    print(f"\n{'='*70}")
    print(f"ğŸ“¦ æ‰¹é‡è½¬æ¢æ¨¡å¼")
    print(f"{'='*70}")
    print(f"   è¾“å…¥ç›®å½•: {input_dir}")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    print(f"   å‘ç° {len(ply_files)} ä¸ª .ply æ–‡ä»¶")
    print(f"   é…ç½®æ ·æœ¬: {len(config_dict)}/{len(ply_files)}")
    print(f"{'='*70}\n")
    
    converter = LocalPCDConverter(normalization_source)
    
    success_count = 0
    failed_count = 0
    
    for i, ply_path in enumerate(ply_files, 1):
        print(f"\n{'='*70}")
        print(f"[{i}/{len(ply_files)}] å¤„ç†: {ply_path.name}")
        print(f"{'='*70}")
        
        output_path = output_dir / ply_path.with_suffix('.pth').name
        
        # ğŸ”¥ è§£æé…ç½®
        sample_config = config_dict.get(ply_path.name, {})
        
        # æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
        # 1. å®Œæ•´é…ç½®: {"gt_position": [x,y,z], "bigpcd_id": 1, ...}
        # 2. ç®€åŒ–é…ç½®: [x, y, z]  (ä»… GT ä½ç½®)
        if isinstance(sample_config, list):
            # ç®€åŒ–æ ¼å¼ï¼šç›´æ¥æ˜¯ GT ä½ç½®
            gt_position = sample_config
            bigpcd_id = None
            bigpcd_name = None
        elif isinstance(sample_config, dict):
            # å®Œæ•´æ ¼å¼
            gt_position = sample_config.get('gt_position', None)
            bigpcd_id = sample_config.get('bigpcd_id', None)
            bigpcd_name = sample_config.get('bigpcd_name', None)
        else:
            # æ— é…ç½®
            gt_position = None
            bigpcd_id = None
            bigpcd_name = None
        
        try:
            converter.convert_to_pth(
                ply_path=ply_path,
                output_path=output_path,
                category=category,
                category_id=category_id,
                sample_name=ply_path.stem,  # ğŸ”¥ ä½¿ç”¨æ–‡ä»¶åä½œä¸ºæ ·æœ¬å
                gt_position=gt_position,
                bigpcd_id=bigpcd_id,
                bigpcd_name=bigpcd_name,
            )
            success_count += 1
        except Exception as e:
            print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            failed_count += 1
            continue
    
    print(f"\n{'='*70}")
    print(f"âœ… æ‰¹é‡è½¬æ¢å®Œæˆï¼")
    print(f"   æˆåŠŸ: {success_count}/{len(ply_files)}")
    print(f"   å¤±è´¥: {failed_count}/{len(ply_files)}")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    print(f"{'='*70}\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="ğŸ¯ å°† GelSight å±€éƒ¨ç‚¹äº‘ (.ply) è½¬æ¢ä¸ºæ¨ç†ç”¨çš„ .pth æ–‡ä»¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

1. å•æ–‡ä»¶è½¬æ¢ï¼ˆæ—  GTï¼Œæ— çˆ¶ç‚¹äº‘ï¼‰:
   python convert_local_pcd_to_pth.py \\
       --input sample.ply \\
       --normalization data_root/Scissors/patches/patch_000001.pth \\
       --category Scissors \\
       --category_id 0

2. å•æ–‡ä»¶è½¬æ¢ï¼ˆæœ‰ GTï¼Œæœ‰çˆ¶ç‚¹äº‘ï¼‰:
   python convert_local_pcd_to_pth.py \\
       --input sample.ply \\
       --normalization data_root/Scissors/patches/patch_000001.pth \\
       --category Scissors \\
       --category_id 0 \\
       --gt_x 0.012 --gt_y 0.034 --gt_z 0.056 \\
       --bigpcd_id 1

3. æ‰¹é‡è½¬æ¢ï¼ˆæ— é…ç½®æ–‡ä»¶ï¼‰:
   python convert_local_pcd_to_pth.py \\
       --input_dir gelsight_samples/ \\
       --output_dir inference_data/ \\
       --normalization data_root/Scissors/patches/patch_000001.pth \\
       --category Scissors \\
       --category_id 0

4. æ‰¹é‡è½¬æ¢ï¼ˆæœ‰é…ç½®æ–‡ä»¶ï¼‰:
   python convert_local_pcd_to_pth.py \\
       --input_dir gelsight_samples/ \\
       --output_dir inference_data/ \\
       --normalization data_root/Scissors/patches/patch_000001.pth \\
       --category Scissors \\
       --category_id 0 \\
       --config samples_config.json

   é…ç½®æ–‡ä»¶æ ¼å¼ (samples_config.json):
   {
     "sample1.ply": {
       "gt_position": [0.012, 0.034, 0.056],
       "bigpcd_id": 1,
       "bigpcd_name": "bigpointcloud_001.ply"
     },
     "sample2.ply": {
       "bigpcd_id": 2
     },
     "sample3.ply": [0.023, 0.045, 0.067]
   }

5. éªŒè¯è½¬æ¢ç»“æœ:
   python convert_local_pcd_to_pth.py \\
       --verify output.pth
        """
    )
    
    # è¾“å…¥/è¾“å‡ºå‚æ•°
    parser.add_argument(
        "--input", type=str, default=None,
        help="è¾“å…¥çš„ .ply æ–‡ä»¶è·¯å¾„ï¼ˆå•æ–‡ä»¶æ¨¡å¼ï¼‰"
    )
    parser.add_argument(
        "--output", type=str, default=None,
        help="è¾“å‡ºçš„ .pth æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šä¸è¾“å…¥åŒååŒç›®å½•ï¼‰"
    )
    parser.add_argument(
        "--input_dir", type=str, default=None,
        help="è¾“å…¥ç›®å½•ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰"
    )
    parser.add_argument(
        "--output_dir", type=str, default=None,
        help="è¾“å‡ºç›®å½•ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰"
    )
    
    # å½’ä¸€åŒ–å‚æ•°
    parser.add_argument(
        "--normalization", type=str, required=False,
        help="å½’ä¸€åŒ–å‚æ•°æ¥æºï¼šè®­ç»ƒé›†çš„ .pth æ ·æœ¬"
    )
    
    # ç±»åˆ«å‚æ•°
    parser.add_argument(
        "--category", type=str, default="Unknown",
        help="ç±»åˆ«åç§°ï¼ˆä¾‹å¦‚: Scissors, Cup, Avocadoï¼‰"
    )
    parser.add_argument(
        "--category_id", type=int, default=0,
        help="ç±»åˆ« IDï¼ˆ0=Scissors, 1=Cup, 2=Avocadoï¼‰"
    )
    
    # ğŸ”¥ GT ä½ç½®å‚æ•°ï¼ˆå•æ–‡ä»¶æ¨¡å¼ï¼‰
    parser.add_argument(
        "--gt_x", type=float, default=None,
        help="GT ä½ç½®çš„ X åæ ‡ï¼ˆç±³ï¼ŒçœŸå®ç©ºé—´ï¼‰"
    )
    parser.add_argument(
        "--gt_y", type=float, default=None,
        help="GT ä½ç½®çš„ Y åæ ‡ï¼ˆç±³ï¼ŒçœŸå®ç©ºé—´ï¼‰"
    )
    parser.add_argument(
        "--gt_z", type=float, default=None,
        help="GT ä½ç½®çš„ Z åæ ‡ï¼ˆç±³ï¼ŒçœŸå®ç©ºé—´ï¼‰"
    )
    
    # ğŸ”¥ çˆ¶ç‚¹äº‘å‚æ•°ï¼ˆå•æ–‡ä»¶æ¨¡å¼ï¼‰
    parser.add_argument(
        "--bigpcd_id", type=int, default=None,
        help="çˆ¶ç‚¹äº‘ IDï¼ˆä¾‹å¦‚ 1, 2, 3ï¼‰ã€‚å¦‚æœä¸æä¾›ï¼Œå°†ä¸å°è¯•åŠ è½½çˆ¶ç‚¹äº‘"
    )
    parser.add_argument(
        "--bigpcd_name", type=str, default=None,
        help="çˆ¶ç‚¹äº‘æ–‡ä»¶åï¼ˆä¾‹å¦‚ bigpointcloud_001.plyï¼‰ã€‚å¯é€‰ï¼Œé»˜è®¤æ ¹æ® ID ç”Ÿæˆ"
    )
    
    # ğŸ”¥ é…ç½®æ–‡ä»¶ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰
    parser.add_argument(
        "--config", type=str, default=None,
        help="é…ç½®æ–‡ä»¶ï¼ˆJSON æ ¼å¼ï¼Œæ‰¹é‡æ¨¡å¼ï¼‰ã€‚åŒ…å« GT ä½ç½®å’Œçˆ¶ç‚¹äº‘ ID"
    )
    
    # éªŒè¯æ¨¡å¼
    parser.add_argument(
        "--verify", type=str, default=None,
        help="éªŒè¯ .pth æ–‡ä»¶"
    )
       
    args = parser.parse_args()
    
    if args.verify:
        # ğŸ”¥ éªŒè¯æ¨¡å¼ï¼ˆä¸éœ€è¦ normalization å‚æ•°ï¼‰
        converter_temp = LocalPCDConverter.__new__(LocalPCDConverter)
        converter_temp.verify_pth(args.verify)
    
    elif args.input_dir and args.output_dir and args.normalization:
        # æ‰¹é‡æ¨¡å¼
        batch_convert(
            input_dir=args.input_dir,
            output_dir=args.output_dir,
            normalization_source=args.normalization,
            category=args.category,
            category_id=args.category_id,
            config_file=args.config,  # ğŸ”¥ æ”¹ä¸º config_file
        )
    
    elif args.input and args.normalization:
        # å•æ–‡ä»¶æ¨¡å¼
        converter = LocalPCDConverter(args.normalization)
        
        # ğŸ”¥ æ„é€  GT ä½ç½®ï¼ˆå¦‚æœæä¾›ï¼‰
        gt_position = None
        if args.gt_x is not None and args.gt_y is not None and args.gt_z is not None:
            gt_position = [args.gt_x, args.gt_y, args.gt_z]
        
        converter.convert_to_pth(
            ply_path=args.input,
            output_path=args.output,
            category=args.category,
            category_id=args.category_id,
            sample_name=None,  # ğŸ”¥ ä¼šè‡ªåŠ¨ä½¿ç”¨æ–‡ä»¶å
            gt_position=gt_position,
            bigpcd_id=args.bigpcd_id,
            bigpcd_name=args.bigpcd_name,             
        )
    
    else:
        parser.print_help()